{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "from io import StringIO\n",
    "import mne\n",
    "from mne.io import read_raw_eeglab, read_epochs_eeglab\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from scipy import fftpack\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from livelossplot.tf_keras import PlotLossesCallback\n",
    "\n",
    "import sklearn.model_selection\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "import multiprocessing\n",
    "from tpot import TPOTRegressor\n",
    "from oct2py import octave\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from joblib import wrap_non_picklable_objects\n",
    "import json\n",
    "import pickle\n",
    "import os.path\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import timeit\n",
    "from skimage.transform import resize\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, optimizers, callbacks\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.genmod import bayes_mixed_glm as glm\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import RFECV\n",
    "from spectrum import arburg, arma2psd, pburg\n",
    "import pylab\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.integrate import simps\n",
    "from scipy.io import loadmat\n",
    "from numpy import trapz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import some MATLAB libraries\n",
    "This helps us read .set files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.:/home/raquib/Documents/MATLAB/eeglab2019_0/functions/sigprocfunc:/home/raquib/Documents/MATLAB/eeglab2019_0/functions/adminfunc:/home/raquib/Documents/MATLAB/eeglab2019_0/functions/popfunc:/home/raquib/Documents/MATLAB/eeglab2019_0/functions/guifunc:/home/raquib/Documents/MATLAB/eeglab2019_0/functions/miscfunc:/home/raquib/anaconda3/envs/tmseeg/lib/python3.7/site-packages/oct2py:/home/raquib/anaconda3/envs/tmseeg/lib/python3.7/site-packages/octave_kernel:/usr/lib/x86_64-linux-gnu/octave/4.2.2/site/oct/x86_64-pc-linux-gnu:/usr/lib/x86_64-linux-gnu/octave/site/oct/api-v51/x86_64-pc-linux-gnu:/usr/lib/x86_64-linux-gnu/octave/site/oct/x86_64-pc-linux-gnu:/usr/share/octave/4.2.2/site/m:/usr/share/octave/site/api-v51/m:/usr/share/octave/site/m:/usr/share/octave/site/m/startup:/usr/lib/x86_64-linux-gnu/octave/4.2.2/oct/x86_64-pc-linux-gnu:/usr/share/octave/4.2.2/m:/usr/share/octave/4.2.2/m/audio:/usr/share/octave/4.2.2/m/debian:/usr/share/octave/4.2.2/m/deprecated:/usr/share/octave/4.2.2/m/elfun:/usr/share/octave/4.2.2/m/general:/usr/share/octave/4.2.2/m/geometry:/usr/share/octave/4.2.2/m/gui:/usr/share/octave/4.2.2/m/help:/usr/share/octave/4.2.2/m/image:/usr/share/octave/4.2.2/m/io:/usr/share/octave/4.2.2/m/java:/usr/share/octave/4.2.2/m/linear-algebra:/usr/share/octave/4.2.2/m/miscellaneous:/usr/share/octave/4.2.2/m/ode:/usr/share/octave/4.2.2/m/optimization:/usr/share/octave/4.2.2/m/path:/usr/share/octave/4.2.2/m/pkg:/usr/share/octave/4.2.2/m/plot:/usr/share/octave/4.2.2/m/plot/appearance:/usr/share/octave/4.2.2/m/plot/draw:/usr/share/octave/4.2.2/m/plot/util:/usr/share/octave/4.2.2/m/polynomial:/usr/share/octave/4.2.2/m/prefs:/usr/share/octave/4.2.2/m/profiler:/usr/share/octave/4.2.2/m/set:/usr/share/octave/4.2.2/m/signal:/usr/share/octave/4.2.2/m/sparse:/usr/share/octave/4.2.2/m/specfun:/usr/share/octave/4.2.2/m/special-matrix:/usr/share/octave/4.2.2/m/startup:/usr/share/octave/4.2.2/m/statistics:/usr/share/octave/4.2.2/m/statistics/base:/usr/share/octave/4.2.2/m/statistics/distributions:/usr/share/octave/4.2.2/m/statistics/models:/usr/share/octave/4.2.2/m/statistics/tests:/usr/share/octave/4.2.2/m/strings:/usr/share/octave/4.2.2/m/testfun:/usr/share/octave/4.2.2/m/time:/usr/share/octave/4.2.2/data'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeglab_path = '/home/raquib/Documents/MATLAB/eeglab2019_0/functions/'\n",
    "octave.addpath(eeglab_path + 'guifunc')\n",
    "octave.addpath(eeglab_path + 'popfunc')\n",
    "octave.addpath(eeglab_path + 'adminfunc')\n",
    "octave.addpath(eeglab_path + 'sigprocfunc')\n",
    "octave.addpath(eeglab_path + 'miscfunc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all file paths.\n",
    "EEG artifacts were cleaned in MATLAB and clean EEGs were saved in MAT files. Some trials are rejected:\n",
    "\n",
    "- Trials are rejected when there are more than one session. This means we only take one session of each subject.\n",
    "- Trials are rejected when the MEP is unusable.\n",
    "- Trials are rejected when the session log file explicitely states that there is something wrong with those trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/original/sub02/exp01/eeg/SP 110RMT r1/08-avg-csd.mat',\n",
       " 'data/original/sub02/exp01/eeg/SP 110RMT r2/08-avg-csd.mat',\n",
       " 'data/original/sub02/exp01/eeg/SP 110RMT r3/08-avg-csd.mat',\n",
       " 'data/original/sub03/exp01/eeg/SP 110RMT r1/08-avg-csd.mat',\n",
       " 'data/original/sub03/exp01/eeg/SP 110RMT r2/08-avg-csd.mat',\n",
       " 'data/original/sub03/exp01/eeg/SP 110RMT r3/08-avg-csd.mat',\n",
       " 'data/original/sub03/exp03/eeg/SP 110RMT r1/08-avg-csd.mat',\n",
       " 'data/original/sub03/exp03/eeg/SP 110RMT r2/08-avg-csd.mat',\n",
       " 'data/original/sub03/exp03/eeg/SP 110RMT r3/08-avg-csd.mat',\n",
       " 'data/original/sub04/exp01/eeg/SP 110RMT r1/08-avg-csd.mat',\n",
       " 'data/original/sub04/exp01/eeg/SP 110RMT r2/08-avg-csd.mat',\n",
       " 'data/original/sub04/exp01/eeg/SP 110RMT r3/08-avg-csd.mat',\n",
       " 'data/original/sub04/exp02/eeg/SP 110RMT r1/08-avg-csd.mat',\n",
       " 'data/original/sub04/exp02/eeg/SP 110RMT r2/08-avg-csd.mat',\n",
       " 'data/original/sub04/exp02/eeg/SP 110RMT r3/08-avg-csd.mat',\n",
       " 'data/original/sub05/exp01/eeg/SP 110RMT r1/08-avg-csd.mat',\n",
       " 'data/original/sub05/exp01/eeg/SP 110RMT r2/08-avg-csd.mat',\n",
       " 'data/original/sub05/exp01/eeg/SP 110RMT r3/08-avg-csd.mat',\n",
       " 'data/original/sub05/exp02/eeg/SP 110RMT r1/08-avg-csd.mat',\n",
       " 'data/original/sub05/exp02/eeg/SP 110RMT r2/08-avg-csd.mat',\n",
       " 'data/original/sub05/exp02/eeg/SP 110RMT r3/08-avg-csd.mat',\n",
       " 'data/original/sub06/exp01/eeg/SP 110RMT r1/08-avg-csd.mat',\n",
       " 'data/original/sub06/exp01/eeg/SP 110RMT r2/08-avg-csd.mat',\n",
       " 'data/original/sub06/exp01/eeg/SP 110RMT r3/08-avg-csd.mat',\n",
       " 'data/original/sub06/exp02/eeg/SP 110RMT r1/08-avg-csd.mat',\n",
       " 'data/original/sub07/exp01/eeg/SP 110RMT r1/08-avg-csd.mat',\n",
       " 'data/original/sub07/exp01/eeg/SP 110RMT r2/08-avg-csd.mat',\n",
       " 'data/original/sub07/exp01/eeg/SP 110RMT r3/08-avg-csd.mat',\n",
       " 'data/original/sub08/exp01/eeg/SP 110RMT r1/08-avg-csd.mat',\n",
       " 'data/original/sub08/exp01/eeg/SP 110RMT r2/08-avg-csd.mat',\n",
       " 'data/original/sub08/exp01/eeg/SP 110RMT r3/08-avg-csd.mat',\n",
       " 'data/original/sub08/exp02/eeg/SP 110RMT r1/08-avg-csd.mat',\n",
       " 'data/original/sub08/exp03/eeg/SP 110RMT r1/08-avg-csd.mat',\n",
       " 'data/original/sub08/exp03/eeg/SP 110RMT r2/08-avg-csd.mat',\n",
       " 'data/original/sub08/exp03/eeg/SP 110RMT r3/08-avg-csd.mat',\n",
       " 'data/original/sub09/exp01/eeg/SP 110RMT r1/08-avg-csd.mat',\n",
       " 'data/original/sub10/exp01/eeg/SP 110RMT r1/08-avg-csd.mat',\n",
       " 'data/original/sub10/exp02/eeg/SP 110RMT r1/08-avg-csd.mat',\n",
       " 'data/original/sub10/exp02/eeg/SP 110RMT r2/08-avg-csd.mat',\n",
       " 'data/original/sub10/exp02/eeg/SP 110RMT r3/08-avg-csd.mat',\n",
       " 'data/original/sub11/exp01/eeg/SP 110RMT r1/08-avg-csd.mat',\n",
       " 'data/original/sub12/exp01/eeg/SP 110RMT r1/08-avg-csd.mat',\n",
       " 'data/original/sub12/exp02/eeg/SP 110RMT r1/08-avg-csd.mat',\n",
       " 'data/original/sub12/exp03/eeg/SP 110RMT r1/08-avg-csd.mat',\n",
       " 'data/original/sub12/exp03/eeg/SP 110RMT r2/08-avg-csd.mat',\n",
       " 'data/original/sub12/exp03/eeg/SP 110RMT r3/08-avg-csd.mat',\n",
       " 'data/original/sub13/exp01/eeg/SP 110RMT r1/08-avg-csd.mat',\n",
       " 'data/original/sub13/exp02/eeg/SP 110RMT r1/08-avg-csd.mat',\n",
       " 'data/original/sub13/exp02/eeg/SP 110RMT r2/08-avg-csd.mat',\n",
       " 'data/original/sub13/exp02/eeg/SP 110RMT r3/08-avg-csd.mat',\n",
       " 'data/original/sub14/exp01/eeg/SP 110RMT r1/08-avg-csd.mat',\n",
       " 'data/original/sub14/exp01/eeg/SP 110RMT r2/08-avg-csd.mat',\n",
       " 'data/original/sub14/exp01/eeg/SP 110RMT r3/08-avg-csd.mat',\n",
       " 'data/original/sub15/exp01/eeg/SP 110RMT r1/08-avg-csd.mat',\n",
       " 'data/original/sub15/exp01/eeg/SP 110RMT r2/08-avg-csd.mat',\n",
       " 'data/original/sub15/exp01/eeg/SP 110RMT r3/08-avg-csd.mat',\n",
       " 'data/original/sub16/exp01/eeg/SP 110RMT r1/08-avg-csd.mat',\n",
       " 'data/original/sub16/exp01/eeg/SP 110RMT r2/08-avg-csd.mat',\n",
       " 'data/original/sub16/exp01/eeg/SP 110RMT r3/08-avg-csd.mat',\n",
       " 'data/original/sub17/exp01/eeg/SP 110RMT r1/08-avg-csd.mat',\n",
       " 'data/original/sub17/exp01/eeg/SP 110RMT r2/08-avg-csd.mat',\n",
       " 'data/original/sub17/exp01/eeg/SP 110RMT r3/08-avg-csd.mat',\n",
       " 'data/original/sub18/exp01/eeg/SP 110RMT r1/08-avg-csd.mat',\n",
       " 'data/original/sub18/exp01/eeg/SP 110RMT r2/08-avg-csd.mat',\n",
       " 'data/original/sub18/exp01/eeg/SP 110RMT r3/08-avg-csd.mat',\n",
       " 'data/original/sub19/exp01/eeg/SP 110RMT r1/08-avg-csd.mat',\n",
       " 'data/original/sub19/exp01/eeg/SP 110RMT r2/08-avg-csd.mat',\n",
       " 'data/original/sub19/exp01/eeg/SP 110RMT r3/08-avg-csd.mat',\n",
       " 'data/original/sub20/exp01/eeg/SP 110RMT r1/08-avg-csd.mat',\n",
       " 'data/original/sub20/exp01/eeg/SP 110RMT r2/08-avg-csd.mat',\n",
       " 'data/original/sub20/exp01/eeg/SP 110RMT r3/08-avg-csd.mat',\n",
       " 'data/original/sub21/exp01/eeg/SP 110RMT r1/08-avg-csd.mat',\n",
       " 'data/original/sub21/exp01/eeg/SP 110RMT r2/08-avg-csd.mat',\n",
       " 'data/original/sub21/exp01/eeg/SP 110RMT r3/08-avg-csd.mat',\n",
       " 'data/original/sub22/exp01/eeg/SP 110RMT r1/08-avg-csd.mat',\n",
       " 'data/original/sub22/exp01/eeg/SP 110RMT r2/08-avg-csd.mat',\n",
       " 'data/original/sub22/exp01/eeg/SP 110RMT r3/08-avg-csd.mat']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eegs = sorted(glob.glob('data/original/*/*/eeg/SP 110RMT r*/08-avg-csd.mat'))\n",
    "rejected_trials = [\n",
    "    {'sub': 'sub03', 'exp': 'exp01', 'run': 'r1', 'trial': '*'}, # We are using exp02 for this one\n",
    "    {'sub': 'sub03', 'exp': 'exp01', 'run': 'r2', 'trial': '*'}, # We are using exp02 for this one\n",
    "    {'sub': 'sub03', 'exp': 'exp01', 'run': 'r3', 'trial': '*'}, # We are using exp02 for this one\n",
    "    {'sub': 'sub05', 'exp': 'exp01', 'run': 'r1', 'trial': '*'}, # BAD MEP.\n",
    "    {'sub': 'sub05', 'exp': 'exp01', 'run': 'r2', 'trial': '*'}, # BAD MEP.\n",
    "    {'sub': 'sub17', 'exp': 'exp01', 'run': 'r1', 'trial': 0}, # Session log mentions there is no pulse.\n",
    "    {'sub': 'sub17', 'exp': 'exp01', 'run': 'r1', 'trial': 1}, # Session log mentions there is no pulse.\n",
    "    {'sub': 'sub17', 'exp': 'exp01', 'run': 'r1', 'trial': 48}, # Session log mentions there is no pulse.\n",
    "    {'sub': 'sub17', 'exp': 'exp01', 'run': 'r1', 'trial': 49}, # Session log mentions there is no pulse.\n",
    "    {'sub': 'sub22', 'exp': 'exp01', 'run': 'r1', 'trial': 17}, # Session log mentions there is a problem.\n",
    "    {'sub': 'sub22', 'exp': 'exp01', 'run': 'r1', 'trial': 18}, # Session log mentions there is a problem.\n",
    "]\n",
    "eegs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic I/O and conversions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read EEG trials for MAT file. Returns a list of dataframes. \n",
    "# The dataframes contain three columns: C3, C4 and time.\n",
    "def read_trials_from_mat(filename):\n",
    "    x = loadmat(filename)\n",
    "    mat_trials = x['dat'][0][0][3][0]\n",
    "    trials = []\n",
    "    time = np.linspace(-1000, 1000, len(mat_trials[0][0]))\n",
    "    for mat_trial in mat_trials:\n",
    "        trials.append(pd.DataFrame({\n",
    "            'FC5': mat_trial[0], \n",
    "            'FC3': mat_trial[1], \n",
    "            'FC1': mat_trial[2], \n",
    "            'C5': mat_trial[3], \n",
    "            'C3': mat_trial[4], \n",
    "            'C1': mat_trial[5], \n",
    "            'CP5': mat_trial[6], \n",
    "            'CP3': mat_trial[7], \n",
    "            'CP1': mat_trial[8], \n",
    "            'FC6': mat_trial[9], \n",
    "            'FC4': mat_trial[10], \n",
    "            'FC2': mat_trial[11], \n",
    "            'C6': mat_trial[12], \n",
    "            'C4': mat_trial[13], \n",
    "            'C2': mat_trial[14], \n",
    "            'CP6': mat_trial[15], \n",
    "            'CP4': mat_trial[16], \n",
    "            'CP2': mat_trial[17], \n",
    "            'time': time\n",
    "        }))\n",
    "    return trials\n",
    "\n",
    "# Take the last segments of selected length from trials. By default, \n",
    "# it will return last 500ms of the trials.\n",
    "def crop_trials(trial_list, duration_millis=500, sampling_rate=2048):\n",
    "    new_trial_list = []\n",
    "    for trial in trial_list:\n",
    "        samples_to_pick = duration_millis * sampling_rate / 1000\n",
    "        new_trial_list.append(trial.tail(int(samples_to_pick)))\n",
    "    return new_trial_list, samples_to_pick\n",
    "\n",
    "# Returns the cropped MEP between two time points.\n",
    "def crop_mep_region(mep_frame, crop_start=0.211, crop_end=0.4):\n",
    "    multiplier = 7499 / 1.4998\n",
    "    start = int(crop_start * multiplier)\n",
    "    end = int(crop_end * multiplier)\n",
    "    mep_cropped = mep_frame.iloc[start:end, :]\n",
    "    time = mep_frame.iloc[start:end, :]\n",
    "    return mep_cropped\n",
    "\n",
    "# The MEP files do not have a consistent column name. \n",
    "# For some files, the column is named L APB and for others, its APB.\n",
    "# This function returns the appropriate column name which contain \n",
    "# the amplitudes.\n",
    "def get_apb_column_name(mep_frame):\n",
    "    if 'L APB' in mep_frame:\n",
    "        return 'L APB'\n",
    "    else:\n",
    "        return 'APB'\n",
    "\n",
    "# Reads MEP file from disk and returns it as a dataframe.\n",
    "def open_mep_as_df(path):\n",
    "    fileMep = open(path, \"r+\")\n",
    "    mep_frames = fileMep.read().split('\\n\\n')\n",
    "    df_list = []\n",
    "    for mep_frame in mep_frames:\n",
    "        df_list.append(pd.read_csv(StringIO(mep_frame), '\\t'))\n",
    "    return df_list\n",
    "\n",
    "# Get the corresponding MEP path from an EEG file path.\n",
    "def get_mep_path(eeg_path):\n",
    "    segments = eeg_path.split('/')\n",
    "    segments[4] = 'mep'\n",
    "    segments = segments[:-1]\n",
    "    mep_path = '/'.join(segments) + '/*.txt'\n",
    "    mep_path = glob.glob(mep_path)[0]\n",
    "    return mep_path\n",
    "\n",
    "# Calculate the MEP amplitude peak to peak.\n",
    "def calculate_mep_size(mep_frame, latency, duration):\n",
    "    mep_cropped = crop_mep_region(mep_frame, latency, latency + duration)\n",
    "    apb_name = get_apb_column_name(mep_frame)\n",
    "    max_row = mep_frame.iloc[mep_cropped.idxmax(axis=0)[apb_name]]\n",
    "    min_row = mep_frame.iloc[mep_cropped.idxmin(axis=0)[apb_name]]\n",
    "    mep_size = max_row[apb_name] - min_row[apb_name]\n",
    "    return mep_size, min_row, max_row\n",
    "\n",
    "# Classifies the MEP amplitude into two classes: large (if amplitude is > 0.5) and small.\n",
    "def get_mep_category_absolute_binary(mep_size):\n",
    "    if mep_size <= .5:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "# Classifies the MEP amplitude into two percentile classes (largest 50% is considered large).\n",
    "def calculate_mep_categories_binary(mep_sizes):\n",
    "    p1 = np.percentile(mep_sizes, 50)\n",
    "    cat = np.ones(len(mep_sizes)) * (mep_sizes >= p1)\n",
    "    return cat\n",
    "\n",
    "# Read latency and durations from disk (CSV file). \n",
    "# These values were manually selected using Signals software.\n",
    "def read_latency_duration(eeg_path):\n",
    "    segments = eeg_path.split('/')\n",
    "    sub = segments[2]\n",
    "    exp = segments[3]\n",
    "    run = segments[5]\n",
    "    path = 'data/original/' + sub + '/' + exp + '/mep/' + run + '/01-ld.csv'\n",
    "    files = glob.glob(path)\n",
    "    if len(files) < 1:\n",
    "        return False\n",
    "    fileMep = open(path, \"r+\")\n",
    "    lines = fileMep.read().split('\\n')\n",
    "    df_ld = []\n",
    "    for frame_txt in lines:\n",
    "        if 'Frame' in frame_txt:\n",
    "            continue\n",
    "        segments = frame_txt.split('\\t')\n",
    "        if len(segments) >= 4:\n",
    "            df_ld.append({\n",
    "                'trial_num': int(segments[0])-1,\n",
    "                'latency': float(segments[2]),\n",
    "                'duration': float(segments[3]) - float(segments[2])\n",
    "            })\n",
    "    return pd.DataFrame(df_ld)\n",
    "\n",
    "# Calculate MEP area starting from the latency time point and ends at latency + duration.\n",
    "# Trapezoidal integration is used to calculate this value.\n",
    "def calculate_mep_area(mep_frame, latency, duration, plot=False):\n",
    "    apb_name = get_apb_column_name(mep_frame)\n",
    "    mep_frame = mep_frame[(mep_frame['s'] >= latency) * (mep_frame['s'] <= latency + duration)]\n",
    "    amplitude = mep_frame[apb_name]\n",
    "    amplitude = np.abs(amplitude)\n",
    "    time_diff = mep_frame['s'].iloc[1] - mep_frame['s'].iloc[0]\n",
    "    area = trapz(amplitude, dx=time_diff)\n",
    "    if (plot == True):\n",
    "        plt.plot(mep_frame['s'], amplitude)\n",
    "    return area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power and phase calculations\n",
    "\n",
    "## Phase calculation\n",
    "\n",
    "Channel is first band pass filtered (Blackman harris filter) within the given band (e.g. beta, mu etc.). Then Hilbert transformed data represents the phase in each time point.\n",
    "\n",
    "## Power calculation\n",
    "\n",
    "At first, channel is cropped within the region of interest (last 150ms before pulse). Then its resampled 500 Hz. Then power is computed using one of the three methods: Burg's method, Welch's method and Fourier's method. In our case, Burg's method is used. The other three methods were initially used to verify that the Burg's method is working correctly. For gamma band, the resampled signal was first notch filtered (Blackman harris filter) within 48Hz and 52Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blackman_harris_filter(channel, time, cutoffs, fs, numtaps=801):\n",
    "    b = signal.firwin(numtaps, cutoffs, window='blackmanharris', fs=fs)\n",
    "    filtered = signal.lfilter(b, 1, channel)\n",
    "    delay = 0.5 * (numtaps - 1) / fs\n",
    "    df = pd.DataFrame({\n",
    "        'time': time-delay,\n",
    "        'channel': filtered\n",
    "    })\n",
    "    return df\n",
    "\n",
    "def get_phase(channel, time, band, fs=4096, plot=False):\n",
    "    df_filtered = blackman_harris_filter(channel, time, [0.000001, band[0]], fs)\n",
    "    df_filtered = blackman_harris_filter(df_filtered['channel'].values, df_filtered['time'].values, band[1], fs)    \n",
    "    hilb = signal.hilbert(df_filtered[(df_filtered['time'] > -750) * (df_filtered['time'] < -1)]['channel'])\n",
    "    phase = np.angle(hilb, deg=True)\n",
    "    df_phase = pd.DataFrame(phase, columns=['phase'])\n",
    "    df_phase['time'] = df_filtered[(df_filtered['time'] > -750) * (df_filtered['time'] < -1)]['time'].values\n",
    "    return df_phase.iloc[-1]['phase'] + 180\n",
    "\n",
    "def get_power(channel, time, band, crop_start_millis=-150, fs=500, plot=False, method='pburg'):       \n",
    "    # Crop.\n",
    "    channel = channel[(time > crop_start_millis) * (time < -1)].values\n",
    "    time = time[(time > crop_start_millis) * (time < -1)].values\n",
    "\n",
    "    # Resample.\n",
    "    ts = time[1] - time[0]\n",
    "    secs = len(channel) * ts\n",
    "    secs = secs/1000\n",
    "    resampled = signal.resample(channel, int(secs*fs))\n",
    "    resampled_time = np.linspace(time[0], time[-1], len(resampled))\n",
    "    \n",
    "    # Filer if gamma region.\n",
    "    if 48 > band[0] and 48 < band[1]:\n",
    "        df_filtered = blackman_harris_filter(resampled, resampled_time, [48, 52], fs, numtaps=101)\n",
    "        resampled = df_filtered['channel']\n",
    "        resampled_time = df_filtered['time']\n",
    "    \n",
    "    # PSD.\n",
    "    try:\n",
    "        if method == 'welch':\n",
    "            # Welch method\n",
    "            freq, power = signal.welch(resampled, fs, nperseg=4 * fs, nfft=4 * fs)\n",
    "            freq_res = freq[1] - freq[0]\n",
    "            df_power = pd.DataFrame({'freq': freq, 'power': power})\n",
    "            df_power_in_band = df_power[(df_power['freq'] >= band[0]) * (df_power['freq'] <= band[1])]\n",
    "            mean_power = np.mean(df_power_in_band['power'])\n",
    "            # idx_band = np.logical_and(freq >= band[0], freq <= band[1])\n",
    "            # mean_power = simps(power[idx_band], dx=freq_res)\n",
    "        elif method == 'fft':\n",
    "            # FFT method\n",
    "            power = np.abs(np.fft.fft(resampled, n=500))\n",
    "            freq = np.linspace(0, fs, len(power))\n",
    "            df_power = pd.DataFrame({'freq': freq, 'power': power})\n",
    "            df_power_in_band = df_power[(df_power['freq'] >= band[0]) * (df_power['freq'] <= band[1])]\n",
    "            mean_power = np.mean(df_power_in_band['power'])\n",
    "        elif method == 'pburg':\n",
    "            # Burgs method\n",
    "            p = pburg(resampled, int(len(resampled)/2), sampling=fs, NFFT=4096)\n",
    "            power = p.psd\n",
    "            freq = np.linspace(0, fs, len(power))\n",
    "            df_power = pd.DataFrame({'freq': freq, 'power': power})\n",
    "            df_power = df_power[df_power['freq'] < fs/2]\n",
    "            df_power_in_band = df_power[(df_power['freq'] >= band[0]) * (df_power['freq'] <= band[1])]\n",
    "            mean_power = np.mean(df_power_in_band['power'])\n",
    "    except:\n",
    "        return 0\n",
    "    return mean_power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute powers and phases of all trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_power_phase(trial, channel):    \n",
    "    phase_power_dict = {}     \n",
    "    \n",
    "    if channel == 'C4':\n",
    "        channel_avg = trial[channel] + trial['FC6'] + trial['FC4'] + trial['FC2'] + trial['C6'] + trial['C4'] + trial['C2'] + trial['CP6'] + trial['CP4'] + trial['CP2']\n",
    "    else:\n",
    "        channel_avg = trial[channel] + trial['FC5'] + trial['FC3'] + trial['FC1'] + trial['C5'] + trial['C3'] + trial['C1'] + trial['CP5'] + trial['CP3'] + trial['CP1']\n",
    "    channel_avg = channel_avg / 9\n",
    "        \n",
    "    \n",
    "    phase_power_dict['theta_phase'] = get_phase(channel_avg, trial['time'], [3.5, 8])\n",
    "    phase_power_dict['mu_phase'] = get_phase(channel_avg, trial['time'], [8, 12])\n",
    "    phase_power_dict['beta_phase'] = get_phase(channel_avg, trial['time'], [13, 30])\n",
    "    phase_power_dict['gamma_phase'] = get_phase(channel_avg, trial['time'], [30, 80])\n",
    "    phase_power_dict['low_beta_phase'] = get_phase(channel_avg, trial['time'], [12, 20])\n",
    "    phase_power_dict['high_beta_phase'] = get_phase(channel_avg, trial['time'], [20, 30])\n",
    "    phase_power_dict['low_gamma_phase'] = get_phase(channel_avg, trial['time'], [30, 46])\n",
    "    phase_power_dict['high_gamma_phase'] = get_phase(channel_avg, trial['time'], [46, 70])\n",
    "\n",
    "    phase_power_dict['theta_power'] = get_power(channel_avg, trial['time'], [3.5, 8])\n",
    "    phase_power_dict['mu_power'] = get_power(channel_avg, trial['time'], [8, 12])\n",
    "    phase_power_dict['beta_power'] = get_power(channel_avg, trial['time'], [13, 30])\n",
    "    phase_power_dict['gamma_power'] = get_power(channel_avg, trial['time'], [30, 80])\n",
    "    phase_power_dict['low_beta_power'] = get_power(channel_avg, trial['time'], [12, 20])\n",
    "    phase_power_dict['high_beta_power'] = get_power(channel_avg, trial['time'], [20, 30])\n",
    "    phase_power_dict['low_gamma_power'] = get_power(channel_avg, trial['time'], [30, 46])\n",
    "    phase_power_dict['high_gamma_power'] = get_power(channel_avg, trial['time'], [46, 70])\n",
    "    return phase_power_dict\n",
    "        \n",
    "def process_trials(eeg_path):\n",
    "    sub = eeg_path.split('/')[2]\n",
    "    exp = eeg_path.split('/')[3]\n",
    "    run = eeg_path.split('/')[5]\n",
    "    \n",
    "    files = glob.glob(os.path.dirname(eeg_path) + \"/08-avg-csd.mat\")\n",
    "    if (len(files) == 0):\n",
    "        return []\n",
    "    \n",
    "    trials = read_trials_from_mat(os.path.dirname(eeg_path) + \"/08-avg-csd.mat\")\n",
    "\n",
    "    # Calculate CMAP.\n",
    "    try:\n",
    "        cmap_max, cmap_min = find_cmap_peaks(read_cmap(get_cmap_path(eeg_path)))\n",
    "        cmap = cmap_max - cmap_min\n",
    "    except:\n",
    "        cmap = 0\n",
    "\n",
    "    # Read latency duration\n",
    "    df_ld = read_latency_duration(eeg_path)\n",
    "    if isinstance(df_ld, pd.DataFrame) == False:\n",
    "        return []\n",
    "    \n",
    "    # Calculate powers and phases. And combine the results in a df list.\n",
    "    power_phase_list = []\n",
    "    for trial_num in df_ld['trial_num'].values:\n",
    "        if len(trials)-1 < trial_num:\n",
    "            continue\n",
    "        trial = trials[trial_num]\n",
    "    \n",
    "        # Ignore rejected trials.\n",
    "        break_loop = False\n",
    "        for rejected in rejected_trials:\n",
    "            if (sub == rejected['sub']) and (exp == rejected['exp']) and (rejected['run'] == run.split(' ')[2]) and ((rejected['trial'] == trial_num) or (rejected['trial'] == '*')):\n",
    "                print('Rejecting ' + sub + '/' + exp + '/' + run + '/' + str(rejected['trial']))\n",
    "                break_loop = True\n",
    "                break\n",
    "        if break_loop == True or df_ld[df_ld['trial_num'] == trial_num].shape[0] == 0:\n",
    "            continue\n",
    "        \n",
    "        # Calculate phase and power.\n",
    "        print('Processing ' + sub + '/' + exp + '/' + run + '/' + str(trial_num))\n",
    "        try:\n",
    "            if sub in ['sub13', 'sub02']:\n",
    "                channel = 'C4'\n",
    "            else:\n",
    "                channel = 'C3'\n",
    "            power = calculate_power_phase(trial, channel)\n",
    "        except ValueError as e:\n",
    "            print('Skipping ' + sub + '/' + exp + '/' + run + '/' + str(trial_num) + ': ' + str(e))\n",
    "            continue\n",
    "\n",
    "        latency = df_ld[df_ld['trial_num'] == trial_num].iloc[0]['latency']\n",
    "        duration = df_ld[df_ld['trial_num'] == trial_num].iloc[0]['duration']\n",
    "        mep_frame = open_mep_as_df(get_mep_path(eeg_path))[trial_num]\n",
    "        mep_size, _, _ = calculate_mep_size(mep_frame, latency, duration)\n",
    "        power_phase_dict = power\n",
    "        power_phase_dict['sub'] = sub\n",
    "        power_phase_dict['exp'] = exp\n",
    "        power_phase_dict['run'] = run\n",
    "        power_phase_dict['trial_num'] = trial_num\n",
    "        power_phase_dict['cmap'] = cmap\n",
    "        power_phase_dict['mep_size'] = mep_size\n",
    "        power_phase_dict['mep_latency'] = latency - 0.20\n",
    "        power_phase_dict['mep_duration'] = duration\n",
    "        power_phase_dict['mep_area'] = calculate_mep_area(mep_frame, latency, duration)\n",
    "        \n",
    "        power_phase_dict['rejected'] = False\n",
    "        for rejected in rejected_trials:\n",
    "            if (sub == rejected['sub']) and (exp == rejected['exp']) and (rejected['run'] == run.split(' ')[2]) and ((rejected['trial'] == trial_num) or (rejected['trial'] == '*')):\n",
    "                power_phase_dict['rejected'] = True\n",
    "                break\n",
    "\n",
    "        power_phase_list.append(power_phase_dict)\n",
    "    return power_phase_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start processing in all cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96ce85ccc3f74fbc9f2187e8a17709af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=77), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_cores = multiprocessing.cpu_count()-2\n",
    "results = Parallel(n_jobs=num_cores)(delayed(process_trials)(eeg_path) for eeg_path in tqdm_notebook(eegs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the powers and phases in a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2863, 26)\n"
     ]
    }
   ],
   "source": [
    "# Map the subject numbers with names.\n",
    "sub_map = {\n",
    "    'sub01': 'Terry Baedon',\n",
    "    'sub02': 'David Brown',\n",
    "    'sub03': 'Sarah Brunet',\n",
    "    'sub04': 'Lynette Gallaty',\n",
    "    'sub05': 'Mana Higashihara',\n",
    "    'sub06': 'Tim Howells',\n",
    "    'sub07': 'Merolene Pirsarkiewicz',\n",
    "    'sub08': 'Steve Vucic',\n",
    "    'sub09': 'Hayeley Turnbull',\n",
    "    'sub10': 'Nimeshan Geevasinga',\n",
    "    'sub11': 'Amarissa M',\n",
    "    'sub12': 'Marshall Owen',\n",
    "    'sub13': 'Stephen Schebeci',\n",
    "    'sub14': 'Matt Silsby',\n",
    "    'sub15': 'Carlos Brito',\n",
    "    'sub16': 'Alistair McEwan',\n",
    "    'sub17': 'Toni Mathieson',\n",
    "    'sub18': 'Karen Robertson',\n",
    "    'sub19': 'Julie Terry',\n",
    "    'sub20': 'Natalie Terry',\n",
    "    'sub21': 'Raquib-ul Alam',\n",
    "    'sub22': 'Lin Gavin',\n",
    "}\n",
    "\n",
    "df_powers = []\n",
    "for result in results:\n",
    "    if len(result) == 0:\n",
    "        continue\n",
    "    for trial in result:\n",
    "        df_powers.append(trial)\n",
    "len(df_powers)\n",
    "\n",
    "df_power = pd.DataFrame(df_powers)\n",
    "print(df_power.shape)\n",
    "\n",
    "df_power['name'] = df_power.apply(lambda x: sub_map[x['sub']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_power['sub_exp'] = df_power['sub'] + \"_\" + df_power['exp']\n",
    "df_power = df_power[~df_power['sub_exp'].isin(['sub04_exp01', 'sub14_exp01'])]\n",
    "df_power.to_excel('148-csd-avg-v1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
