{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/raquib/anaconda3/envs/tmseeg/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/raquib/anaconda3/envs/tmseeg/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "from io import StringIO\n",
    "import mne\n",
    "from mne.io import read_raw_eeglab, read_epochs_eeglab\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from scipy import fftpack\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "# from tqdm import tqdm, tqdm_notebook\n",
    "from tqdm.notebook import tqdm\n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from livelossplot.tf_keras import PlotLossesCallback\n",
    "\n",
    "import sklearn.model_selection\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "import multiprocessing\n",
    "from tpot import TPOTRegressor\n",
    "from oct2py import octave\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from joblib import wrap_non_picklable_objects\n",
    "import json\n",
    "import pickle\n",
    "import os.path\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import timeit\n",
    "from skimage.transform import resize\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, optimizers, callbacks\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.genmod import bayes_mixed_glm as glm\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import RFECV\n",
    "from spectrum import arburg, arma2psd, pburg\n",
    "import pylab\n",
    "from scipy.signal import find_peaks, butter\n",
    "from scipy.integrate import simps\n",
    "from scipy.io import loadmat\n",
    "from numpy import trapz\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power and phase calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blackman_harris_filter(channel, time, cutoffs, fs, numtaps=801):\n",
    "    b = signal.firwin(numtaps, cutoffs, window='blackmanharris', fs=fs)\n",
    "    filtered = signal.lfilter(b, 1, channel)\n",
    "    delay = 0.5 * (numtaps - 1) / fs\n",
    "    df = pd.DataFrame({\n",
    "        'time': time-delay,\n",
    "        'channel': filtered\n",
    "    })\n",
    "    return df\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, btype='bandpass', order=2):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype=btype)\n",
    "    y = signal.lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "def get_phase(channel, time, band, fs=4096, plot=False, filter_type='butter', start_time_ms=-750, stop_time_ms=-2):\n",
    "    if filter_type=='butter':\n",
    "        df_filtered = pd.DataFrame({'channel': butter_bandpass_filter(channel, band[0], band[1], 4096), 'time': time})\n",
    "    else:\n",
    "        df_filtered = blackman_harris_filter(channel, time, [0.000001, band[0]], fs)\n",
    "        df_filtered = blackman_harris_filter(df_filtered['channel'].values, df_filtered['time'].values, band[1], fs)    \n",
    "    \n",
    "    hilb = signal.hilbert(df_filtered[(df_filtered['time'] > start_time_ms) * (df_filtered['time'] < stop_time_ms)]['channel'])\n",
    "    phase = np.angle(hilb, deg=True)\n",
    "    df_phase = pd.DataFrame(phase, columns=['phase'])\n",
    "    df_phase['time'] = df_filtered[(df_filtered['time'] > start_time_ms) * (df_filtered['time'] < stop_time_ms)]['time'].values\n",
    "    \n",
    "    if plot == True:\n",
    "        fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(13,10))\n",
    "        ax1.plot(time, channel)\n",
    "        ax1.set_xlabel('Time')\n",
    "        ax1.set_ylabel('Amplitude')\n",
    "        ax1.set_title('Signal')\n",
    "        \n",
    "        ax2.plot(df_filtered['time'], df_filtered['channel'])\n",
    "        ax2.set_title('Filtered channel')\n",
    "        ax2.set_xlabel('Time')\n",
    "        ax2.set_ylabel('Filtered channel')\n",
    "        \n",
    "        freq, power = signal.welch(df_filtered['channel'], 4096, nperseg=4096/2, nfft=4096/2)\n",
    "        freq_res = freq[1] - freq[0]\n",
    "        power = np.log(power)\n",
    "        ax3.plot(freq[freq < 200], power[freq < 200])\n",
    "        ax3.set_title('Power spectrum')\n",
    "        ax3.set_xlabel('Frequency')\n",
    "        ax3.set_ylabel('Power')\n",
    "        \n",
    "        ax4.plot(df_phase['time'], df_phase['phase'])\n",
    "        ax4.plot(df_phase.iloc[-1]['time'], df_phase.iloc[-1]['phase'], 'o')\n",
    "        ax4.set_title('Phase')\n",
    "        ax4.set_xlabel('Time')\n",
    "        ax4.set_ylabel('Phase')\n",
    "        plt.tight_layout()\n",
    "    # df_phase = df_phase[df_phase['time'] <= -20]\n",
    "    return df_phase.iloc[-1]['phase'] + 180\n",
    "\n",
    "def get_power(channel, time, crop_start_millis=-150, fs=500, plot=False, method='pburg'):       \n",
    "    # Crop.\n",
    "    channel = channel[(time > crop_start_millis) * (time < -1)].values\n",
    "    time = time[(time > crop_start_millis) * (time < -1)].values\n",
    "\n",
    "    # Resample.\n",
    "    ts = time[1] - time[0]\n",
    "    secs = len(channel) * ts\n",
    "    secs = secs/1000\n",
    "    resampled = signal.resample(channel, int(secs*fs))\n",
    "    resampled_time = np.linspace(time[0], time[-1], len(resampled))\n",
    "    \n",
    "    # Filer if gamma region.\n",
    "#     if 48 > band[0] and 48 < band[1]:\n",
    "#     if filter_type == 'butter':\n",
    "#         resampled = butter_bandpass_filter(resampled, 48, 52, fs, 'bandstop')\n",
    "#         resampled_time = resampled_time\n",
    "#     else:\n",
    "#         df_filtered = blackman_harris_filter(resampled, resampled_time, [48, 52], fs, numtaps=101)\n",
    "#         resampled = df_filtered['channel']\n",
    "#         resampled_time = df_filtered['time']\n",
    "    \n",
    "    # PSD.\n",
    "    try:\n",
    "        if method == 'welch':\n",
    "            # Welch method\n",
    "            freq, power = signal.welch(resampled, fs)\n",
    "            freq_res = freq[1] - freq[0]\n",
    "            df_power = pd.DataFrame({'freq': freq, 'power': power})\n",
    "        elif method == 'fft':\n",
    "            # FFT method\n",
    "            power = np.abs(np.fft.fft(resampled, n=500))\n",
    "            freq = np.linspace(0, fs, len(power))\n",
    "            df_power = pd.DataFrame({'freq': freq, 'power': power})\n",
    "        elif method == 'pburg':\n",
    "            # Burgs method\n",
    "            p = pburg(resampled, int(len(resampled)*0.25), sampling=fs, NFFT=4096)\n",
    "            power = p.psd\n",
    "            freq = np.linspace(0, fs, len(power))\n",
    "            df_power = pd.DataFrame({'freq': freq, 'power': power})\n",
    "            df_power = df_power[df_power['freq'] < fs/2]\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "        return 0\n",
    "\n",
    "    return df_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg_files = glob.glob('data/dataset2/alcoholism/*/*.gz')\n",
    "print(len(eeg_files))\n",
    "eeg_files[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trial(trial_file):\n",
    "    # Read the gzip file.\n",
    "    with gzip.open(trial_file, 'rb') as f:\n",
    "        trial_str = str(f.read(), 'utf-8')\n",
    "    \n",
    "    # Parse the file.\n",
    "    df_long = []\n",
    "    lines = trial_str.split('\\n')\n",
    "    if len(lines) < 10:\n",
    "        return None\n",
    "    sub = lines[0].split(' ')[1].split('.')[0].strip()\n",
    "    alcoholic = sub[3] == 'a'\n",
    "    condition = lines[3].split(',')[0][2:].strip()\n",
    "    for line in lines[5:]:\n",
    "        segments = line.split(' ')\n",
    "        if segments[0] == '#' or len(segments) < 3:\n",
    "            continue\n",
    "        df_long.append({\n",
    "            'subject': sub,\n",
    "            'alcoholic': alcoholic,\n",
    "            'condition': condition,\n",
    "            'trial': int(segments[0]),\n",
    "            'channel': segments[1],\n",
    "            'sample': int(segments[2]),\n",
    "            'value': float(segments[3])\n",
    "        })\n",
    "    df_long = pd.DataFrame(df_long)\n",
    "    \n",
    "    # Convert to wide format.\n",
    "    df_wide = df_long.pivot_table(values=['value'], index=['subject', 'trial', 'sample', 'condition', 'alcoholic'], columns=['channel'])\n",
    "    df_wide.columns = df_wide.columns.to_series().str[1]\n",
    "    df_wide = df_wide.reset_index()\n",
    "    \n",
    "    # Add time column.\n",
    "    df_wide['time'] = np.linspace(0, 1, df_wide.shape[0])\n",
    "    \n",
    "    # Remove errors.\n",
    "    df_wide = df_wide[~df_wide['condition'].str.contains(\"err\", case=False)]\n",
    "    \n",
    "    return df_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trials as csv files for MATLAB.\n",
    "cols = ['AF1', 'AF2', 'AF7', 'AF8', 'AFZ', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'CP1', 'CP2', 'CP3', 'CP4', 'CP5', 'CP6', 'CPZ', 'CZ', 'F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7', 'F8', 'FC1', 'FC2', 'FC3', 'FC4', 'FC5', 'FC6', 'FCZ', 'FP1', 'FP2', 'FPZ', 'FT7', 'FT8', 'FZ', 'O1', 'O2', 'OZ', 'P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'P8', 'PO1', 'PO2', 'PO7', 'PO8', 'POZ', 'PZ', 'T7', 'T8', 'TP7', 'TP8', 'X', 'Y', 'nd']\n",
    "def export_trials_csv(sub):\n",
    "    trial_files = glob.glob(sub + '*.gz')\n",
    "    for trial_file in trial_files:\n",
    "        df_trial = get_trial(trial_file)\n",
    "        if df_trial is not None and df_trial.shape[0] > 0:\n",
    "            filename = 'data/dataset2/parsed-156/' + df_trial.iloc[0]['subject']\n",
    "            if not os.path.exists(filename):\n",
    "                os.makedirs(filename)\n",
    "            filename = filename + '/trial-' + str(df_trial.iloc[0]['trial']) + '.csv'\n",
    "            df_trial = df_trial[cols]\n",
    "            df_trial.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "609cc178f4a747f18a2cc0242e2d8540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=122.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subs = sorted(glob.glob('data/dataset2/original/*/'))\n",
    "num_cores = multiprocessing.cpu_count() - 2\n",
    "Parallel(n_jobs=num_cores)(delayed(export_trials_csv)(sub) for sub in tqdm(subs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute power for trials\n",
    "def process_trial(trial_file):\n",
    "    # Read trial and compute powers\n",
    "    df_trial = pd.read_csv(trial_file)\n",
    "    freq, power = signal.welch(df_trial['C3'].values, 256)\n",
    "    df_psd = pd.DataFrame({'freq': freq, 'power': 10*np.log10(power)})\n",
    "\n",
    "    # Read subject file to extract alcoholism and condition of the trials\n",
    "    subject = trial_file.split('/')[2]\n",
    "    trial = trial_file.split('/')[3].split('-')[1].split('.')[0]\n",
    "    df_sub = pd.read_csv('data/alcoholism-01-parsed/' + subject + '.csv')\n",
    "\n",
    "    # Append to dataframe\n",
    "    return {\n",
    "        'subject': subject,\n",
    "        'trial': trial,\n",
    "        'condition': df_sub[df_sub['trial'] == int(trial)].iloc[0]['condition'],\n",
    "        'alcoholic': df_sub.iloc[0]['alcoholic'],\n",
    "        'theta_power': df_psd[(df_psd['freq'] >= 4) * (df_psd['freq'] < 8)]['power'].mean(),\n",
    "        'mu_power': df_psd[(df_psd['freq'] >= 8) * (df_psd['freq'] < 12)]['power'].mean(),\n",
    "        'beta_power': df_psd[(df_psd['freq'] >= 13) * (df_psd['freq'] < 30)]['power'].mean(),\n",
    "        'gamma_power': df_psd[(df_psd['freq'] >= 30) * (df_psd['freq'] < 80)]['power'].mean(),\n",
    "    }\n",
    "\n",
    "# Run multithread processing\n",
    "trial_files = sorted(glob.glob('data/alcoholism-02-for-matlab/*/*.csv'))\n",
    "num_cores = multiprocessing.cpu_count() - 2\n",
    "results = Parallel(n_jobs=num_cores)(delayed(process_trial)(trial_file) for trial_file in tqdm(trial_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all results\n",
    "df_power = []\n",
    "for result in results:\n",
    "    df_power.append(result)\n",
    "df_power = pd.DataFrame(df_power)\n",
    "\n",
    "# Print result\n",
    "print(df_power.shape)\n",
    "df_power.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melt = pd.melt(df_power, id_vars=['subject', 'condition', 'trial', 'alcoholic'], value_vars=['theta_power', 'mu_power', 'beta_power', 'gamma_power'])\n",
    "df_melt = df_melt[df_melt['condition'].isin(['S1 obj', 'S2 nomatch', 'S2 match'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2,figsize=(13,3))\n",
    "sns.boxplot(x=\"variable\", y=\"value\", hue='condition', data=df_melt[df_melt['alcoholic'] == True], ax=axs[0])\n",
    "axs[0].set_title('Alcoholic')\n",
    "sns.boxplot(x=\"variable\", y=\"value\", hue='condition', data=df_melt[df_melt['alcoholic'] == False], ax=axs[1])\n",
    "axs[1].set_title('Non-alcoholic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=\"variable\", y=\"value\", hue='alcoholic', data=df_melt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = df_melt['subject'].unique()\n",
    "for sub in tqdm(subs[np.linspace(0,120,11).astype(int)]):\n",
    "    df_sub = df_melt[df_melt['subject'] == sub]\n",
    "    fig,axs=plt.subplots(1,2,figsize=(13,3))\n",
    "    df_fullsub = pd.read_csv('data/alcoholism-01-parsed/' + sub + '.csv')\n",
    "    sns.lineplot(x=\"time\", y=\"C3\", data=df_fullsub, ax=axs[0])\n",
    "    axs[0].set_xlabel('Time (s)')\n",
    "    axs[0].set_ylabel('Average C3 uV')\n",
    "    axs[0].set_xlim([0, 1])\n",
    "    sns.boxplot(x=\"variable\", y=\"value\", hue='condition', data=df_sub, ax=axs[1])\n",
    "    axs[1].set_xlabel('Bands')\n",
    "    axs[1].set_ylabel('C3 Power (dB)')\n",
    "    plt.suptitle(df_sub.iloc[0]['subject'] + ' - alcoholic = ' + str(df_sub.iloc[0]['alcoholic']))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_files = sorted(glob.glob('data/alcoholism-02-for-matlab/*/*.csv'))\n",
    "for trial_ind in tqdm(np.linspace(0,len(trial_files)-2,10).astype(int)):\n",
    "    trial_file = trial_files[trial_ind]\n",
    "    sub = trial_file.split('/')[2]\n",
    "    trial = trial_file.split('/')[3].split('-')[1].split('.')[0]\n",
    "    df_trial = pd.read_csv(trial_file)\n",
    "    freq, power = signal.welch(df_trial['C3'].values, 256)\n",
    "    df_psd = pd.DataFrame({'freq': freq, 'power': 10*np.log10(power)})\n",
    "    df_psd = df_psd[df_psd['freq'] <= 60]\n",
    "    df_psd = df_psd[df_psd['freq'] >=4]\n",
    "    df_trial['time'] = np.linspace(0, 1, df_trial.shape[0])\n",
    "    \n",
    "    fig, axs=plt.subplots(1,2,figsize=(13,3))\n",
    "    sns.lineplot(x=\"time\", y=\"C3\", data=df_trial, ax=axs[0])\n",
    "    axs[0].set_xlabel('Time (s)')\n",
    "    axs[0].set_ylabel('C3 (uV)')\n",
    "    axs[0].set_xlim([0, 1])\n",
    "    \n",
    "    axs[1].plot(df_psd['freq'], df_psd['power'])\n",
    "    axs[1].set_xlabel('Frequency (Hz)')\n",
    "    axs[1].set_ylabel('C3 Power (dB)')\n",
    "    axs[1].set_xlim([4, 60])\n",
    "    plt.suptitle(sub + \" - trial \" + trial)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
