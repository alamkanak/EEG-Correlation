{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raquib/anaconda3/envs/tmseeg/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "Using TensorFlow backend.\n",
      "/home/raquib/anaconda3/envs/tmseeg/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/raquib/anaconda3/envs/tmseeg/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/raquib/anaconda3/envs/tmseeg/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/raquib/anaconda3/envs/tmseeg/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/raquib/anaconda3/envs/tmseeg/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/raquib/anaconda3/envs/tmseeg/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/raquib/anaconda3/envs/tmseeg/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/raquib/anaconda3/envs/tmseeg/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/raquib/anaconda3/envs/tmseeg/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/raquib/anaconda3/envs/tmseeg/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/raquib/anaconda3/envs/tmseeg/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/raquib/anaconda3/envs/tmseeg/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/raquib/anaconda3/envs/tmseeg/lib/python3.7/site-packages/pyparsing.py:2927: FutureWarning: Possible set intersection at position 3\n",
      "  self.re = re.compile( self.reString )\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import glob\n",
    "import pandas as pd\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "from io import StringIO\n",
    "import mne\n",
    "from mne.io import read_raw_eeglab, read_epochs_eeglab\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from livelossplot.tf_keras import PlotLossesCallback\n",
    "\n",
    "import autosklearn.regression\n",
    "import sklearn.model_selection\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "import multiprocessing\n",
    "from tpot import TPOTRegressor\n",
    "from oct2py import octave\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from joblib import wrap_non_picklable_objects\n",
    "import json\n",
    "import pickle\n",
    "import os.path\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import timeit\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: function /home/raquib/Documents/MATLAB/eeglab2019_0/functions/sigprocfunc/quantile.m shadows a core library function\n"
     ]
    }
   ],
   "source": [
    "eeglab_path = '/home/raquib/Documents/MATLAB/eeglab2019_0/functions/'\n",
    "octave.addpath(eeglab_path + 'guifunc');\n",
    "octave.addpath(eeglab_path + 'popfunc');\n",
    "octave.addpath(eeglab_path + 'adminfunc');\n",
    "octave.addpath(eeglab_path + 'sigprocfunc');\n",
    "octave.addpath(eeglab_path + 'miscfunc');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "experiment = 'data/original/*/*'\n",
    "meps = sorted(glob.glob(experiment + '/mep/*/*.txt'))\n",
    "mep_present = len(meps) > 0\n",
    "eegs = sorted(glob.glob(experiment + '/eeg/*/clean-prestimulus.set'))\n",
    "eeg_present = len(eegs) > 0\n",
    "cmaps = sorted(glob.glob(experiment + '/cmap/*.xlsx'))\n",
    "cmap_present = len(cmaps) > 0\n",
    "all_present = mep_present and eeg_present and cmap_present\n",
    "print(all_present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG count: 44\n",
      "MEP count: 77\n",
      "CMAP count: 22\n"
     ]
    }
   ],
   "source": [
    "print('EEG count: ' + str(len(eegs)))\n",
    "print('MEP count: ' + str(len(meps)))\n",
    "print('CMAP count: ' + str(len(cmaps)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/original/sub03/exp01/eeg/SP 110RMT r1/clean-prestimulus.set',\n",
       " 'data/original/sub03/exp01/eeg/SP 110RMT r2/clean-prestimulus.set',\n",
       " 'data/original/sub03/exp01/eeg/SP 110RMT r3/clean-prestimulus.set',\n",
       " 'data/original/sub03/exp02/eeg/SP 110RMT r1/clean-prestimulus.set',\n",
       " 'data/original/sub03/exp02/eeg/SP 110RMT r2/clean-prestimulus.set',\n",
       " 'data/original/sub03/exp03/eeg/SP 110RMT r1/clean-prestimulus.set',\n",
       " 'data/original/sub03/exp03/eeg/SP 110RMT r2/clean-prestimulus.set',\n",
       " 'data/original/sub03/exp03/eeg/SP 110RMT r3/clean-prestimulus.set',\n",
       " 'data/original/sub04/exp01/eeg/SP 110RMT r1/clean-prestimulus.set',\n",
       " 'data/original/sub04/exp01/eeg/SP 110RMT r2/clean-prestimulus.set',\n",
       " 'data/original/sub04/exp01/eeg/SP 110RMT r3/clean-prestimulus.set',\n",
       " 'data/original/sub05/exp01/eeg/SP 110RMT r3/clean-prestimulus.set',\n",
       " 'data/original/sub05/exp02/eeg/SP 120RMT r2/clean-prestimulus.set',\n",
       " 'data/original/sub06/exp01/eeg/SP 110RMT r1/clean-prestimulus.set',\n",
       " 'data/original/sub06/exp01/eeg/SP 110RMT r2/clean-prestimulus.set',\n",
       " 'data/original/sub06/exp01/eeg/SP 110RMT r3/clean-prestimulus.set',\n",
       " 'data/original/sub06/exp02/eeg/SP 110RMT/clean-prestimulus.set',\n",
       " 'data/original/sub07/exp01/eeg/SP 110RMT r1/clean-prestimulus.set',\n",
       " 'data/original/sub07/exp01/eeg/SP 110RMT r2/clean-prestimulus.set',\n",
       " 'data/original/sub07/exp01/eeg/SP 110RMT r3/clean-prestimulus.set',\n",
       " 'data/original/sub08/exp01/eeg/SP 110RMT r1/clean-prestimulus.set',\n",
       " 'data/original/sub08/exp01/eeg/SP 110RMT r2/clean-prestimulus.set',\n",
       " 'data/original/sub08/exp01/eeg/SP 110RMT r3/clean-prestimulus.set',\n",
       " 'data/original/sub08/exp02/eeg/SP 110RMT/clean-prestimulus.set',\n",
       " 'data/original/sub08/exp03/eeg/SP 110RMT r1/clean-prestimulus.set',\n",
       " 'data/original/sub08/exp03/eeg/SP 110RMT r2/clean-prestimulus.set',\n",
       " 'data/original/sub08/exp03/eeg/SP 110RMT r3/clean-prestimulus.set',\n",
       " 'data/original/sub09/exp01/eeg/SP 110RMT/clean-prestimulus.set',\n",
       " 'data/original/sub10/exp01/eeg/SP 110RMT/clean-prestimulus.set',\n",
       " 'data/original/sub10/exp02/eeg/SP 110RMT r1/clean-prestimulus.set',\n",
       " 'data/original/sub10/exp02/eeg/SP 110RMT r2/clean-prestimulus.set',\n",
       " 'data/original/sub10/exp02/eeg/SP 110RMT r3/clean-prestimulus.set',\n",
       " 'data/original/sub11/exp01/eeg/SP 110RMT/clean-prestimulus.set',\n",
       " 'data/original/sub11/exp02/eeg/SP 110RMT/clean-prestimulus.set',\n",
       " 'data/original/sub12/exp01/eeg/SP 110RMT/clean-prestimulus.set',\n",
       " 'data/original/sub12/exp02/eeg/SP 110RMT/clean-prestimulus.set',\n",
       " 'data/original/sub13/exp01/eeg/SP 110RMT/clean-prestimulus.set',\n",
       " 'data/original/sub14/exp01/eeg/SP 110RMT r1/clean-prestimulus.set',\n",
       " 'data/original/sub15/exp01/eeg/SP 110RMT r1/clean-prestimulus.set',\n",
       " 'data/original/sub15/exp01/eeg/SP 110RMT r2/clean-prestimulus.set',\n",
       " 'data/original/sub15/exp01/eeg/SP 110RMT r3/clean-prestimulus.set',\n",
       " 'data/original/sub16/exp01/eeg/SP 110RMT r1/clean-prestimulus.set',\n",
       " 'data/original/sub16/exp01/eeg/SP 110RMT r2/clean-prestimulus.set',\n",
       " 'data/original/sub16/exp01/eeg/SP 110RMT r3/clean-prestimulus.set']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eegs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eegs = [\n",
    "    'data/original/sub03/exp01/eeg/SP 110RMT r1/clean-prestimulus.set',\n",
    "    'data/original/sub03/exp01/eeg/SP 110RMT r2/clean-prestimulus.set',\n",
    "    'data/original/sub03/exp01/eeg/SP 110RMT r3/clean-prestimulus.set',\n",
    "#     'data/original/sub03/exp02/eeg/SP 110RMT r1/clean-prestimulus.set', NO CMAP\n",
    "#     'data/original/sub03/exp02/eeg/SP 110RMT r2/clean-prestimulus.set', NO CMAP\n",
    "#     'data/original/sub03/exp03/eeg/SP 110RMT r1/clean-prestimulus.set', NO CMAP\n",
    "    'data/original/sub03/exp03/eeg/SP 110RMT r2/clean-prestimulus.set',\n",
    "    'data/original/sub03/exp03/eeg/SP 110RMT r3/clean-prestimulus.set',\n",
    "#     'data/original/sub04/exp01/eeg/SP 110RMT r1/clean-prestimulus.set', NO CMAP\n",
    "#     'data/original/sub04/exp01/eeg/SP 110RMT r2/clean-prestimulus.set', NO CMAP\n",
    "#     'data/original/sub04/exp01/eeg/SP 110RMT r3/clean-prestimulus.set', NO CMAP\n",
    "#     'data/original/sub05/exp01/eeg/SP 110RMT r3/clean-prestimulus.set',\n",
    "    'data/original/sub06/exp01/eeg/SP 110RMT r1/clean-prestimulus.set',\n",
    "    'data/original/sub06/exp01/eeg/SP 110RMT r2/clean-prestimulus.set',\n",
    "    'data/original/sub06/exp01/eeg/SP 110RMT r3/clean-prestimulus.set',\n",
    "    'data/original/sub06/exp02/eeg/SP 110RMT/clean-prestimulus.set',\n",
    "    'data/original/sub07/exp01/eeg/SP 110RMT r1/clean-prestimulus.set',\n",
    "    'data/original/sub07/exp01/eeg/SP 110RMT r2/clean-prestimulus.set',\n",
    "    'data/original/sub07/exp01/eeg/SP 110RMT r3/clean-prestimulus.set',\n",
    "    'data/original/sub08/exp01/eeg/SP 110RMT r1/clean-prestimulus.set',\n",
    "    'data/original/sub08/exp01/eeg/SP 110RMT r2/clean-prestimulus.set',\n",
    "    'data/original/sub08/exp01/eeg/SP 110RMT r3/clean-prestimulus.set',\n",
    "    'data/original/sub08/exp02/eeg/SP 110RMT/clean-prestimulus.set',\n",
    "    'data/original/sub08/exp03/eeg/SP 110RMT r1/clean-prestimulus.set',\n",
    "    'data/original/sub08/exp03/eeg/SP 110RMT r2/clean-prestimulus.set',\n",
    "    'data/original/sub08/exp03/eeg/SP 110RMT r3/clean-prestimulus.set',\n",
    "    'data/original/sub12/exp02/eeg/SP 110RMT/clean-prestimulus.set',\n",
    "#     'data/original/sub13/exp01/eeg/SP 110RMT/clean-prestimulus.set', LEFT HANDED\n",
    "    'data/original/sub14/exp01/eeg/SP 110RMT r1/clean-prestimulus.set',\n",
    "    'data/original/sub15/exp01/eeg/SP 110RMT r1/clean-prestimulus.set',\n",
    "    'data/original/sub15/exp01/eeg/SP 110RMT r2/clean-prestimulus.set',\n",
    "    'data/original/sub15/exp01/eeg/SP 110RMT r3/clean-prestimulus.set',\n",
    "    'data/original/sub16/exp01/eeg/SP 110RMT r1/clean-prestimulus.set',\n",
    "    'data/original/sub16/exp01/eeg/SP 110RMT r2/clean-prestimulus.set',\n",
    "    'data/original/sub16/exp01/eeg/SP 110RMT r3/clean-prestimulus.set'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and process EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def read_eeg(path):\n",
    "    eeg = octave.pop_loadset(path)\n",
    "    new_trial_list = []\n",
    "    for i in range(eeg.data.shape[2]):\n",
    "        trial = eeg.data[:, :, i]\n",
    "        time = np.linspace(-1000, -20, num=trial.shape[1])\n",
    "        trial = pd.DataFrame(np.transpose(trial), columns=eeg.chanlocs.labels[0])\n",
    "        trial['time'] = time\n",
    "        new_trial_list.append(trial)\n",
    "    return new_trial_list\n",
    "\n",
    "def crop_trials(trial_list, duration_millis=500, sampling_rate=2048):\n",
    "    new_trial_list = []\n",
    "    for trial in trial_list:\n",
    "        samples_to_pick = duration_millis * sampling_rate / 1000\n",
    "        new_trial_list.append(trial.tail(int(samples_to_pick)))\n",
    "    return new_trial_list, samples_to_pick\n",
    "\n",
    "# Calculate EEG area.\n",
    "def calculate_eeg_area(epoch_df, sf=2048):\n",
    "    y = epoch_df.drop('time', axis=1).mean(axis=1)\n",
    "    b2, a2 = signal.butter(4, 200/(sf/2), btype='lowpass')\n",
    "    envelope = signal.filtfilt(b2, a2, np.abs(y))\n",
    "    area = np.trapz(envelope, epoch_df['time'].values)\n",
    "    return area\n",
    "\n",
    "# Calculate EEG frequency.\n",
    "def calculate_eeg_frequency(channel):\n",
    "    sf = 2048\n",
    "    win = 4 * sf\n",
    "    freqs, psd = signal.welch(channel, sf, nperseg=win)\n",
    "    return freqs, psd\n",
    "\n",
    "def calculate_eeg_max_amplitude(epoch_df):\n",
    "    avg = epoch_df.mean(axis=1)\n",
    "    return np.max(avg.values)\n",
    "\n",
    "def band_max(freq, psd, interval):\n",
    "    indices = []\n",
    "    for el in freq:\n",
    "        indices.append(el in interval)\n",
    "    freq = freq[indices]\n",
    "    psd = psd[indices]\n",
    "    if (len(psd) == 0):\n",
    "        return 0, 0\n",
    "    i = np.argmax(np.abs(psd))\n",
    "    return freq[i], psd[i]\n",
    "\n",
    "def filter_electrodes(trial, which='all'):\n",
    "    time_column = trial['time']\n",
    "    if which == 'ltm1':\n",
    "        channel_names = ['FC5','FC1','C3','CP5','CP1','FC3','C5','C1','CP3']\n",
    "    elif which == 'rtm1':\n",
    "        channel_names = ['FC6','FC2','C4','CP6','CP2','FC4','C6','C2','CP4']\n",
    "    elif which == 'central':\n",
    "        channel_names = ['Fz','FCz','Cz','F1','FC1','C1','C2','FC2','F2']\n",
    "    else:\n",
    "        channel_names = ['Fp1', 'Fpz', 'Fp2', 'F7', 'F3', 'Fz', 'F4', 'F8', 'FC5', 'FC1', 'FC2', 'FC6', 'M1', 'T7', 'C3', 'Cz', 'C4', 'T8', 'M2', 'CP5', 'CP1', 'CP2', 'CP6', 'P7', 'P3', 'Pz', 'P4', 'P8', 'POz', 'O1', 'O2', 'EOG', 'AF7', 'AF3', 'AF4', 'AF8', 'F5', 'F1', 'F2', 'F6', 'FC3', 'FCz', 'FC4', 'C5', 'C1', 'C2', 'C6', 'CP3', 'CP4', 'P5', 'P1', 'P2', 'P6', 'PO5', 'PO3', 'PO4', 'PO6', 'FT7', 'FT8', 'TP7', 'TP8', 'PO7', 'PO8', 'Oz']\n",
    "    trial = trial[channel_names]\n",
    "    trial['time'] = time_column\n",
    "    return trial\n",
    "\n",
    "def read_wavelets(sub, exp, run, epoch_num):\n",
    "    path = 'wavelets/' + sub + '-' + exp + '-' + run + '-' + str(epoch_num)\n",
    "    with open(path + '-central.pickle', 'rb') as f:\n",
    "        central = pickle.load(f)\n",
    "    with open(path + '-ltm1.pickle', 'rb') as f:\n",
    "        ltm1 = pickle.load(f)\n",
    "    with open(path + '-rtm1.pickle', 'rb') as f:\n",
    "        rtm1 = pickle.load(f)\n",
    "    with open(path + '-all.pickle', 'rb') as f:\n",
    "        all_channels = pickle.load(f)\n",
    "    return all_channels, ltm1, rtm1, central\n",
    "\n",
    "def wavelet_band_max(df, interval):\n",
    "    indices = []\n",
    "    for el in (df.index * 1000):\n",
    "        indices.append(el in interval)\n",
    "    df = df[indices]\n",
    "    if (df.shape[0] == 0):\n",
    "        return 0, 0, 0, 0\n",
    "    return df.mean(axis=1).max(), df.mean(axis=1).argmax() * 1000, df.mean(axis=0).max(), df.mean(axis=0).argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read features file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_filename = '55-features-v1.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(features_filename, index_col=0)\n",
    "\n",
    "p1 = np.percentile(df['mep_category_cmap'], 50)\n",
    "cat = np.ones(len(df['mep_category_cmap'])) * (df['mep_category_cmap'] > p1)\n",
    "df['mep_category_cmap_across_subjects'] = cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare wavelet dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(image, mx=1, mn=0):\n",
    "    wt_min = image.min().min()\n",
    "    std = (image.values - wt_min) / (image.max().max() - wt_min)\n",
    "    image.loc[:, :] = std * (mx - mn) + mn\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1412a61259f54aa8a0bf39d87986833a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1400), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start_time_sec = -500\n",
    "end_time_sec = -20\n",
    "\n",
    "df_wt = []\n",
    "        \n",
    "for idx, epoch in tqdm_notebook(df.iterrows(), total=df.shape[0]):\n",
    "    wt_all, wt_ltm1, wt_rtm1, wt_central = read_wavelets(epoch['sub'], epoch['exp'], epoch['run'], epoch['epoch'])\n",
    "\n",
    "    # Take 6-50Hz frequencies.\n",
    "#     wt_all = wt_all[(wt_all.index * 1000 > 6) * (wt_all.index * 1000 < 50)]\n",
    "    wt_ltm1 = wt_ltm1[(wt_ltm1.index * 1000 > 2) * (wt_ltm1.index * 1000 < 50)]\n",
    "#     wt_rtm1 = wt_rtm1[(wt_rtm1.index * 1000 > 6) * (wt_rtm1.index * 1000 < 50)]\n",
    "#     wt_central = wt_central[(wt_central.index * 1000 > 6) * (wt_central.index * 1000 < 50)]\n",
    "\n",
    "    # Take only last -100ms to -20ms.\n",
    "#     wt_all = wt_all.loc[:, wt_all.columns.isin(wt_all.columns[(wt_all.columns >= (start_time_sec/1000)) * (wt_all.columns <= (end_time_sec/1000))])]\n",
    "    wt_ltm1 = wt_ltm1.loc[:, wt_ltm1.columns.isin(wt_ltm1.columns[(wt_ltm1.columns >= (start_time_sec/1000)) * (wt_ltm1.columns <= (end_time_sec/1000))])]\n",
    "#     wt_rtm1 = wt_rtm1.loc[:, wt_rtm1.columns.isin(wt_rtm1.columns[(wt_rtm1.columns >= (start_time_sec/1000)) * (wt_rtm1.columns <= (end_time_sec/1000))])]\n",
    "#     wt_central = wt_central.loc[:, wt_central.columns.isin(wt_central.columns[(wt_central.columns >= (start_time_sec/1000)) * (wt_central.columns <= (end_time_sec/1000))])]\n",
    "    \n",
    "    df_wt.append(normalize_image(wt_ltm1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 983)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wt[5].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raquib/anaconda3/envs/tmseeg/lib/python3.7/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/home/raquib/anaconda3/envs/tmseeg/lib/python3.7/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "for wt in df_wt:\n",
    "    img = np.array(wt.values)\n",
    "    # img = np.stack([img]*3, axis=-1)\n",
    "    img = resize(img, (160, 160))\n",
    "    x.append(img.reshape(img.shape[0], img.shape[1], 1))\n",
    "    \n",
    "x = np.array(x)\n",
    "y = cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 160, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = TQDMNotebookCallback(show_inner=False)\n",
    "cb.on_train_batch_begin = cb.on_batch_begin\n",
    "cb.on_train_batch_end = cb.on_batch_end\n",
    "cb.on_test_begin = cb.on_train_begin\n",
    "cb.on_test_end = cb.on_train_end\n",
    "cb.on_test_batch_begin = cb.on_batch_begin\n",
    "cb.on_test_batch_end = cb.on_batch_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([128, 256, 512]))\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.Discrete([0.3, 0.5]))\n",
    "HP_LEARNING_RATE = hp.HParam('learning_rate', hp.Discrete([0.0001, 0.00001]))\n",
    "HP_CNN_FILTER_1 = hp.HParam('filter_1', hp.Discrete([16, 64, 256]))\n",
    "HP_CNN_FILTER_2 = hp.HParam('filter_2', hp.Discrete([16, 64, 256]))\n",
    "HP_BATCH_NORM = hp.HParam('batch_norm', hp.Discrete([False, True]))\n",
    "HP_CNN_KERNEL_X_1 = hp.HParam('kernel_1_x', hp.Discrete([50, 20, 5]))\n",
    "HP_CNN_KERNEL_Y_1 = hp.HParam('kernel_1_y', hp.Discrete([50, 20, 5]))\n",
    "HP_CNN_KERNEL_X_2 = hp.HParam('kernel_2_x', hp.Discrete([50, 20, 5]))\n",
    "HP_CNN_KERNEL_Y_2 = hp.HParam('kernel_2_y', hp.Discrete([50, 20, 5]))\n",
    "\n",
    "with tf.summary.create_file_writer('logs/73-hparam-tuning').as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_LEARNING_RATE, HP_CNN_KERNEL_X_1, HP_CNN_KERNEL_Y_1, HP_CNN_KERNEL_X_2, HP_CNN_KERNEL_Y_2, HP_CNN_FILTER_1, HP_CNN_FILTER_2, HP_BATCH_NORM],\n",
    "        metrics=[hp.Metric('accuracy', display_name='Accuracy')],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_test_model(logdir, hparams):\n",
    "    classifier = tf.keras.Sequential()\n",
    "\n",
    "    classifier.add(tf.keras.layers.Conv2D(filters=hparams[HP_CNN_FILTER_1], kernel_size=(hparams[HP_CNN_KERNEL_X_1], hparams[HP_CNN_KERNEL_Y_1]), padding='same', activation='relu', input_shape=(x_train[0].shape[0], x_train[0].shape[1],1)))\n",
    "    if hparams[HP_BATCH_NORM]:\n",
    "        classifier.add(tf.keras.layers.BatchNormalization())\n",
    "    classifier.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "    classifier.add(tf.keras.layers.Dropout(hparams[HP_DROPOUT]))\n",
    "\n",
    "    classifier.add(tf.keras.layers.Conv2D(filters=hparams[HP_CNN_FILTER_2], kernel_size=(hparams[HP_CNN_KERNEL_X_2], hparams[HP_CNN_KERNEL_Y_2]), padding='same', activation='relu'))\n",
    "    classifier.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "    classifier.add(tf.keras.layers.Dropout(hparams[HP_DROPOUT]))\n",
    "\n",
    "    classifier.add(tf.keras.layers.Flatten())\n",
    "\n",
    "    classifier.add(tf.keras.layers.Dense(hparams[HP_NUM_UNITS], activation='relu'))\n",
    "    classifier.add(tf.keras.layers.Dropout(hparams[HP_DROPOUT]))\n",
    "    classifier.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    classifier.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hparams[HP_LEARNING_RATE], decay=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    cb = [\n",
    "        tf.keras.callbacks.TensorBoard(log_dir=logdir),\n",
    "        hp.KerasCallback(logdir, hparams)\n",
    "    ]\n",
    "    classifier.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=64, epochs=200, callbacks=cb, verbose=0)\n",
    "    \n",
    "    _, accuracy = classifier.evaluate(x_test, y_test)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-0\n",
      "{'num_units': 128, 'dropout': 0.3, 'learning_rate': 1e-05, 'kernel_1_x': 5, 'kernel_1_y': 5, 'kernel_2_x': 5, 'kernel_2_y': 5, 'filter_1': 16, 'filter_2': 16, 'batch_norm': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0826 10:49:36.692766 140537437452096 deprecation.py:323] From /home/raquib/anaconda3/envs/tmseeg/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 321us/sample - loss: 0.6637 - accuracy: 0.5971\n",
      "--- Starting trial: run-1\n",
      "{'num_units': 128, 'dropout': 0.3, 'learning_rate': 0.0001, 'kernel_1_x': 5, 'kernel_1_y': 5, 'kernel_2_x': 5, 'kernel_2_y': 5, 'filter_1': 16, 'filter_2': 16, 'batch_norm': False}\n",
      "350/350 [==============================] - 0s 327us/sample - loss: 2.0264 - accuracy: 0.5057\n",
      "--- Starting trial: run-2\n",
      "{'num_units': 128, 'dropout': 0.3, 'learning_rate': 1e-05, 'kernel_1_x': 5, 'kernel_1_y': 5, 'kernel_2_x': 5, 'kernel_2_y': 20, 'filter_1': 16, 'filter_2': 16, 'batch_norm': False}\n",
      "350/350 [==============================] - 0s 399us/sample - loss: 0.6730 - accuracy: 0.5714\n",
      "--- Starting trial: run-3\n",
      "{'num_units': 128, 'dropout': 0.3, 'learning_rate': 0.0001, 'kernel_1_x': 5, 'kernel_1_y': 5, 'kernel_2_x': 5, 'kernel_2_y': 20, 'filter_1': 16, 'filter_2': 16, 'batch_norm': False}\n",
      "350/350 [==============================] - 0s 281us/sample - loss: 2.2574 - accuracy: 0.5114\n",
      "--- Starting trial: run-4\n",
      "{'num_units': 128, 'dropout': 0.3, 'learning_rate': 1e-05, 'kernel_1_x': 5, 'kernel_1_y': 5, 'kernel_2_x': 5, 'kernel_2_y': 50, 'filter_1': 16, 'filter_2': 16, 'batch_norm': False}\n",
      "350/350 [==============================] - 0s 553us/sample - loss: 0.6754 - accuracy: 0.5543\n",
      "--- Starting trial: run-5\n",
      "{'num_units': 128, 'dropout': 0.3, 'learning_rate': 0.0001, 'kernel_1_x': 5, 'kernel_1_y': 5, 'kernel_2_x': 5, 'kernel_2_y': 50, 'filter_1': 16, 'filter_2': 16, 'batch_norm': False}\n",
      "350/350 [==============================] - 0s 365us/sample - loss: 2.3902 - accuracy: 0.5400\n",
      "--- Starting trial: run-6\n",
      "{'num_units': 128, 'dropout': 0.3, 'learning_rate': 1e-05, 'kernel_1_x': 5, 'kernel_1_y': 5, 'kernel_2_x': 20, 'kernel_2_y': 5, 'filter_1': 16, 'filter_2': 16, 'batch_norm': False}\n",
      "350/350 [==============================] - 0s 434us/sample - loss: 0.6747 - accuracy: 0.5743\n",
      "--- Starting trial: run-7\n",
      "{'num_units': 128, 'dropout': 0.3, 'learning_rate': 0.0001, 'kernel_1_x': 5, 'kernel_1_y': 5, 'kernel_2_x': 20, 'kernel_2_y': 5, 'filter_1': 16, 'filter_2': 16, 'batch_norm': False}\n",
      "350/350 [==============================] - 0s 277us/sample - loss: 2.4786 - accuracy: 0.5057\n",
      "--- Starting trial: run-8\n",
      "{'num_units': 128, 'dropout': 0.3, 'learning_rate': 1e-05, 'kernel_1_x': 5, 'kernel_1_y': 5, 'kernel_2_x': 20, 'kernel_2_y': 20, 'filter_1': 16, 'filter_2': 16, 'batch_norm': False}\n",
      "350/350 [==============================] - 0s 458us/sample - loss: 0.6971 - accuracy: 0.5800\n",
      "--- Starting trial: run-9\n",
      "{'num_units': 128, 'dropout': 0.3, 'learning_rate': 0.0001, 'kernel_1_x': 5, 'kernel_1_y': 5, 'kernel_2_x': 20, 'kernel_2_y': 20, 'filter_1': 16, 'filter_2': 16, 'batch_norm': False}\n",
      "350/350 [==============================] - 0s 271us/sample - loss: 2.9505 - accuracy: 0.5000\n",
      "--- Starting trial: run-10\n",
      "{'num_units': 128, 'dropout': 0.3, 'learning_rate': 1e-05, 'kernel_1_x': 5, 'kernel_1_y': 5, 'kernel_2_x': 20, 'kernel_2_y': 50, 'filter_1': 16, 'filter_2': 16, 'batch_norm': False}\n",
      "350/350 [==============================] - 0s 722us/sample - loss: 0.6983 - accuracy: 0.5686\n",
      "--- Starting trial: run-11\n",
      "{'num_units': 128, 'dropout': 0.3, 'learning_rate': 0.0001, 'kernel_1_x': 5, 'kernel_1_y': 5, 'kernel_2_x': 20, 'kernel_2_y': 50, 'filter_1': 16, 'filter_2': 16, 'batch_norm': False}\n",
      "350/350 [==============================] - 0s 356us/sample - loss: 2.8137 - accuracy: 0.5143\n",
      "--- Starting trial: run-12\n",
      "{'num_units': 128, 'dropout': 0.3, 'learning_rate': 1e-05, 'kernel_1_x': 5, 'kernel_1_y': 5, 'kernel_2_x': 50, 'kernel_2_y': 5, 'filter_1': 16, 'filter_2': 16, 'batch_norm': False}\n",
      "350/350 [==============================] - 0s 547us/sample - loss: 0.6855 - accuracy: 0.5657\n",
      "--- Starting trial: run-13\n",
      "{'num_units': 128, 'dropout': 0.3, 'learning_rate': 0.0001, 'kernel_1_x': 5, 'kernel_1_y': 5, 'kernel_2_x': 50, 'kernel_2_y': 5, 'filter_1': 16, 'filter_2': 16, 'batch_norm': False}\n",
      "350/350 [==============================] - 0s 382us/sample - loss: 2.9473 - accuracy: 0.5029\n",
      "--- Starting trial: run-14\n",
      "{'num_units': 128, 'dropout': 0.3, 'learning_rate': 1e-05, 'kernel_1_x': 5, 'kernel_1_y': 5, 'kernel_2_x': 50, 'kernel_2_y': 20, 'filter_1': 16, 'filter_2': 16, 'batch_norm': False}\n",
      "350/350 [==============================] - 0s 719us/sample - loss: 0.7083 - accuracy: 0.5514\n",
      "--- Starting trial: run-15\n",
      "{'num_units': 128, 'dropout': 0.3, 'learning_rate': 0.0001, 'kernel_1_x': 5, 'kernel_1_y': 5, 'kernel_2_x': 50, 'kernel_2_y': 20, 'filter_1': 16, 'filter_2': 16, 'batch_norm': False}\n",
      "350/350 [==============================] - 0s 350us/sample - loss: 2.9786 - accuracy: 0.5429\n",
      "--- Starting trial: run-16\n",
      "{'num_units': 128, 'dropout': 0.3, 'learning_rate': 1e-05, 'kernel_1_x': 5, 'kernel_1_y': 5, 'kernel_2_x': 50, 'kernel_2_y': 50, 'filter_1': 16, 'filter_2': 16, 'batch_norm': False}\n",
      "350/350 [==============================] - 0s 1ms/sample - loss: 0.7169 - accuracy: 0.5571\n",
      "--- Starting trial: run-17\n",
      "{'num_units': 128, 'dropout': 0.3, 'learning_rate': 0.0001, 'kernel_1_x': 5, 'kernel_1_y': 5, 'kernel_2_x': 50, 'kernel_2_y': 50, 'filter_1': 16, 'filter_2': 16, 'batch_norm': False}\n",
      "350/350 [==============================] - 0s 355us/sample - loss: 2.9382 - accuracy: 0.5571\n",
      "--- Starting trial: run-18\n",
      "{'num_units': 128, 'dropout': 0.3, 'learning_rate': 1e-05, 'kernel_1_x': 5, 'kernel_1_y': 20, 'kernel_2_x': 5, 'kernel_2_y': 5, 'filter_1': 16, 'filter_2': 16, 'batch_norm': False}\n",
      "350/350 [==============================] - 0s 349us/sample - loss: 0.6712 - accuracy: 0.5800\n",
      "--- Starting trial: run-19\n",
      "{'num_units': 128, 'dropout': 0.3, 'learning_rate': 0.0001, 'kernel_1_x': 5, 'kernel_1_y': 20, 'kernel_2_x': 5, 'kernel_2_y': 5, 'filter_1': 16, 'filter_2': 16, 'batch_norm': False}\n",
      "350/350 [==============================] - 0s 314us/sample - loss: 2.2821 - accuracy: 0.5257\n",
      "--- Starting trial: run-20\n",
      "{'num_units': 128, 'dropout': 0.3, 'learning_rate': 1e-05, 'kernel_1_x': 5, 'kernel_1_y': 20, 'kernel_2_x': 5, 'kernel_2_y': 20, 'filter_1': 16, 'filter_2': 16, 'batch_norm': False}\n",
      "350/350 [==============================] - 0s 288us/sample - loss: 0.6898 - accuracy: 0.5743\n",
      "--- Starting trial: run-21\n",
      "{'num_units': 128, 'dropout': 0.3, 'learning_rate': 0.0001, 'kernel_1_x': 5, 'kernel_1_y': 20, 'kernel_2_x': 5, 'kernel_2_y': 20, 'filter_1': 16, 'filter_2': 16, 'batch_norm': False}\n",
      "350/350 [==============================] - 0s 291us/sample - loss: 2.4331 - accuracy: 0.5314\n",
      "--- Starting trial: run-22\n",
      "{'num_units': 128, 'dropout': 0.3, 'learning_rate': 1e-05, 'kernel_1_x': 5, 'kernel_1_y': 20, 'kernel_2_x': 5, 'kernel_2_y': 50, 'filter_1': 16, 'filter_2': 16, 'batch_norm': False}\n",
      "350/350 [==============================] - 0s 371us/sample - loss: 0.6959 - accuracy: 0.5657\n",
      "--- Starting trial: run-23\n",
      "{'num_units': 128, 'dropout': 0.3, 'learning_rate': 0.0001, 'kernel_1_x': 5, 'kernel_1_y': 20, 'kernel_2_x': 5, 'kernel_2_y': 50, 'filter_1': 16, 'filter_2': 16, 'batch_norm': False}\n",
      "350/350 [==============================] - 0s 355us/sample - loss: 2.6263 - accuracy: 0.5114\n",
      "--- Starting trial: run-24\n",
      "{'num_units': 128, 'dropout': 0.3, 'learning_rate': 1e-05, 'kernel_1_x': 5, 'kernel_1_y': 20, 'kernel_2_x': 20, 'kernel_2_y': 5, 'filter_1': 16, 'filter_2': 16, 'batch_norm': False}\n",
      "350/350 [==============================] - 0s 291us/sample - loss: 0.6816 - accuracy: 0.5714\n",
      "--- Starting trial: run-25\n",
      "{'num_units': 128, 'dropout': 0.3, 'learning_rate': 0.0001, 'kernel_1_x': 5, 'kernel_1_y': 20, 'kernel_2_x': 20, 'kernel_2_y': 5, 'filter_1': 16, 'filter_2': 16, 'batch_norm': False}\n",
      "350/350 [==============================] - 0s 296us/sample - loss: 2.6552 - accuracy: 0.5057\n",
      "--- Starting trial: run-26\n",
      "{'num_units': 128, 'dropout': 0.3, 'learning_rate': 1e-05, 'kernel_1_x': 5, 'kernel_1_y': 20, 'kernel_2_x': 20, 'kernel_2_y': 20, 'filter_1': 16, 'filter_2': 16, 'batch_norm': False}\n",
      "350/350 [==============================] - 0s 307us/sample - loss: 0.7129 - accuracy: 0.5600\n",
      "--- Starting trial: run-27\n",
      "{'num_units': 128, 'dropout': 0.3, 'learning_rate': 0.0001, 'kernel_1_x': 5, 'kernel_1_y': 20, 'kernel_2_x': 20, 'kernel_2_y': 20, 'filter_1': 16, 'filter_2': 16, 'batch_norm': False}\n",
      "350/350 [==============================] - 0s 278us/sample - loss: 2.8193 - accuracy: 0.5343\n",
      "--- Starting trial: run-28\n",
      "{'num_units': 128, 'dropout': 0.3, 'learning_rate': 1e-05, 'kernel_1_x': 5, 'kernel_1_y': 20, 'kernel_2_x': 20, 'kernel_2_y': 50, 'filter_1': 16, 'filter_2': 16, 'batch_norm': False}\n",
      "350/350 [==============================] - 0s 370us/sample - loss: 0.7094 - accuracy: 0.5686\n",
      "--- Starting trial: run-29\n",
      "{'num_units': 128, 'dropout': 0.3, 'learning_rate': 0.0001, 'kernel_1_x': 5, 'kernel_1_y': 20, 'kernel_2_x': 20, 'kernel_2_y': 50, 'filter_1': 16, 'filter_2': 16, 'batch_norm': False}\n",
      "350/350 [==============================] - 0s 387us/sample - loss: 3.1037 - accuracy: 0.5314\n",
      "--- Starting trial: run-30\n",
      "{'num_units': 128, 'dropout': 0.3, 'learning_rate': 1e-05, 'kernel_1_x': 5, 'kernel_1_y': 20, 'kernel_2_x': 50, 'kernel_2_y': 5, 'filter_1': 16, 'filter_2': 16, 'batch_norm': False}\n",
      "350/350 [==============================] - 0s 366us/sample - loss: 0.6912 - accuracy: 0.5771\n",
      "--- Starting trial: run-31\n",
      "{'num_units': 128, 'dropout': 0.3, 'learning_rate': 0.0001, 'kernel_1_x': 5, 'kernel_1_y': 20, 'kernel_2_x': 50, 'kernel_2_y': 5, 'filter_1': 16, 'filter_2': 16, 'batch_norm': False}\n",
      "350/350 [==============================] - 0s 368us/sample - loss: 2.9378 - accuracy: 0.5000\n",
      "--- Starting trial: run-32\n",
      "{'num_units': 128, 'dropout': 0.3, 'learning_rate': 1e-05, 'kernel_1_x': 5, 'kernel_1_y': 20, 'kernel_2_x': 50, 'kernel_2_y': 20, 'filter_1': 16, 'filter_2': 16, 'batch_norm': False}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-7525661f986a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m                                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'--- Starting trial: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mrun_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                                         \u001b[0mtrain_test_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'logs/tensorboard/73-wavelet-hyper-v1/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrun_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m                                         \u001b[0msession_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-6ceaab0c932c>\u001b[0m in \u001b[0;36mtrain_test_model\u001b[0;34m(logdir, hparams)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     ]\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tmseeg/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tmseeg/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tmseeg/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tmseeg/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3508\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3509\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3510\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3512\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tmseeg/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    570\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m    571\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m--> 572\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tmseeg/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tmseeg/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args)\u001b[0m\n\u001b[1;32m    443\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[1;32m    444\u001b[0m                    \"config_proto\", config),\n\u001b[0;32m--> 445\u001b[0;31m             ctx=ctx)\n\u001b[0m\u001b[1;32m    446\u001b[0m       \u001b[0;31m# Replace empty list with None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tmseeg/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "session_num = 0\n",
    "for batch_norm in HP_BATCH_NORM.domain.values:\n",
    "    for dropout in HP_DROPOUT.domain.values:\n",
    "        for filter_1 in HP_CNN_FILTER_1.domain.values:\n",
    "            for filter_2 in HP_CNN_FILTER_2.domain.values:\n",
    "                for num_units in HP_NUM_UNITS.domain.values:\n",
    "                    for kernel_1_x in HP_CNN_KERNEL_X_1.domain.values:\n",
    "                        for kernel_1_y in HP_CNN_KERNEL_Y_1.domain.values:\n",
    "                            for kernel_2_x in HP_CNN_KERNEL_X_2.domain.values:\n",
    "                                for kernel_2_y in HP_CNN_KERNEL_Y_2.domain.values:\n",
    "                                    for lr in HP_LEARNING_RATE.domain.values:\n",
    "                                        hparams = {\n",
    "                                            HP_NUM_UNITS: num_units,\n",
    "                                            HP_DROPOUT: dropout,\n",
    "                                            HP_LEARNING_RATE: lr,\n",
    "                                            HP_CNN_KERNEL_X_1: kernel_1_x,\n",
    "                                            HP_CNN_KERNEL_Y_1: kernel_1_y,\n",
    "                                            HP_CNN_KERNEL_X_2: kernel_2_x,\n",
    "                                            HP_CNN_KERNEL_Y_2: kernel_2_y,\n",
    "                                            HP_CNN_FILTER_1: filter_1,\n",
    "                                            HP_CNN_FILTER_2: filter_2,\n",
    "                                            HP_BATCH_NORM: batch_norm\n",
    "                                        }\n",
    "                                        run_name = \"run-%d\" % session_num\n",
    "                                        print('--- Starting trial: %s' % run_name)\n",
    "                                        print({h.name: hparams[h] for h in hparams})\n",
    "                                        train_test_model('logs/tensorboard/73-wavelet-hyper-v1/' + run_name, hparams)\n",
    "                                        session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
