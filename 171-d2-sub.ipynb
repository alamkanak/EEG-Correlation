{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/raquib/anaconda3/envs/tmseeg/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/raquib/anaconda3/envs/tmseeg/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "from io import StringIO\n",
    "import mne\n",
    "from mne.io import read_raw_eeglab, read_epochs_eeglab\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from scipy import fftpack\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "# from tqdm import tqdm, tqdm_notebook\n",
    "from tqdm.notebook import tqdm\n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from livelossplot.tf_keras import PlotLossesCallback\n",
    "\n",
    "import sklearn.model_selection\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "import multiprocessing\n",
    "from tpot import TPOTRegressor\n",
    "from oct2py import octave\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from joblib import wrap_non_picklable_objects\n",
    "import json\n",
    "import pickle\n",
    "import os.path\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import timeit\n",
    "from skimage.transform import resize\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, optimizers, callbacks\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.genmod import bayes_mixed_glm as glm\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import RFECV\n",
    "from spectrum import arburg, arma2psd, pburg\n",
    "import pylab\n",
    "from scipy.signal import find_peaks, butter\n",
    "from scipy.integrate import simps\n",
    "from scipy.io import loadmat\n",
    "from numpy import trapz\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power and phase calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blackman_harris_filter(channel, time, cutoffs, fs, numtaps=801):\n",
    "    b = signal.firwin(numtaps, cutoffs, window='blackmanharris', fs=fs)\n",
    "    filtered = signal.lfilter(b, 1, channel)\n",
    "    delay = 0.5 * (numtaps - 1) / fs\n",
    "    df = pd.DataFrame({\n",
    "        'time': time-delay,\n",
    "        'channel': filtered\n",
    "    })\n",
    "    return df\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, btype='bandpass', order=2):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype=btype)\n",
    "    y = signal.lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "def get_phase(channel, time, band, fs=4096, plot=False, filter_type='butter', start_time_ms=-750, stop_time_ms=-2):\n",
    "    if filter_type=='butter':\n",
    "        df_filtered = pd.DataFrame({'channel': butter_bandpass_filter(channel, band[0], band[1], 4096), 'time': time})\n",
    "    else:\n",
    "        df_filtered = blackman_harris_filter(channel, time, [0.000001, band[0]], fs)\n",
    "        df_filtered = blackman_harris_filter(df_filtered['channel'].values, df_filtered['time'].values, band[1], fs)    \n",
    "    \n",
    "    hilb = signal.hilbert(df_filtered[(df_filtered['time'] > start_time_ms) * (df_filtered['time'] < stop_time_ms)]['channel'])\n",
    "    phase = np.angle(hilb, deg=True)\n",
    "    df_phase = pd.DataFrame(phase, columns=['phase'])\n",
    "    df_phase['time'] = df_filtered[(df_filtered['time'] > start_time_ms) * (df_filtered['time'] < stop_time_ms)]['time'].values\n",
    "    \n",
    "    if plot == True:\n",
    "        fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(13,10))\n",
    "        ax1.plot(time, channel)\n",
    "        ax1.set_xlabel('Time')\n",
    "        ax1.set_ylabel('Amplitude')\n",
    "        ax1.set_title('Signal')\n",
    "        \n",
    "        ax2.plot(df_filtered['time'], df_filtered['channel'])\n",
    "        ax2.set_title('Filtered channel')\n",
    "        ax2.set_xlabel('Time')\n",
    "        ax2.set_ylabel('Filtered channel')\n",
    "        \n",
    "        freq, power = signal.welch(df_filtered['channel'], 4096, nperseg=4096/2, nfft=4096/2)\n",
    "        freq_res = freq[1] - freq[0]\n",
    "        power = np.log(power)\n",
    "        ax3.plot(freq[freq < 200], power[freq < 200])\n",
    "        ax3.set_title('Power spectrum')\n",
    "        ax3.set_xlabel('Frequency')\n",
    "        ax3.set_ylabel('Power')\n",
    "        \n",
    "        ax4.plot(df_phase['time'], df_phase['phase'])\n",
    "        ax4.plot(df_phase.iloc[-1]['time'], df_phase.iloc[-1]['phase'], 'o')\n",
    "        ax4.set_title('Phase')\n",
    "        ax4.set_xlabel('Time')\n",
    "        ax4.set_ylabel('Phase')\n",
    "        plt.tight_layout()\n",
    "    # df_phase = df_phase[df_phase['time'] <= -20]\n",
    "    return df_phase.iloc[-1]['phase'] + 180\n",
    "\n",
    "def get_power(channel, time, crop_start_millis=-150, fs=500, plot=False, method='pburg'):       \n",
    "    # Crop.\n",
    "    channel = channel[(time > crop_start_millis) * (time < -1)].values\n",
    "    time = time[(time > crop_start_millis) * (time < -1)].values\n",
    "\n",
    "    # Resample.\n",
    "    ts = time[1] - time[0]\n",
    "    secs = len(channel) * ts\n",
    "    secs = secs/1000\n",
    "    resampled = signal.resample(channel, int(secs*fs))\n",
    "    resampled_time = np.linspace(time[0], time[-1], len(resampled))\n",
    "    \n",
    "    # Filer if gamma region.\n",
    "#     if 48 > band[0] and 48 < band[1]:\n",
    "#     if filter_type == 'butter':\n",
    "#         resampled = butter_bandpass_filter(resampled, 48, 52, fs, 'bandstop')\n",
    "#         resampled_time = resampled_time\n",
    "#     else:\n",
    "#         df_filtered = blackman_harris_filter(resampled, resampled_time, [48, 52], fs, numtaps=101)\n",
    "#         resampled = df_filtered['channel']\n",
    "#         resampled_time = df_filtered['time']\n",
    "    \n",
    "    # PSD.\n",
    "    try:\n",
    "        if method == 'welch':\n",
    "            # Welch method\n",
    "            freq, power = signal.welch(resampled, fs)\n",
    "            freq_res = freq[1] - freq[0]\n",
    "            df_power = pd.DataFrame({'freq': freq, 'power': power})\n",
    "        elif method == 'fft':\n",
    "            # FFT method\n",
    "            power = np.abs(np.fft.fft(resampled, n=500))\n",
    "            freq = np.linspace(0, fs, len(power))\n",
    "            df_power = pd.DataFrame({'freq': freq, 'power': power})\n",
    "        elif method == 'pburg':\n",
    "            # Burgs method\n",
    "            p = pburg(resampled, int(len(resampled)*0.25), sampling=fs, NFFT=4096)\n",
    "            power = p.psd\n",
    "            freq = np.linspace(0, fs, len(power))\n",
    "            df_power = pd.DataFrame({'freq': freq, 'power': power})\n",
    "            df_power = df_power[df_power['freq'] < fs/2]\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "        return 0\n",
    "\n",
    "    return df_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11074\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['data/dataset2/original/co2c1000367/co2c1000367.rd.030.gz',\n",
       " 'data/dataset2/original/co2c1000367/co2c1000367.rd.092.gz',\n",
       " 'data/dataset2/original/co2c1000367/co2c1000367.rd.047.gz',\n",
       " 'data/dataset2/original/co2c1000367/co2c1000367.rd.075.gz',\n",
       " 'data/dataset2/original/co2c1000367/co2c1000367.rd.116.gz',\n",
       " 'data/dataset2/original/co2c1000367/co2c1000367.rd.063.gz',\n",
       " 'data/dataset2/original/co2c1000367/co2c1000367.rd.033.gz',\n",
       " 'data/dataset2/original/co2c1000367/co2c1000367.rd.110.gz',\n",
       " 'data/dataset2/original/co2c1000367/co2c1000367.rd.099.gz',\n",
       " 'data/dataset2/original/co2c1000367/co2c1000367.rd.001.gz']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg_files = glob.glob('data/dataset2/original/*/*.gz')\n",
    "print(len(eeg_files))\n",
    "eeg_files[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sub(trial_file):\n",
    "    # Read the gzip file.\n",
    "    with gzip.open(trial_file, 'rb') as f:\n",
    "        trial_str = str(f.read(), 'utf-8')\n",
    "    \n",
    "    # Parse the file.\n",
    "    df_long = []\n",
    "    lines = trial_str.split('\\n')\n",
    "    if len(lines) < 10:\n",
    "        return None\n",
    "    sub = lines[0].split(' ')[1].split('.')[0].strip()\n",
    "    alcoholic = sub[3] == 'a'\n",
    "    condition = lines[3].split(',')[0][2:].strip()\n",
    "    trial = trial_file.split('/')[-1].split('.')[-2]\n",
    "    return {\n",
    "        'subject': sub,\n",
    "        'alcoholic': alcoholic,\n",
    "        'condition': condition,\n",
    "        'trial': trial\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trials as csv files for MATLAB.\n",
    "def export_trials_csv(sub):\n",
    "    trial_files = glob.glob(sub + '*.gz')\n",
    "    subs = []\n",
    "    for trial_file in trial_files:\n",
    "        sub = get_sub(trial_file)\n",
    "        if sub is not None:\n",
    "            subs.append(sub)\n",
    "    subs = pd.DataFrame(subs)\n",
    "    subs.to_csv('data/dataset2/subjects/{}.csv'.format(subs.iloc[0]['subject']))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9d3fce2c48748948da15159e98f3a13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=122.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subs = sorted(glob.glob('data/dataset2/original/*/'))\n",
    "num_cores = multiprocessing.cpu_count() - 2\n",
    "Parallel(n_jobs=num_cores)(delayed(export_trials_csv)(sub) for sub in tqdm(subs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
