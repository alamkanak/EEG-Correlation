{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raquib/anaconda3/envs/tmseeg/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "Using TensorFlow backend.\n",
      "/home/raquib/anaconda3/envs/tmseeg/lib/python3.7/site-packages/pyparsing.py:3168: FutureWarning: Possible set intersection at position 3\n",
      "  self.re = re.compile(self.reString)\n",
      "/home/raquib/anaconda3/envs/tmseeg/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:17: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Mapping, defaultdict\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "from io import StringIO\n",
    "import mne\n",
    "from mne.io import read_raw_eeglab, read_epochs_eeglab\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from scipy import fftpack\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import math\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from livelossplot.tf_keras import PlotLossesCallback\n",
    "\n",
    "import autosklearn.regression\n",
    "import sklearn.model_selection\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "import multiprocessing\n",
    "from tpot import TPOTRegressor\n",
    "from oct2py import octave\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from joblib import wrap_non_picklable_objects\n",
    "import json\n",
    "import pickle\n",
    "import os.path\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import timeit\n",
    "from skimage.transform import resize\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta\n",
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, optimizers, callbacks\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.genmod import bayes_mixed_glm as glm\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "from spectrum import arburg, arma2psd, pburg\n",
    "import pylab\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.integrate import simps\n",
    "from IPython.core.display import display, HTML\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: function /home/raquib/Documents/MATLAB/eeglab2019_0/functions/sigprocfunc/quantile.m shadows a core library function\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'.:/home/raquib/Documents/MATLAB/eeglab2019_0/functions/sigprocfunc:/home/raquib/Documents/MATLAB/eeglab2019_0/functions/adminfunc:/home/raquib/Documents/MATLAB/eeglab2019_0/functions/popfunc:/home/raquib/Documents/MATLAB/eeglab2019_0/functions/guifunc:/home/raquib/anaconda3/envs/tmseeg/lib/python3.7/site-packages/oct2py:/home/raquib/anaconda3/envs/tmseeg/lib/python3.7/site-packages/octave_kernel:/usr/lib/x86_64-linux-gnu/octave/4.2.2/site/oct/x86_64-pc-linux-gnu:/usr/lib/x86_64-linux-gnu/octave/site/oct/api-v51/x86_64-pc-linux-gnu:/usr/lib/x86_64-linux-gnu/octave/site/oct/x86_64-pc-linux-gnu:/usr/share/octave/4.2.2/site/m:/usr/share/octave/site/api-v51/m:/usr/share/octave/site/m:/usr/share/octave/site/m/startup:/usr/lib/x86_64-linux-gnu/octave/4.2.2/oct/x86_64-pc-linux-gnu:/usr/share/octave/4.2.2/m:/usr/share/octave/4.2.2/m/audio:/usr/share/octave/4.2.2/m/debian:/usr/share/octave/4.2.2/m/deprecated:/usr/share/octave/4.2.2/m/elfun:/usr/share/octave/4.2.2/m/general:/usr/share/octave/4.2.2/m/geometry:/usr/share/octave/4.2.2/m/gui:/usr/share/octave/4.2.2/m/help:/usr/share/octave/4.2.2/m/image:/usr/share/octave/4.2.2/m/io:/usr/share/octave/4.2.2/m/java:/usr/share/octave/4.2.2/m/linear-algebra:/usr/share/octave/4.2.2/m/miscellaneous:/usr/share/octave/4.2.2/m/ode:/usr/share/octave/4.2.2/m/optimization:/usr/share/octave/4.2.2/m/path:/usr/share/octave/4.2.2/m/pkg:/usr/share/octave/4.2.2/m/plot:/usr/share/octave/4.2.2/m/plot/appearance:/usr/share/octave/4.2.2/m/plot/draw:/usr/share/octave/4.2.2/m/plot/util:/usr/share/octave/4.2.2/m/polynomial:/usr/share/octave/4.2.2/m/prefs:/usr/share/octave/4.2.2/m/profiler:/usr/share/octave/4.2.2/m/set:/usr/share/octave/4.2.2/m/signal:/usr/share/octave/4.2.2/m/sparse:/usr/share/octave/4.2.2/m/specfun:/usr/share/octave/4.2.2/m/special-matrix:/usr/share/octave/4.2.2/m/startup:/usr/share/octave/4.2.2/m/statistics:/usr/share/octave/4.2.2/m/statistics/base:/usr/share/octave/4.2.2/m/statistics/distributions:/usr/share/octave/4.2.2/m/statistics/models:/usr/share/octave/4.2.2/m/statistics/tests:/usr/share/octave/4.2.2/m/strings:/usr/share/octave/4.2.2/m/testfun:/usr/share/octave/4.2.2/m/time:/usr/share/octave/4.2.2/data'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeglab_path = '/home/raquib/Documents/MATLAB/eeglab2019_0/functions/'\n",
    "octave.addpath(eeglab_path + 'guifunc')\n",
    "octave.addpath(eeglab_path + 'popfunc')\n",
    "octave.addpath(eeglab_path + 'adminfunc')\n",
    "octave.addpath(eeglab_path + 'sigprocfunc')\n",
    "octave.addpath(eeglab_path + 'miscfunc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eegs = ['data/original/sub03/exp01/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    " 'data/original/sub03/exp01/eeg/SP 110RMT r2/06-clean-prestimulus-hjorth.mat',\n",
    " 'data/original/sub03/exp01/eeg/SP 110RMT r3/06-clean-prestimulus-hjorth.mat',\n",
    " 'data/original/sub03/exp03/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    " 'data/original/sub03/exp03/eeg/SP 110RMT r2/06-clean-prestimulus-hjorth.mat',\n",
    " 'data/original/sub03/exp03/eeg/SP 110RMT r3/06-clean-prestimulus-hjorth.mat',\n",
    " 'data/original/sub04/exp01/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    " 'data/original/sub04/exp01/eeg/SP 110RMT r2/06-clean-prestimulus-hjorth.mat',\n",
    " 'data/original/sub04/exp01/eeg/SP 110RMT r3/06-clean-prestimulus-hjorth.mat',\n",
    "#  'data/original/sub05/exp01/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',  # NO MEP\n",
    "#  'data/original/sub05/exp01/eeg/SP 110RMT r2/06-clean-prestimulus-hjorth.mat',  # NO MEP\n",
    " 'data/original/sub05/exp01/eeg/SP 110RMT r3/06-clean-prestimulus-hjorth.mat',\n",
    " 'data/original/sub06/exp01/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    " 'data/original/sub06/exp01/eeg/SP 110RMT r2/06-clean-prestimulus-hjorth.mat',\n",
    " 'data/original/sub06/exp01/eeg/SP 110RMT r3/06-clean-prestimulus-hjorth.mat',\n",
    " 'data/original/sub06/exp02/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    " 'data/original/sub07/exp01/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    " 'data/original/sub07/exp01/eeg/SP 110RMT r2/06-clean-prestimulus-hjorth.mat',\n",
    " 'data/original/sub07/exp01/eeg/SP 110RMT r3/06-clean-prestimulus-hjorth.mat',\n",
    " 'data/original/sub08/exp01/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    " 'data/original/sub08/exp01/eeg/SP 110RMT r2/06-clean-prestimulus-hjorth.mat',\n",
    " 'data/original/sub08/exp01/eeg/SP 110RMT r3/06-clean-prestimulus-hjorth.mat',\n",
    " 'data/original/sub08/exp02/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    " 'data/original/sub08/exp03/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    " 'data/original/sub08/exp03/eeg/SP 110RMT r2/06-clean-prestimulus-hjorth.mat',\n",
    " 'data/original/sub08/exp03/eeg/SP 110RMT r3/06-clean-prestimulus-hjorth.mat',\n",
    " 'data/original/sub09/exp01/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    " 'data/original/sub10/exp01/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    " 'data/original/sub10/exp02/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    " 'data/original/sub10/exp02/eeg/SP 110RMT r2/06-clean-prestimulus-hjorth.mat',\n",
    " 'data/original/sub10/exp02/eeg/SP 110RMT r3/06-clean-prestimulus-hjorth.mat',\n",
    " 'data/original/sub11/exp01/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    " 'data/original/sub12/exp01/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    " 'data/original/sub12/exp02/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    " 'data/original/sub12/exp03/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    " 'data/original/sub12/exp03/eeg/SP 110RMT r2/06-clean-prestimulus-hjorth.mat',\n",
    " 'data/original/sub12/exp03/eeg/SP 110RMT r3/06-clean-prestimulus-hjorth.mat',\n",
    "#  'data/original/sub13/exp01/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat', # Left handed\n",
    "# 'data/original/sub14/exp01/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',   # BAD MEP\n",
    "#  'data/original/sub14/exp01/eeg/SP 110RMT r2/06-clean-prestimulus-hjorth.mat', # BAD MEP\n",
    "# 'data/original/sub14/exp01/eeg/SP 110RMT r3/06-clean-prestimulus-hjorth.mat',   # BAD MEP\n",
    " 'data/original/sub15/exp01/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    " 'data/original/sub15/exp01/eeg/SP 110RMT r2/06-clean-prestimulus-hjorth.mat',\n",
    " 'data/original/sub15/exp01/eeg/SP 110RMT r3/06-clean-prestimulus-hjorth.mat',\n",
    " 'data/original/sub16/exp01/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    " 'data/original/sub16/exp01/eeg/SP 110RMT r2/06-clean-prestimulus-hjorth.mat',\n",
    " 'data/original/sub16/exp01/eeg/SP 110RMT r3/06-clean-prestimulus-hjorth.mat',\n",
    " 'data/original/sub17/exp01/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    " 'data/original/sub18/exp01/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    " 'data/original/sub18/exp01/eeg/SP 110RMT r2/06-clean-prestimulus-hjorth.mat',\n",
    " 'data/original/sub18/exp01/eeg/SP 110RMT r3/06-clean-prestimulus-hjorth.mat',\n",
    " 'data/original/sub19/exp01/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    " 'data/original/sub19/exp01/eeg/SP 110RMT r2/06-clean-prestimulus-hjorth.mat',\n",
    " 'data/original/sub19/exp01/eeg/SP 110RMT r3/06-clean-prestimulus-hjorth.mat']\n",
    "\n",
    "\n",
    "rejected_trials = [\n",
    "    {'sub': 'sub03', 'exp': 'exp02', 'run': 'r1', 'trial': '*'},\n",
    "    {'sub': 'sub03', 'exp': 'exp02', 'run': 'r2', 'trial': '*'},\n",
    "    {'sub': 'sub05', 'exp': 'exp01', 'run': 'r3', 'trial': '*'},\n",
    "    {'sub': 'sub07', 'exp': 'exp01', 'run': 'r1', 'trial': '*'},\n",
    "    {'sub': 'sub09', 'exp': 'exp01', 'run': 'r1', 'trial': '*'},\n",
    "    {'sub': 'sub10', 'exp': 'exp02', 'run': 'r1', 'trial': '*'},\n",
    "    {'sub': 'sub10', 'exp': 'exp02', 'run': 'r2', 'trial': '*'},\n",
    "    {'sub': 'sub10', 'exp': 'exp02', 'run': 'r3', 'trial': '*'},\n",
    "    {'sub': 'sub11', 'exp': 'exp01', 'run': 'r1', 'trial': '*'},\n",
    "    {'sub': 'sub11', 'exp': 'exp02', 'run': 'r1', 'trial': '*'},\n",
    "    {'sub': 'sub12', 'exp': 'exp01', 'run': 'r1', 'trial': '*'},\n",
    "    {'sub': 'sub15', 'exp': 'exp01', 'run': 'r1', 'trial': '*'},\n",
    "    {'sub': 'sub08', 'exp': 'exp03', 'run': 'r1', 'trial': 0},\n",
    "    {'sub': 'sub09', 'exp': 'exp01', 'run': 'r1', 'trial': 0},\n",
    "    {'sub': 'sub11', 'exp': 'exp02', 'run': 'r1', 'trial': 14},\n",
    "    {'sub': 'sub11', 'exp': 'exp02', 'run': 'r1', 'trial': 38},\n",
    "    {'sub': 'sub12', 'exp': 'exp01', 'run': 'r1', 'trial': 0},\n",
    "    {'sub': 'sub12', 'exp': 'exp02', 'run': 'r1', 'trial': 14},\n",
    "    {'sub': 'sub12', 'exp': 'exp02', 'run': 'r1', 'trial': 36},\n",
    "    {'sub': 'sub12', 'exp': 'exp02', 'run': 'r1', 'trial': 44},\n",
    "    {'sub': 'sub12', 'exp': 'exp03', 'run': 'r1', 'trial': 11},\n",
    "    {'sub': 'sub12', 'exp': 'exp03', 'run': 'r1', 'trial': 15},\n",
    "    {'sub': 'sub12', 'exp': 'exp03', 'run': 'r1', 'trial': 16},\n",
    "    {'sub': 'sub12', 'exp': 'exp03', 'run': 'r1', 'trial': 17},\n",
    "    {'sub': 'sub12', 'exp': 'exp03', 'run': 'r1', 'trial': 24},\n",
    "    {'sub': 'sub12', 'exp': 'exp03', 'run': 'r1', 'trial': 25},\n",
    "    {'sub': 'sub12', 'exp': 'exp03', 'run': 'r1', 'trial': 26},\n",
    "    {'sub': 'sub12', 'exp': 'exp03', 'run': 'r1', 'trial': 27},\n",
    "    {'sub': 'sub12', 'exp': 'exp03', 'run': 'r1', 'trial': 28},\n",
    "    {'sub': 'sub12', 'exp': 'exp03', 'run': 'r1', 'trial': 29},\n",
    "    {'sub': 'sub12', 'exp': 'exp03', 'run': 'r1', 'trial': 30},\n",
    "    {'sub': 'sub12', 'exp': 'exp03', 'run': 'r1', 'trial': 32},\n",
    "    {'sub': 'sub03', 'exp': 'exp01', 'run': 'r2', 'trial': 0},\n",
    "    {'sub': 'sub03', 'exp': 'exp01', 'run': 'r3', 'trial': 0},\n",
    "    {'sub': 'sub03', 'exp': 'exp01', 'run': 'r3', 'trial': 5},\n",
    "    {'sub': 'sub03', 'exp': 'exp01', 'run': 'r3', 'trial': 6},\n",
    "    {'sub': 'sub03', 'exp': 'exp01', 'run': 'r3', 'trial': 8},\n",
    "    {'sub': 'sub04', 'exp': 'exp01', 'run': 'r2', 'trial': 16},\n",
    "    {'sub': 'sub04', 'exp': 'exp01', 'run': 'r2', 'trial': 21},\n",
    "    {'sub': 'sub04', 'exp': 'exp01', 'run': 'r2', 'trial': 22},\n",
    "    {'sub': 'sub04', 'exp': 'exp01', 'run': 'r2', 'trial': 23},\n",
    "    {'sub': 'sub05', 'exp': 'exp01', 'run': 'r3', 'trial': 3},\n",
    "    {'sub': 'sub05', 'exp': 'exp01', 'run': 'r3', 'trial': 4},\n",
    "    {'sub': 'sub05', 'exp': 'exp01', 'run': 'r3', 'trial': 5},\n",
    "    {'sub': 'sub05', 'exp': 'exp01', 'run': 'r3', 'trial': 26},\n",
    "    {'sub': 'sub05', 'exp': 'exp01', 'run': 'r3', 'trial': 3},\n",
    "    {'sub': 'sub05', 'exp': 'exp01', 'run': 'r3', 'trial': 3},\n",
    "    {'sub': 'sub06', 'exp': 'exp01', 'run': 'r2', 'trial': 37},\n",
    "    {'sub': 'sub06', 'exp': 'exp02', 'run': 'r1', 'trial': 0},\n",
    "    {'sub': 'sub07', 'exp': 'exp01', 'run': 'r2', 'trial': 0},\n",
    "    {'sub': 'sub07', 'exp': 'exp01', 'run': 'r2', 'trial': 3},\n",
    "    {'sub': 'sub07', 'exp': 'exp01', 'run': 'r2', 'trial': 11},\n",
    "    {'sub': 'sub07', 'exp': 'exp01', 'run': 'r2', 'trial': 45},\n",
    "    {'sub': 'sub07', 'exp': 'exp01', 'run': 'r2', 'trial': 46},\n",
    "    {'sub': 'sub07', 'exp': 'exp01', 'run': 'r2', 'trial': 47},\n",
    "    {'sub': 'sub07', 'exp': 'exp01', 'run': 'r2', 'trial': 48},\n",
    "    {'sub': 'sub07', 'exp': 'exp01', 'run': 'r2', 'trial': 49},\n",
    "    {'sub': 'sub07', 'exp': 'exp01', 'run': 'r2', 'trial': 38},\n",
    "    {'sub': 'sub07', 'exp': 'exp01', 'run': 'r2', 'trial': 24},\n",
    "    {'sub': 'sub08', 'exp': 'exp02', 'run': 'r1', 'trial': 0},\n",
    "    {'sub': 'sub09', 'exp': 'exp01', 'run': 'r1', 'trial': 0},\n",
    "    {'sub': 'sub09', 'exp': 'exp01', 'run': 'r1', 'trial': 1},\n",
    "    {'sub': 'sub10', 'exp': 'exp01', 'run': 'r1', 'trial': 2},\n",
    "    {'sub': 'sub10', 'exp': 'exp01', 'run': 'r1', 'trial': 26},\n",
    "    {'sub': 'sub10', 'exp': 'exp01', 'run': 'r1', 'trial': 16},\n",
    "    {'sub': 'sub10', 'exp': 'exp01', 'run': 'r1', 'trial': 15},\n",
    "    {'sub': 'sub10', 'exp': 'exp01', 'run': 'r1', 'trial': 12},\n",
    "    {'sub': 'sub10', 'exp': 'exp02', 'run': 'r2', 'trial': 37},\n",
    "    {'sub': 'sub10', 'exp': 'exp02', 'run': 'r2', 'trial': 42},\n",
    "    {'sub': 'sub10', 'exp': 'exp02', 'run': 'r3', 'trial': 23},\n",
    "    {'sub': 'sub10', 'exp': 'exp02', 'run': 'r3', 'trial': 24},\n",
    "    {'sub': 'sub10', 'exp': 'exp02', 'run': 'r3', 'trial': 25},\n",
    "    {'sub': 'sub10', 'exp': 'exp02', 'run': 'r3', 'trial': 26},\n",
    "    {'sub': 'sub10', 'exp': 'exp02', 'run': 'r3', 'trial': 27},\n",
    "    {'sub': 'sub10', 'exp': 'exp02', 'run': 'r3', 'trial': 28},\n",
    "    {'sub': 'sub10', 'exp': 'exp02', 'run': 'r3', 'trial': 29},\n",
    "    {'sub': 'sub10', 'exp': 'exp02', 'run': 'r3', 'trial': 30},\n",
    "    {'sub': 'sub10', 'exp': 'exp02', 'run': 'r3', 'trial': 31},\n",
    "    {'sub': 'sub10', 'exp': 'exp02', 'run': 'r3', 'trial': 32},\n",
    "    {'sub': 'sub10', 'exp': 'exp02', 'run': 'r3', 'trial': 33},\n",
    "    {'sub': 'sub10', 'exp': 'exp02', 'run': 'r3', 'trial': 34},\n",
    "    {'sub': 'sub10', 'exp': 'exp02', 'run': 'r3', 'trial': 35},\n",
    "    {'sub': 'sub10', 'exp': 'exp02', 'run': 'r3', 'trial': 36},\n",
    "    {'sub': 'sub10', 'exp': 'exp02', 'run': 'r3', 'trial': 37},\n",
    "    {'sub': 'sub10', 'exp': 'exp02', 'run': 'r3', 'trial': 38},\n",
    "    {'sub': 'sub10', 'exp': 'exp02', 'run': 'r3', 'trial': 39},\n",
    "    {'sub': 'sub10', 'exp': 'exp02', 'run': 'r3', 'trial': 40},\n",
    "    {'sub': 'sub10', 'exp': 'exp02', 'run': 'r3', 'trial': 41},\n",
    "    {'sub': 'sub10', 'exp': 'exp02', 'run': 'r3', 'trial': 42},\n",
    "    {'sub': 'sub10', 'exp': 'exp02', 'run': 'r3', 'trial': 43},\n",
    "    {'sub': 'sub10', 'exp': 'exp02', 'run': 'r3', 'trial': 44},\n",
    "    {'sub': 'sub10', 'exp': 'exp02', 'run': 'r3', 'trial': 45},\n",
    "    {'sub': 'sub10', 'exp': 'exp02', 'run': 'r3', 'trial': 46},\n",
    "    {'sub': 'sub10', 'exp': 'exp02', 'run': 'r3', 'trial': 47},\n",
    "    {'sub': 'sub10', 'exp': 'exp02', 'run': 'r3', 'trial': 48},\n",
    "    {'sub': 'sub10', 'exp': 'exp02', 'run': 'r3', 'trial': 49},\n",
    "    {'sub': 'sub12', 'exp': 'exp01', 'run': 'r1', 'trial': 0},\n",
    "    {'sub': 'sub12', 'exp': 'exp02', 'run': 'r1', 'trial': 44},\n",
    "    {'sub': 'sub12', 'exp': 'exp02', 'run': 'r1', 'trial': 36},\n",
    "    {'sub': 'sub12', 'exp': 'exp02', 'run': 'r1', 'trial': 14},\n",
    "    {'sub': 'sub12', 'exp': 'exp01', 'run': 'r1', 'trial': 0},\n",
    "    {'sub': 'sub12', 'exp': 'exp02', 'run': 'r1', 'trial': 44},\n",
    "    {'sub': 'sub12', 'exp': 'exp02', 'run': 'r1', 'trial': 14},\n",
    "    {'sub': 'sub09', 'exp': 'exp01', 'run': 'r1', 'trial': 0},\n",
    "    {'sub': 'sub16', 'exp': 'exp01', 'run': 'r3', 'trial': 14},\n",
    "    {'sub': 'sub15', 'exp': 'exp01', 'run': 'r2', 'trial': 36},\n",
    "    {'sub': 'sub15', 'exp': 'exp01', 'run': 'r2', 'trial': 14},\n",
    "    {'sub': 'sub19', 'exp': 'exp01', 'run': 'r1', 'trial': 0}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic I/O and conversions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_eeg(path):\n",
    "    eeg = octave.pop_loadset(path)\n",
    "    new_trial_list = []\n",
    "    for i in range(eeg.data.shape[2]):\n",
    "        trial = eeg.data[:, :, i]\n",
    "        time = np.linspace(-1000, 1000, num=trial.shape[1])\n",
    "        trial = pd.DataFrame(np.transpose(trial), columns=eeg.chanlocs.labels[0])\n",
    "        trial['time'] = time\n",
    "        new_trial_list.append(trial)\n",
    "    return new_trial_list\n",
    "\n",
    "def read_trials_from_mat(filename):\n",
    "    x = loadmat(filename)\n",
    "    mat_trials = x['dat'][0][0][3][0]\n",
    "    trials = []\n",
    "    time = np.linspace(-1000, 1000, len(mat_trials[0][0]))\n",
    "    for mat_trial in mat_trials:\n",
    "        trials.append(pd.DataFrame({'C3': mat_trial[0], 'C4': mat_trial[1], 'time': time}))\n",
    "    return trials\n",
    "\n",
    "def crop_trials(trial_list, duration_millis=500, sampling_rate=2048):\n",
    "    new_trial_list = []\n",
    "    for trial in trial_list:\n",
    "        samples_to_pick = duration_millis * sampling_rate / 1000\n",
    "        new_trial_list.append(trial.tail(int(samples_to_pick)))\n",
    "    return new_trial_list, samples_to_pick\n",
    "\n",
    "def crop_mep_region(mep_frame, crop_start=0.211, crop_end=0.4):\n",
    "    multiplier = 7499 / 1.4998\n",
    "    start = int(crop_start * multiplier)\n",
    "    end = int(crop_end * multiplier)\n",
    "    mep_cropped = mep_frame.iloc[start:end, :]\n",
    "    time = mep_frame.iloc[start:end, :]\n",
    "    return mep_cropped\n",
    "\n",
    "def get_apb_column_name(mep_frame):\n",
    "    if 'L APB' in mep_frame:\n",
    "        return 'L APB'\n",
    "    else:\n",
    "        return 'APB'\n",
    "\n",
    "def open_mep_as_df(path):\n",
    "    fileMep = open(path, \"r+\")\n",
    "    mep_frames = fileMep.read().split('\\n\\n')\n",
    "    df_list = []\n",
    "    for mep_frame in mep_frames:\n",
    "        df_list.append(pd.read_csv(StringIO(mep_frame), '\\t'))\n",
    "    return df_list\n",
    "\n",
    "def get_mep_path(eeg_path):\n",
    "    segments = eeg_path.split('/')\n",
    "    segments[4] = 'mep'\n",
    "    segments = segments[:-1]\n",
    "    mep_path = '/'.join(segments) + '/*.txt'\n",
    "    mep_path = glob.glob(mep_path)[0]\n",
    "    return mep_path\n",
    "\n",
    "def calculate_mep_size(mep_frame):\n",
    "    mep_cropped = crop_mep_region(mep_frame)\n",
    "    apb_name = get_apb_column_name(mep_frame)\n",
    "    max_row = mep_frame.iloc[mep_cropped.idxmax(axis=0)[apb_name]]\n",
    "    min_row = mep_frame.iloc[mep_cropped.idxmin(axis=0)[apb_name]]\n",
    "    mep_size = max_row[apb_name] - min_row[apb_name]\n",
    "    return mep_size, min_row, max_row\n",
    "\n",
    "# Read CMAP file.\n",
    "def read_cmap(path):\n",
    "    df = pd.read_excel(path, sheet_name='Raw data', header=None)\n",
    "    columns = []\n",
    "    ix = 0\n",
    "    for r in df.index.values:\n",
    "        if df[0][r] == 'Channel':\n",
    "            ix = r\n",
    "            break\n",
    "    for c in df.columns.values:\n",
    "        if (df[c][ix] == 2):\n",
    "            columns.append(c)\n",
    "    for r in df.index.values:\n",
    "        if df[0][r] == 'Time (ms)':\n",
    "            ix = r\n",
    "            break\n",
    "    df2 = df[columns].iloc[np.linspace(ix+1, df.shape[0]-2, df.shape[0]-ix-2)]\n",
    "    df2['time'] = df[0].iloc[np.linspace(ix+1, df.shape[0]-2, df.shape[0]-ix-2)]\n",
    "    return df2\n",
    "\n",
    "# Identify CMAP peaks.\n",
    "def find_cmap_peaks(df):\n",
    "    df2 = df[(df['time'] > 105) * (df['time'] < 120)]\n",
    "    time = df2['time']\n",
    "    mean_clean = np.mean(df2.drop('time', axis=1), axis=1)\n",
    "    return mean_clean.max(), mean_clean.min()\n",
    "\n",
    "def get_cmap_path(eeg_path):\n",
    "    segments = eeg_path.split('/')\n",
    "    segments[4] = 'cmap'\n",
    "    del segments[5]\n",
    "    segments = segments[:-1]\n",
    "    cmap_path = '/'.join(segments) + '/*.xlsx'\n",
    "    cmap_paths = glob.glob(cmap_path)\n",
    "    if (len(cmap_paths) == 0):\n",
    "        print('No CMAP found for ' + cmap_path)\n",
    "        return ''\n",
    "    return cmap_paths[0]\n",
    "\n",
    "def get_mep_category_absolute_binary(mep_size):\n",
    "    if mep_size <= .5:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def calculate_mep_categories_binary(mep_sizes):\n",
    "    p1 = np.percentile(mep_sizes, 50)\n",
    "    cat = np.ones(len(mep_sizes)) * (mep_sizes >= p1)\n",
    "    return cat\n",
    "\n",
    "def calculate_mep_categories_cmap_binary(mep_sizes, cmap):\n",
    "    sizes = []\n",
    "    for mep_size in mep_sizes:\n",
    "        sizes.append(mep_size / cmap)\n",
    "    p1 = np.percentile(sizes, 50)\n",
    "    cat = np.ones(len(mep_sizes)) * (sizes >= p1)\n",
    "    return cat\n",
    "\n",
    "def hjorth_transform(trial):\n",
    "    ch = trial[['FC5','FC1','C3','CP5','CP1','FC3','C5','C1','CP3']].values\n",
    "    trial['LTM1'] = np.mean(ch, axis=1)\n",
    "    ch = trial[['FC6','FC2','C4','CP6','CP2','FC4','C6','C2','CP4']].values\n",
    "    trial['RTM1'] = np.mean(ch, axis=1)\n",
    "    ch = trial[['Fp1','AF3','AF7','F1','F3','F5','F7','FC1','FC3', 'FC5']].values\n",
    "    trial['LTDLPFC'] = np.mean(ch, axis=1)\n",
    "    ch = trial[['Fp2','AF4','AF8','F2','F4','F6','F8','FC2','FC4', 'FC6']].values\n",
    "    trial['RTDLPFC'] = np.mean(ch, axis=1)\n",
    "    ch = trial[['Fz','FCz','Cz','F1','FC1','C1','C2','FC2','F2']].values\n",
    "    trial['CNTRL'] = np.mean(ch, axis=1)\n",
    "    ch = trial[['PO7', 'PO5', 'PO3', 'O1']].values\n",
    "    trial['LTOCC'] = np.mean(ch, axis=1)\n",
    "    ch = trial[['PO4', 'PO6', 'PO8', 'O2']].values\n",
    "    trial['RTOCC'] = np.mean(ch, axis=1)\n",
    "    ch = trial[['PO7', 'PO5', 'PO3', 'POz', 'PO4', 'PO6', 'PO8', 'O1', 'Oz', 'O2']].values\n",
    "    trial['OCC'] = np.mean(ch, axis=1)\n",
    "    ch = trial[['P1', 'P3', 'CP1', 'CP3']].values\n",
    "    trial['LTPAR'] = np.mean(ch, axis=1)\n",
    "    ch = trial[['P2', 'P4', 'CP2', 'CP4']].values\n",
    "    trial['RTPAR'] = np.mean(ch, axis=1)\n",
    "    ch = trial[['P1', 'P3', 'CP1', 'CP3', 'P2', 'P4', 'CP2', 'CP4']].values\n",
    "    trial['PAR'] = np.mean(ch, axis=1)\n",
    "    return trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MEP latency and duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mep_latency_duration(mep_frame, plot=False, title=None):    \n",
    "    \n",
    "    # Calculate prestimulus mean amplitude and std.\n",
    "    std_limit = 5\n",
    "    peak_lookup_start_time = .215\n",
    "    apb_name = get_apb_column_name(mep_frame)\n",
    "    cropped = crop_mep_region(mep_frame, crop_start=0, crop_end=0.198)[apb_name]\n",
    "    mean_amp = np.mean(cropped.values)\n",
    "    std = np.std(cropped)\n",
    "    \n",
    "    # Find the index of the first point where amp > 5 SD of mean prestimulus\n",
    "    df_peak = mep_frame[mep_frame['s'] > peak_lookup_start_time]\n",
    "    peak_time = 0\n",
    "    for idx, row in df_peak.iterrows():\n",
    "        if (row[apb_name] > std_limit * std + mean_amp or row[apb_name] < mean_amp - std_limit * std):\n",
    "            peak_time = row['s']\n",
    "            break\n",
    "\n",
    "    latency_absolute = mep_frame[mep_frame['s'] == peak_time]['s'].values[0]\n",
    "    latency = (latency_absolute - 0.2)\n",
    "    \n",
    "    # Calculate the MEP duration.\n",
    "    std_limit = 6\n",
    "    sample_count = mep_frame[mep_frame['s'] < 0.03].shape[0]\n",
    "    df_mean = crop_mep_region(mep_frame, crop_start=0.26, crop_end=0.3)[apb_name]\n",
    "    mean_amp = np.mean(df_mean.values)\n",
    "    std = np.std(df_mean.values)\n",
    "    consecutive_baseline_count = 0\n",
    "    return_to_baseline_time = 0\n",
    "    cropped = crop_mep_region(mep_frame, crop_start=latency_absolute, crop_end=0.3)\n",
    "    for idx, row in cropped.iterrows():\n",
    "        if (row[apb_name] < mean_amp + std_limit * std) and (row[apb_name] > mean_amp - std_limit * std):\n",
    "            if consecutive_baseline_count == 0:\n",
    "                return_to_baseline_time = row['s']\n",
    "            consecutive_baseline_count += 1\n",
    "        else:\n",
    "            consecutive_baseline_count = 0\n",
    "        if consecutive_baseline_count > sample_count:\n",
    "            break\n",
    "    \n",
    "    if plot == True:\n",
    "        plt.figure(figsize=(20,5))\n",
    "        plt.plot(mep_frame.iloc[0:2000]['s'], mep_frame.iloc[0:2000][apb_name])\n",
    "        plt.axvspan(latency_absolute, return_to_baseline_time, color='r', alpha=0.15)\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Amplitude (mV)')\n",
    "        if title != None:\n",
    "            plt.title(title)\n",
    "    return latency, return_to_baseline_time-0.2\n",
    "\n",
    "\n",
    "# Inspect latencies.\n",
    "# for eeg_path in eegs:\n",
    "#     mep_list = open_mep_as_df(get_mep_path(eeg_path))\n",
    "#     i = 0\n",
    "#     for mep_frame in mep_list:\n",
    "#         calculate_mep_latency(mep_frame, plot=True, title=eeg_path + ' - ' + str(i))\n",
    "#         i = i+1\n",
    "#         if i == 2:\n",
    "#             break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power and phase calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blackman_harris_filter(channel, time, cutoffs, fs):\n",
    "    numtaps = 51\n",
    "    b = signal.firwin(numtaps, cutoffs, window='blackmanharris', fs=fs)\n",
    "    filtered = signal.lfilter(b, 1, channel)\n",
    "    delay = 0.5 * (numtaps - 1) / fs\n",
    "    df = pd.DataFrame({\n",
    "        'time': time-delay,\n",
    "        'channel': filtered\n",
    "    })\n",
    "    return df\n",
    "\n",
    "def get_phase(channel, time, band, fs=4096, plot=False):\n",
    "    df_filtered = blackman_harris_filter(channel, time, [0.00001, band[0]], fs)\n",
    "    df_filtered = blackman_harris_filter(df_filtered['channel'].values, df_filtered['time'].values, [band[1], fs/2-1], fs)    \n",
    "    hilb = signal.hilbert(df_filtered[(df_filtered['time'] > -750) * (df_filtered['time'] < -1)]['channel'])\n",
    "    phase = np.angle(hilb, deg=True)\n",
    "    df_phase = pd.DataFrame(phase, columns=['phase'])\n",
    "    df_phase['time'] = df_filtered[(df_filtered['time'] > -750) * (df_filtered['time'] < -1)]['time'].values\n",
    "    \n",
    "    if plot == True:\n",
    "        plt.figure()\n",
    "        plt.plot(df_phase['time'], df_phase['phase'])\n",
    "        plt.plot(df_phase.iloc[-1]['time'], df_phase.iloc[-1]['phase'], 'o')\n",
    "        plt.show()\n",
    "    # df_phase = df_phase[df_phase['time'] <= -20]\n",
    "    return df_phase.iloc[-1]['phase'] + 180\n",
    "\n",
    "\n",
    "def get_power(channel, time, crop_start_millis=-550, fs=500, method='welch'):       \n",
    "    # Crop.\n",
    "    channel = channel[(time > crop_start_millis) * (time < -1)].values\n",
    "    time = time[(time > crop_start_millis) * (time < -1)].values\n",
    "\n",
    "    # Resample.\n",
    "    ts = time[1] - time[0]\n",
    "    secs = len(channel) * ts\n",
    "    secs = secs/1000\n",
    "    resampled = signal.resample(channel, int(secs*fs))\n",
    "    resampled_time = np.linspace(time[0], time[-1], len(resampled))\n",
    "    \n",
    "    # Filter if gamma region.\n",
    "    df_filtered = blackman_harris_filter(resampled, resampled_time, [48, 52], fs)\n",
    "    resampled = df_filtered['channel']\n",
    "    resampled_time = df_filtered['time']\n",
    "    \n",
    "    # PSD.\n",
    "    try:\n",
    "        if method == 'pburg':\n",
    "            # Burgs method\n",
    "            p = pburg(resampled, 200, sampling=fs, NFFT=4096)\n",
    "            power = p.psd\n",
    "            freq = np.linspace(0, fs, len(power))\n",
    "            df_power = pd.DataFrame({'freq': freq, 'power': np.log(power)})\n",
    "        else:\n",
    "            # Welch method\n",
    "            freq, power = signal.welch(resampled, fs, nperseg=fs/2, nfft=2000)\n",
    "            freq_res = freq[1] - freq[0]\n",
    "            df_power = pd.DataFrame({'freq': freq, 'power': np.log(power)})\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "    return df_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.ion()\n",
    "# eeg_path = eegs[30]\n",
    "# files = glob.glob(os.path.dirname(eeg_path) + \"/06-clean-prestimulus-hjorth.mat\")\n",
    "# trials = read_trials_from_mat(os.path.dirname(eeg_path) + \"/06-clean-prestimulus-hjorth.mat\")\n",
    "# trial = trials[20]\n",
    "# df_power = get_power(trial['C3'], trial['time'])\n",
    "# plt.plot(df_power['freq'], df_power['power'])\n",
    "# plt.xlim(6, 100)\n",
    "# plt.show()\n",
    "\n",
    "# df_power = get_power(trials[5]['C3'], trials[5]['time'], method='pburg')\n",
    "# plt.plot(df_power['freq'], df_power['power'])\n",
    "# plt.xlim(6, 100)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_trials(eeg_path):\n",
    "    plt.ioff()\n",
    "    \n",
    "    segments = eeg_path.split('/')\n",
    "    sub = segments[2]\n",
    "    exp = segments[3]\n",
    "    run = segments[5]\n",
    "\n",
    "#     files = glob.glob(os.path.dirname(eeg_path) + \"/06-clean-prestimulus-hjorth.mat\")\n",
    "#     if (len(files) == 0):\n",
    "#         return\n",
    "#     trials = read_trials_from_mat(os.path.dirname(eeg_path) + \"/06-clean-prestimulus-hjorth.mat\")\n",
    "    trials = pickle.load(open(os.path.dirname(eeg_path) + \"/06-clean-prestimulus.p\", \"rb\"))\n",
    "\n",
    "    # Get CMAP.\n",
    "    try:\n",
    "        cmap = read_cmap(get_cmap_path(eeg_path))\n",
    "        time = cmap['time']\n",
    "        cmap_mean = np.mean(cmap.drop('time', axis=1), axis=1)\n",
    "        cmap = pd.DataFrame({'channel': cmap_mean, 'time': time})\n",
    "        cmap2 = cmap[(cmap['time'] > 105) * (cmap['time'] < 120)]\n",
    "        cmap_peak_1 = np.max(cmap2['channel'])\n",
    "        cmap_peak_2 = np.min(cmap2['channel'])\n",
    "        cmap_found = True\n",
    "    except:\n",
    "        cmap_found = False\n",
    "\n",
    "    # Get MEPs.\n",
    "    try:\n",
    "        mep_list = open_mep_as_df(get_mep_path(eeg_path))\n",
    "        mep_found = True\n",
    "    except:\n",
    "        mep_found = False\n",
    "\n",
    "    for i in range(len(trials)):\n",
    "\n",
    "        rejected = False\n",
    "        for rejected in rejected_trials:\n",
    "            if (sub == rejected['sub']) and (exp == rejected['exp']) and (rejected['run'] == run.split(' ')[2]) and ((rejected['trial'] == i) or (rejected['trial'] == '*')):\n",
    "                rejected = True\n",
    "                break\n",
    "\n",
    "        # Plot C3.\n",
    "        trial = trials[i]\n",
    "        fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(23,4))\n",
    "        ax1.plot(trial['time'], trial['C3'])\n",
    "        ax1.set_xlim([np.min(trial['time']), 0])\n",
    "        ax1.set_title('C3 Hjorth')\n",
    "        ax1.set_xlabel('Time (ms)')\n",
    "        ax1.set_ylabel('C3 Amplitude')\n",
    "\n",
    "        # Plot power.\n",
    "        try:\n",
    "            df_power = get_power(trial['C3'], trial['time'], -150, 500, method='welch')\n",
    "            df_power_in_band = df_power[(df_power['freq'] >= 8) * (df_power['freq'] <= 12)]\n",
    "            mean_power = np.mean(df_power_in_band['power'])\n",
    "            df_power_in_band = df_power[(df_power['freq'] >= 13) * (df_power['freq'] <= 30)]\n",
    "            mean_power2 = np.mean(df_power_in_band['power'])\n",
    "\n",
    "            ax2.plot(df_power['freq'], df_power['power'])\n",
    "            ax2.axhline(mean_power, color='r')\n",
    "            ax2.axhline(mean_power2, color='b')\n",
    "            ax2.axvspan(8, 12, color='r', alpha=0.1)\n",
    "            ax2.axvspan(12, 30, color='b', alpha=0.1)\n",
    "            ax2.set_xlim(5, 200)\n",
    "            ax2.set_title('Power spectrum')\n",
    "            ax2.set_xlabel('Frequency (Hz)')\n",
    "            ax2.set_ylabel('Power density')\n",
    "        except:\n",
    "            print('Error calculating power')\n",
    "\n",
    "        # Plot MEP.\n",
    "        try:\n",
    "            if mep_found == True:\n",
    "                mep = mep_list[i]\n",
    "                mep_size, mn, mx = calculate_mep_size(mep)\n",
    "                apb = get_apb_column_name(mep)\n",
    "                latency, duration = calculate_mep_latency_duration(mep, plot=False)\n",
    "                ax3.plot(mep['s'], mep[apb])\n",
    "                ax3.set_xlim([0.15, 0.5])\n",
    "                ax3.axhline(mn[apb], color='r')\n",
    "                ax3.axhline(mx[apb], color='r')\n",
    "                ax3.set_title('MEP: ' + str(mep_size))\n",
    "                ax3.plot(mn['s'], mn[apb], 'o', color='r')\n",
    "                ax3.plot(mx['s'], mx[apb], 'o', color='r')\n",
    "                ax3.axvspan(latency+.2, latency+duration+.2, color='r', alpha=0.1)\n",
    "                ax3.set_xlabel('Time (s)')\n",
    "                ax3.set_ylabel('MEP Amplitude')\n",
    "        except:\n",
    "            print('No MEP found: ' + sub + '/' + exp + '/' + run)\n",
    "\n",
    "        # Plot CMAP.\n",
    "        if cmap_found == True:\n",
    "            ax4.plot(cmap['time'], cmap['channel'])\n",
    "            ax4.set_xlim([75, np.max(cmap['time'])])\n",
    "            ax4.axhline(cmap_peak_1, color='r')\n",
    "            ax4.axhline(cmap_peak_2, color='r')\n",
    "            ax4.set_title('CMAP')\n",
    "            ax4.set_xlabel('Time (ms)')\n",
    "            ax4.set_ylabel('CMAP Amplitude')\n",
    "\n",
    "        title = \"{'sub': '\" + segments[2] + \"', 'exp': '\" + segments[3] + \"', 'run': '\" + segments[5].split(' ')[2] + \"', 'trial': \" + str(i) + \"},\"\n",
    "        plt.suptitle(title)\n",
    "        plt.tight_layout()\n",
    "        if rejected == True:\n",
    "            file_path = 'figs/clean/rejected/' + sub + '/' + exp + '/' + run + '/' + str(i) + '.png'\n",
    "        else:\n",
    "            file_path = 'figs/clean/accepted/' + sub + '/' + exp + '/' + run + '/' + str(i) + '.png'\n",
    "        if not os.path.exists(os.path.dirname(file_path)):\n",
    "            os.makedirs(os.path.dirname(file_path))\n",
    "        plt.savefig(file_path, format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:00<00:00, 136.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "num_cores = multiprocessing.cpu_count()-2\n",
    "r = Parallel(n_jobs=num_cores)(delayed(process_trials)(eeg_path) for eeg_path in tqdm(eegs))\n",
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
