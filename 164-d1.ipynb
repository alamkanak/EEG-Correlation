{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/raquib/anaconda3/envs/tmseeg/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/raquib/anaconda3/envs/tmseeg/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "from io import StringIO\n",
    "import mne\n",
    "from mne.io import read_raw_eeglab, read_epochs_eeglab\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from scipy import fftpack\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "# from tqdm import tqdm, tqdm_notebook\n",
    "from tqdm.notebook import tqdm\n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from livelossplot.tf_keras import PlotLossesCallback\n",
    "\n",
    "import sklearn.model_selection\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "import multiprocessing\n",
    "from tpot import TPOTRegressor\n",
    "from oct2py import octave\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from joblib import wrap_non_picklable_objects\n",
    "import json\n",
    "import pickle\n",
    "import os.path\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import timeit\n",
    "from skimage.transform import resize\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, optimizers, callbacks\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.genmod import bayes_mixed_glm as glm\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import RFECV\n",
    "from spectrum import arburg, arma2psd, pburg\n",
    "import pylab\n",
    "from scipy.signal import find_peaks, butter\n",
    "from scipy.integrate import simps\n",
    "from scipy.io import loadmat\n",
    "from numpy import trapz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare paths of EEG files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_clean_hjorth = [\n",
    "    'data/dataset1/original/sub02/exp01/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub02/exp01/eeg/SP 110RMT r2/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub02/exp01/eeg/SP 110RMT r3/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub03/exp03/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub03/exp03/eeg/SP 110RMT r2/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub03/exp03/eeg/SP 110RMT r3/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub04/exp02/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub04/exp02/eeg/SP 110RMT r2/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub04/exp02/eeg/SP 110RMT r3/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub05/exp02/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub05/exp02/eeg/SP 110RMT r2/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub05/exp02/eeg/SP 110RMT r3/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub06/exp01/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub06/exp01/eeg/SP 110RMT r2/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub06/exp01/eeg/SP 110RMT r3/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub07/exp01/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub07/exp01/eeg/SP 110RMT r2/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub07/exp01/eeg/SP 110RMT r3/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub08/exp03/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub08/exp03/eeg/SP 110RMT r2/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub08/exp03/eeg/SP 110RMT r3/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub10/exp02/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub10/exp02/eeg/SP 110RMT r2/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub10/exp02/eeg/SP 110RMT r3/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub12/exp03/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub12/exp03/eeg/SP 110RMT r2/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub12/exp03/eeg/SP 110RMT r3/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub13/exp02/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub13/exp02/eeg/SP 110RMT r2/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub13/exp02/eeg/SP 110RMT r3/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub15/exp01/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub15/exp01/eeg/SP 110RMT r2/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub15/exp01/eeg/SP 110RMT r3/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub16/exp01/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub16/exp01/eeg/SP 110RMT r2/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub16/exp01/eeg/SP 110RMT r3/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub17/exp01/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub17/exp01/eeg/SP 110RMT r2/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub17/exp01/eeg/SP 110RMT r3/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub18/exp01/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub18/exp01/eeg/SP 110RMT r2/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub18/exp01/eeg/SP 110RMT r3/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub19/exp01/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub19/exp01/eeg/SP 110RMT r2/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub19/exp01/eeg/SP 110RMT r3/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub20/exp01/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub20/exp01/eeg/SP 110RMT r2/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub20/exp01/eeg/SP 110RMT r3/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub21/exp01/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub21/exp01/eeg/SP 110RMT r2/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub21/exp01/eeg/SP 110RMT r3/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub22/exp01/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub22/exp01/eeg/SP 110RMT r2/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub22/exp01/eeg/SP 110RMT r3/06-clean-prestimulus-hjorth.mat'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = []\n",
    "for path in paths_clean_hjorth:\n",
    "    paths.append({\n",
    "        'clean_hjorth': path,\n",
    "        'clean_raw': path[0:-31] + '06-clean-prestimulus.p',\n",
    "        'hjorth': path[0:-31] + '010-raw-hjorth.mat',\n",
    "        'raw': path[0:-31] + 'raw.p',\n",
    "    })\n",
    "df_paths = pd.DataFrame(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic I/O and conversions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_trials_from_mat(filename):\n",
    "    x = loadmat(filename)\n",
    "    mat_trials = x['dat'][0][0][3][0]\n",
    "    trials = []\n",
    "    time = np.linspace(-1000, 1000, len(mat_trials[0][0]))\n",
    "    for mat_trial in mat_trials:\n",
    "        trials.append(pd.DataFrame({'C3': mat_trial[0], 'C4': mat_trial[1], 'time': time}))\n",
    "    return trials\n",
    "\n",
    "def crop_mep_region(mep_frame, crop_start=0.211, crop_end=0.4):\n",
    "    multiplier = 7499 / 1.4998\n",
    "    start = int(crop_start * multiplier)\n",
    "    end = int(crop_end * multiplier)\n",
    "    mep_cropped = mep_frame.iloc[start:end, :]\n",
    "    time = mep_frame.iloc[start:end, :]\n",
    "    return mep_cropped\n",
    "\n",
    "def get_apb_column_name(mep_frame):\n",
    "    if 'L APB' in mep_frame:\n",
    "        return 'L APB'\n",
    "    else:\n",
    "        return 'APB'\n",
    "\n",
    "def open_mep_as_df(path):\n",
    "    fileMep = open(path, \"r+\")\n",
    "    mep_frames = fileMep.read().split('\\n\\n')\n",
    "    df_list = []\n",
    "    for mep_frame in mep_frames:\n",
    "        df_list.append(pd.read_csv(StringIO(mep_frame), '\\t'))\n",
    "    return df_list\n",
    "\n",
    "def get_mep_path(eeg_path):\n",
    "    segments = eeg_path.split('/')\n",
    "    segments[5] = 'mep'\n",
    "    segments = segments[:-1]\n",
    "    mep_path = '/'.join(segments) + '/*.txt'\n",
    "    mep_path = glob.glob(mep_path)[0]\n",
    "    return mep_path\n",
    "\n",
    "def calculate_mep_size(mep_frame, latency, duration):\n",
    "    mep_cropped = crop_mep_region(mep_frame, latency, latency + duration)\n",
    "    apb_name = get_apb_column_name(mep_frame)\n",
    "    max_row = mep_frame.iloc[mep_cropped.idxmax(axis=0)[apb_name]]\n",
    "    min_row = mep_frame.iloc[mep_cropped.idxmin(axis=0)[apb_name]]\n",
    "    mep_size = max_row[apb_name] - min_row[apb_name]\n",
    "    return mep_size, min_row, max_row\n",
    "\n",
    "def read_latency_duration(eeg_path):\n",
    "    segments = eeg_path.split('/')\n",
    "    sub = segments[3]\n",
    "    exp = segments[4]\n",
    "    run = segments[6]\n",
    "    path = 'data/dataset1/original/' + sub + '/' + exp + '/mep/' + run + '/01-ld.csv'\n",
    "    files = glob.glob(path)\n",
    "    if len(files) < 1:\n",
    "        return False\n",
    "    fileMep = open(path, \"r+\")\n",
    "    lines = fileMep.read().split('\\n')\n",
    "    df_ld = []\n",
    "    for frame_txt in lines:\n",
    "        if 'Frame' in frame_txt:\n",
    "            continue\n",
    "        segments = frame_txt.split('\\t')\n",
    "        if len(segments) >= 4:\n",
    "            df_ld.append({\n",
    "                'trial_num': int(segments[0])-1,\n",
    "                'latency': float(segments[2]),\n",
    "                'duration': float(segments[3]) - float(segments[2])\n",
    "            })\n",
    "    return pd.DataFrame(df_ld)\n",
    "\n",
    "def calculate_mep_area(mep_frame, latency, duration, plot=False):\n",
    "    apb_name = get_apb_column_name(mep_frame)\n",
    "    mep_frame = mep_frame[(mep_frame['s'] >= latency) * (mep_frame['s'] <= latency + duration)]\n",
    "    amplitude = mep_frame[apb_name]\n",
    "    amplitude = np.abs(amplitude)\n",
    "    time_diff = mep_frame['s'].iloc[1] - mep_frame['s'].iloc[0]\n",
    "    area = trapz(amplitude, dx=time_diff)\n",
    "    if (plot == True):\n",
    "        plt.plot(mep_frame['s'], amplitude)\n",
    "    return area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power and phase calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blackman_harris_filter(channel, time, cutoffs, fs, numtaps=801):\n",
    "    b = signal.firwin(numtaps, cutoffs, window='blackmanharris', fs=fs)\n",
    "    filtered = signal.lfilter(b, 1, channel)\n",
    "    delay = 0.5 * (numtaps - 1) / fs\n",
    "    df = pd.DataFrame({\n",
    "        'time': time-delay,\n",
    "        'channel': filtered\n",
    "    })\n",
    "    return df\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, btype='bandpass', order=4):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype=btype)\n",
    "    y = signal.lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "def get_phase(channel, time, band, fs, filter_type='butter', start_time_ms=-750, stop_time_ms=-2):\n",
    "    if filter_type=='butter':\n",
    "        df_filtered = pd.DataFrame({'channel': butter_bandpass_filter(channel, band[0], band[1], fs), 'time': time})\n",
    "    else:\n",
    "        df_filtered = blackman_harris_filter(channel, time, [0.000001, band[0]], fs)\n",
    "        df_filtered = blackman_harris_filter(df_filtered['channel'].values, df_filtered['time'].values, band[1], fs)    \n",
    "    \n",
    "    hilb = signal.hilbert(df_filtered[(df_filtered['time'] > start_time_ms) * (df_filtered['time'] < stop_time_ms)]['channel'])\n",
    "    phase = np.angle(hilb, deg=True)\n",
    "    df_phase = pd.DataFrame(phase, columns=['phase'])\n",
    "    df_phase['time'] = df_filtered[(df_filtered['time'] > start_time_ms) * (df_filtered['time'] < stop_time_ms)]['time'].values\n",
    "    \n",
    "    return df_phase.iloc[-1]['phase'] + 180\n",
    "\n",
    "def get_power(channel, time, fs, crop_start_millis=-150, method='pburg', filter_type='butter', resample=True):       \n",
    "    # Crop.\n",
    "    channel = channel[(time > crop_start_millis) * (time < -1)].values\n",
    "    time = time[(time > crop_start_millis) * (time < -1)].values\n",
    "\n",
    "    # Resample.\n",
    "    if resample:\n",
    "        ts = time[1] - time[0]\n",
    "        secs = len(channel) * ts\n",
    "        secs = secs/1000\n",
    "        resampled = signal.resample(channel, int(secs*fs))\n",
    "        resampled_time = np.linspace(time[0], time[-1], len(resampled))\n",
    "    else:\n",
    "        resampled = channel\n",
    "        resampled_time = time\n",
    "    \n",
    "    # Filer to get rid of line noise.\n",
    "    if filter_type == 'butter':\n",
    "        resampled = butter_bandpass_filter(resampled, 48, 52, fs, 'bandstop')\n",
    "        resampled_time = resampled_time\n",
    "    else:\n",
    "        df_filtered = blackman_harris_filter(resampled, resampled_time, [48, 52], fs, numtaps=101)\n",
    "        resampled = df_filtered['channel']\n",
    "        resampled_time = df_filtered['time']\n",
    "    \n",
    "    # PSD.\n",
    "    try:\n",
    "        if method == 'welch':\n",
    "            # Welch method\n",
    "            freq, power = signal.welch(resampled, fs, nfft=2*fs)\n",
    "            freq_res = freq[1] - freq[0]\n",
    "            df_power = pd.DataFrame({'freq': freq, 'power': 10*np.log10(power)})\n",
    "        elif method == 'fft':\n",
    "            # FFT method\n",
    "            power = np.abs(np.fft.fft(resampled, n=2*fs))\n",
    "            freq = np.linspace(0, fs, len(power))\n",
    "            df_power = pd.DataFrame({'freq': freq, 'power': 10*np.log10(power)})\n",
    "        elif method == 'pburg':\n",
    "            # Burgs method\n",
    "            p = pburg(resampled, int(len(resampled)*.5), sampling=fs, NFFT=2000)\n",
    "            power = p.psd\n",
    "            freq = np.linspace(0, fs, len(power))\n",
    "            df_power = pd.DataFrame({'freq': freq, 'power': 10*np.log10(power)})\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "    df_power = df_power[df_power['freq'] < fs/2]\n",
    "    return df_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row = df_paths.iloc[10]\n",
    "# trials = read_trials_from_mat(row['hjorth'])\n",
    "# trial = trials[10]\n",
    "# for filter_type in ['butter', 'blackmann']:\n",
    "#     df_power = get_power(trial['C3'], trial['time'], 2048, method='pburg', filter_type=filter_type, resample=False)\n",
    "#     df_power = df_power[df_power['freq'] < 80]\n",
    "#     df_power = df_power[df_power['freq'] > 3.5]\n",
    "#     plt.plot(df_power['freq'], df_power['power'])\n",
    "#     plt.title(filter_type)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine EEG and others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_block(path_raw, path_hjorth, path_clean_raw, path_clean_hjorth):\n",
    "    powers = []\n",
    "    phases = []\n",
    "    for artifact_removed, eeg_type, path, fs in zip([False, False, True, True, True], ['Raw', 'Hjorth', 'Raw', 'Hjorth', 'Averaged'], [path_raw, path_hjorth, path_clean_raw, path_clean_hjorth, path_clean_raw], [4096, 4096, 2048, 2048, 2048]):\n",
    "        # Read EEG file.\n",
    "        sub = path.split('/')[3]\n",
    "        exp = path.split('/')[4]\n",
    "        run = path.split('/')[6]\n",
    "        if eeg_type == 'Hjorth':\n",
    "            trials = read_trials_from_mat(path)\n",
    "        else:\n",
    "            trials = pickle.load(open(path, \"rb\"))\n",
    "            \n",
    "        # Select channel name.\n",
    "        if sub in ['sub13', 'sub02']:\n",
    "            channel = 'C4'\n",
    "        else:\n",
    "            channel = 'C3'\n",
    "            \n",
    "        # Calculate average of M1 electrodes.\n",
    "        if eeg_type == 'Averaged':\n",
    "            new_trials = []\n",
    "            for trial in trials:\n",
    "                trial['C3'] = trial[['FC5', 'FC3', 'FC1', 'C5', 'C3', 'C1', 'CP5', 'CP3', 'CP1']].mean(axis=1)\n",
    "                trial['C4'] = trial[['FC6', 'FC4', 'FC2', 'C6', 'C4', 'C2', 'CP6', 'CP4', 'CP2']].mean(axis=1)\n",
    "                new_trials.append(trial)\n",
    "            trials = new_trials\n",
    "            \n",
    "        # Read latency duration.\n",
    "        df_ld = read_latency_duration(path)\n",
    "\n",
    "        # Calculate powers and phases. And combine the results in a df list.\n",
    "        for trial_num in df_ld['trial_num'].values:\n",
    "            if len(trials)-1 < trial_num:\n",
    "                continue\n",
    "            trial = trials[trial_num]\n",
    "            \n",
    "            # Calculate MEP parameters.\n",
    "            ld_row = df_ld[df_ld['trial_num'] == trial_num].iloc[0]\n",
    "            latency = ld_row['latency']\n",
    "            duration = ld_row['duration']\n",
    "            mep_frame = open_mep_as_df(get_mep_path(path))[trial_num]\n",
    "            mep_size, _, _ = calculate_mep_size(mep_frame, latency, duration)\n",
    "            mep_area = calculate_mep_area(mep_frame, latency, duration)\n",
    "            \n",
    "            # PSD and phase calculation.\n",
    "            for filter_name, filter_code in zip(['Blackmann-Harris', 'Butterworth'], ['butter', 'blackmann-harris']):\n",
    "\n",
    "                # PSD Calculation.\n",
    "                for resampled, resample_fs in zip([True, False], [512, fs]):\n",
    "                    for time in [-150, -750]:\n",
    "                        for method_name, method_code in zip(['FFT', 'Welch', 'Burg'], ['fft', 'welch', 'pburg']):\n",
    "                            df_power = get_power(trial[channel], trial['time'], method=method_code, filter_type=filter_code, crop_start_millis=time, fs=resample_fs, resample=resampled)\n",
    "                            for band, fc in zip(['Theta', 'Mu', 'Beta', 'Gamma'], [[3.5, 8], [8, 12], [13, 30], [30, 80]]):\n",
    "                                powers.append({\n",
    "                                    'sub': sub,\n",
    "                                    'exp': exp,\n",
    "                                    'run': run,\n",
    "                                    'trial': trial_num,\n",
    "                                    'ArtifactRemoved': artifact_removed,\n",
    "                                    'EEG': eeg_type,\n",
    "                                    'Resampled': resampled,\n",
    "                                    'Filter': filter_name,\n",
    "                                    'Time': time,\n",
    "                                    'Method': method_name,\n",
    "                                    'Band': band,\n",
    "                                    'Power': df_power[(df_power['freq'] >= fc[0]) * (df_power['freq'] < fc[1])]['power'].mean(),\n",
    "                                    'mep_latency': latency,\n",
    "                                    'mep_duration': duration,\n",
    "                                    'mep_area': mep_area\n",
    "                                })\n",
    "                                \n",
    "                for band, fc in zip(['Theta', 'Mu', 'Beta', 'Gamma'], [[3.5, 8], [8, 12], [13, 30], [30, 80]]):\n",
    "                    phases.append({\n",
    "                        'sub': sub,\n",
    "                        'exp': exp,\n",
    "                        'run': run,\n",
    "                        'trial': trial_num,\n",
    "                        'ArtifactRemoved': artifact_removed,\n",
    "                        'EEG': eeg_type,\n",
    "                        'Filter': filter_name,\n",
    "                        'Band': band,\n",
    "                        'Phase': get_phase(trial[channel], trial['time'], [fc[0], fc[1]], filter_type=filter_code, fs=fs),\n",
    "                        'mep_latency': latency,\n",
    "                        'mep_duration': duration,\n",
    "                        'mep_area': mep_area,\n",
    "                    })\n",
    "    return (powers, phases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec62e55b8a534a97a4245df11bf20137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=54.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run analysis\n",
    "paths = [list(a) for a in zip(df_paths['raw'].values, df_paths['hjorth'].values, df_paths['clean_raw'].values, df_paths['clean_hjorth'].values)]\n",
    "num_cores = multiprocessing.cpu_count() - 2\n",
    "results = Parallel(n_jobs=num_cores)(delayed(process_block)(path_raw, path_hjorth, path_clean_raw, path_clean_hjorth) for path_raw, path_hjorth, path_clean_raw, path_clean_hjorth in tqdm(paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b0ee649404743ce960950c3f363b0ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=54.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_powers = []\n",
    "df_phases = []\n",
    "for powers, phases in tqdm(results):\n",
    "    for power in powers:\n",
    "        df_powers.append(power)\n",
    "    for phase in phases:\n",
    "        df_phases.append(phase)\n",
    "\n",
    "df_powers = pd.DataFrame(df_powers)\n",
    "df_phases = pd.DataFrame(df_phases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecb06d9920ee4a26a7709c3c2d636a2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(1285440, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArtifactRemoved</th>\n",
       "      <th>Band</th>\n",
       "      <th>EEG</th>\n",
       "      <th>Filter</th>\n",
       "      <th>Method</th>\n",
       "      <th>Power</th>\n",
       "      <th>Resampled</th>\n",
       "      <th>Time</th>\n",
       "      <th>exp</th>\n",
       "      <th>mep_area</th>\n",
       "      <th>mep_duration</th>\n",
       "      <th>mep_latency</th>\n",
       "      <th>run</th>\n",
       "      <th>sub</th>\n",
       "      <th>trial</th>\n",
       "      <th>trial_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>Theta</td>\n",
       "      <td>Raw</td>\n",
       "      <td>Blackmann-Harris</td>\n",
       "      <td>FFT</td>\n",
       "      <td>41.365676</td>\n",
       "      <td>True</td>\n",
       "      <td>-150</td>\n",
       "      <td>exp01</td>\n",
       "      <td>0.006262</td>\n",
       "      <td>0.1634</td>\n",
       "      <td>0.2212</td>\n",
       "      <td>SP 110RMT r1</td>\n",
       "      <td>sub02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>Mu</td>\n",
       "      <td>Raw</td>\n",
       "      <td>Blackmann-Harris</td>\n",
       "      <td>FFT</td>\n",
       "      <td>40.135540</td>\n",
       "      <td>True</td>\n",
       "      <td>-150</td>\n",
       "      <td>exp01</td>\n",
       "      <td>0.006262</td>\n",
       "      <td>0.1634</td>\n",
       "      <td>0.2212</td>\n",
       "      <td>SP 110RMT r1</td>\n",
       "      <td>sub02</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>Beta</td>\n",
       "      <td>Raw</td>\n",
       "      <td>Blackmann-Harris</td>\n",
       "      <td>FFT</td>\n",
       "      <td>35.602548</td>\n",
       "      <td>True</td>\n",
       "      <td>-150</td>\n",
       "      <td>exp01</td>\n",
       "      <td>0.006262</td>\n",
       "      <td>0.1634</td>\n",
       "      <td>0.2212</td>\n",
       "      <td>SP 110RMT r1</td>\n",
       "      <td>sub02</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>Gamma</td>\n",
       "      <td>Raw</td>\n",
       "      <td>Blackmann-Harris</td>\n",
       "      <td>FFT</td>\n",
       "      <td>32.033988</td>\n",
       "      <td>True</td>\n",
       "      <td>-150</td>\n",
       "      <td>exp01</td>\n",
       "      <td>0.006262</td>\n",
       "      <td>0.1634</td>\n",
       "      <td>0.2212</td>\n",
       "      <td>SP 110RMT r1</td>\n",
       "      <td>sub02</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>Theta</td>\n",
       "      <td>Raw</td>\n",
       "      <td>Blackmann-Harris</td>\n",
       "      <td>Welch</td>\n",
       "      <td>26.367312</td>\n",
       "      <td>True</td>\n",
       "      <td>-150</td>\n",
       "      <td>exp01</td>\n",
       "      <td>0.006262</td>\n",
       "      <td>0.1634</td>\n",
       "      <td>0.2212</td>\n",
       "      <td>SP 110RMT r1</td>\n",
       "      <td>sub02</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ArtifactRemoved   Band  EEG            Filter Method      Power  Resampled  \\\n",
       "0            False  Theta  Raw  Blackmann-Harris    FFT  41.365676       True   \n",
       "1            False     Mu  Raw  Blackmann-Harris    FFT  40.135540       True   \n",
       "2            False   Beta  Raw  Blackmann-Harris    FFT  35.602548       True   \n",
       "3            False  Gamma  Raw  Blackmann-Harris    FFT  32.033988       True   \n",
       "4            False  Theta  Raw  Blackmann-Harris  Welch  26.367312       True   \n",
       "\n",
       "   Time    exp  mep_area  mep_duration  mep_latency           run    sub  \\\n",
       "0  -150  exp01  0.006262        0.1634       0.2212  SP 110RMT r1  sub02   \n",
       "1  -150  exp01  0.006262        0.1634       0.2212  SP 110RMT r1  sub02   \n",
       "2  -150  exp01  0.006262        0.1634       0.2212  SP 110RMT r1  sub02   \n",
       "3  -150  exp01  0.006262        0.1634       0.2212  SP 110RMT r1  sub02   \n",
       "4  -150  exp01  0.006262        0.1634       0.2212  SP 110RMT r1  sub02   \n",
       "\n",
       "   trial  trial_abs  \n",
       "0      0          1  \n",
       "1      0          2  \n",
       "2      0          3  \n",
       "3      0          4  \n",
       "4      0          5  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = []\n",
    "for sub in tqdm(df_powers['sub'].unique()):\n",
    "    df = df_powers[df_powers['sub'] == sub]\n",
    "    i = 1\n",
    "    for idx, row in df.iterrows():\n",
    "        row['trial_abs'] = i\n",
    "        i = i + 1\n",
    "        df_new.append(row)\n",
    "df_powers = pd.DataFrame(df_new)\n",
    "print(df_powers.shape)\n",
    "df_powers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_powers.to_csv('164-d1-powers.csv')\n",
    "df_phases.to_csv('164-d1-phases.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
