{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/raquib/anaconda3/envs/tmseeg/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/raquib/anaconda3/envs/tmseeg/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "from io import StringIO\n",
    "import mne\n",
    "from mne.io import read_raw_eeglab, read_epochs_eeglab\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from scipy import fftpack\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "# from tqdm import tqdm, tqdm_notebook\n",
    "from tqdm.notebook import tqdm\n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from livelossplot.tf_keras import PlotLossesCallback\n",
    "\n",
    "import sklearn.model_selection\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "import multiprocessing\n",
    "from tpot import TPOTRegressor\n",
    "from oct2py import octave\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from joblib import wrap_non_picklable_objects\n",
    "import json\n",
    "import pickle\n",
    "import os.path\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import timeit\n",
    "from skimage.transform import resize\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, optimizers, callbacks\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.genmod import bayes_mixed_glm as glm\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import RFECV\n",
    "from spectrum import arburg, arma2psd, pburg\n",
    "import pylab\n",
    "from scipy.signal import find_peaks, butter\n",
    "from scipy.integrate import simps\n",
    "from scipy.io import loadmat\n",
    "from numpy import trapz\n",
    "import scipy.fftpack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare paths of EEG files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_clean_hjorth = [\n",
    "    'data/dataset1/original/sub02/exp01/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub02/exp01/eeg/SP 110RMT r2/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub02/exp01/eeg/SP 110RMT r3/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub03/exp03/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub03/exp03/eeg/SP 110RMT r2/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub03/exp03/eeg/SP 110RMT r3/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub04/exp02/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub04/exp02/eeg/SP 110RMT r2/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub04/exp02/eeg/SP 110RMT r3/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub05/exp02/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub05/exp02/eeg/SP 110RMT r2/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub05/exp02/eeg/SP 110RMT r3/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub06/exp01/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub06/exp01/eeg/SP 110RMT r2/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub06/exp01/eeg/SP 110RMT r3/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub07/exp01/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub07/exp01/eeg/SP 110RMT r2/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub07/exp01/eeg/SP 110RMT r3/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub08/exp03/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub08/exp03/eeg/SP 110RMT r2/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub08/exp03/eeg/SP 110RMT r3/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub10/exp02/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub10/exp02/eeg/SP 110RMT r2/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub10/exp02/eeg/SP 110RMT r3/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub12/exp03/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub12/exp03/eeg/SP 110RMT r2/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub12/exp03/eeg/SP 110RMT r3/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub13/exp02/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub13/exp02/eeg/SP 110RMT r2/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub13/exp02/eeg/SP 110RMT r3/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub15/exp01/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub15/exp01/eeg/SP 110RMT r2/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub15/exp01/eeg/SP 110RMT r3/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub16/exp01/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub16/exp01/eeg/SP 110RMT r2/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub16/exp01/eeg/SP 110RMT r3/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub17/exp01/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub17/exp01/eeg/SP 110RMT r2/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub17/exp01/eeg/SP 110RMT r3/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub18/exp01/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub18/exp01/eeg/SP 110RMT r2/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub18/exp01/eeg/SP 110RMT r3/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub19/exp01/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub19/exp01/eeg/SP 110RMT r2/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub19/exp01/eeg/SP 110RMT r3/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub20/exp01/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub20/exp01/eeg/SP 110RMT r2/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub20/exp01/eeg/SP 110RMT r3/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub21/exp01/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub21/exp01/eeg/SP 110RMT r2/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub21/exp01/eeg/SP 110RMT r3/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub22/exp01/eeg/SP 110RMT r1/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub22/exp01/eeg/SP 110RMT r2/06-clean-prestimulus-hjorth.mat',\n",
    "    'data/dataset1/original/sub22/exp01/eeg/SP 110RMT r3/06-clean-prestimulus-hjorth.mat'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = []\n",
    "for path in paths_clean_hjorth:\n",
    "    paths.append({\n",
    "        'clean_hjorth': path,\n",
    "        'clean_raw': path[0:-31] + '06-clean-prestimulus.p',\n",
    "        'hjorth': path[0:-31] + '010-raw-hjorth.mat',\n",
    "        'raw': path[0:-31] + 'raw.p',\n",
    "    })\n",
    "df_paths = pd.DataFrame(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic I/O and conversions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_trials_from_mat(filename):\n",
    "    x = loadmat(filename)\n",
    "    mat_trials = x['dat'][0][0][3][0]\n",
    "    trials = []\n",
    "    time = np.linspace(-1000, 1000, len(mat_trials[0][0]))\n",
    "    for mat_trial in mat_trials:\n",
    "        trials.append(pd.DataFrame({'C3': mat_trial[0], 'C4': mat_trial[1], 'time': time}))\n",
    "    return trials\n",
    "\n",
    "def crop_mep_region(mep_frame, crop_start=0.211, crop_end=0.4):\n",
    "    multiplier = 7499 / 1.4998\n",
    "    start = int(crop_start * multiplier)\n",
    "    end = int(crop_end * multiplier)\n",
    "    mep_cropped = mep_frame.iloc[start:end, :]\n",
    "    time = mep_frame.iloc[start:end, :]\n",
    "    return mep_cropped\n",
    "\n",
    "def get_apb_column_name(mep_frame):\n",
    "    if 'L APB' in mep_frame:\n",
    "        return 'L APB'\n",
    "    else:\n",
    "        return 'APB'\n",
    "\n",
    "def open_mep_as_df(path):\n",
    "    fileMep = open(path, \"r+\")\n",
    "    mep_frames = fileMep.read().split('\\n\\n')\n",
    "    df_list = []\n",
    "    for mep_frame in mep_frames:\n",
    "        df_list.append(pd.read_csv(StringIO(mep_frame), '\\t'))\n",
    "    return df_list\n",
    "\n",
    "def get_mep_path(eeg_path):\n",
    "    segments = eeg_path.split('/')\n",
    "    segments[5] = 'mep'\n",
    "    segments = segments[:-1]\n",
    "    mep_path = '/'.join(segments) + '/*.txt'\n",
    "    mep_path = glob.glob(mep_path)[0]\n",
    "    return mep_path\n",
    "\n",
    "def calculate_mep_size(mep_frame, latency, duration):\n",
    "    mep_cropped = crop_mep_region(mep_frame, latency, latency + duration)\n",
    "    apb_name = get_apb_column_name(mep_frame)\n",
    "    max_row = mep_frame.iloc[mep_cropped.idxmax(axis=0)[apb_name]]\n",
    "    min_row = mep_frame.iloc[mep_cropped.idxmin(axis=0)[apb_name]]\n",
    "    mep_size = max_row[apb_name] - min_row[apb_name]\n",
    "    return mep_size, min_row, max_row\n",
    "\n",
    "def read_latency_duration(eeg_path):\n",
    "    segments = eeg_path.split('/')\n",
    "    sub = segments[3]\n",
    "    exp = segments[4]\n",
    "    run = segments[6]\n",
    "    path = 'data/dataset1/original/' + sub + '/' + exp + '/mep/' + run + '/01-ld.csv'\n",
    "    files = glob.glob(path)\n",
    "    if len(files) < 1:\n",
    "        return False\n",
    "    fileMep = open(path, \"r+\")\n",
    "    lines = fileMep.read().split('\\n')\n",
    "    df_ld = []\n",
    "    for frame_txt in lines:\n",
    "        if 'Frame' in frame_txt:\n",
    "            continue\n",
    "        segments = frame_txt.split('\\t')\n",
    "        if len(segments) >= 4:\n",
    "            df_ld.append({\n",
    "                'trial_num': int(segments[0])-1,\n",
    "                'latency': float(segments[2]),\n",
    "                'duration': float(segments[3]) - float(segments[2])\n",
    "            })\n",
    "    return pd.DataFrame(df_ld)\n",
    "\n",
    "def calculate_mep_area(mep_frame, latency, duration, plot=False):\n",
    "    apb_name = get_apb_column_name(mep_frame)\n",
    "    mep_frame = mep_frame[(mep_frame['s'] >= latency) * (mep_frame['s'] <= latency + duration)]\n",
    "    amplitude = mep_frame[apb_name]\n",
    "    amplitude = np.abs(amplitude)\n",
    "    time_diff = mep_frame['s'].iloc[1] - mep_frame['s'].iloc[0]\n",
    "    area = trapz(amplitude, dx=time_diff)\n",
    "    if (plot == True):\n",
    "        plt.plot(mep_frame['s'], amplitude)\n",
    "    return area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power and phase calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blackman_harris_filter(channel, time, cutoffs, fs, numtaps):\n",
    "    b = signal.firwin(numtaps, cutoffs, window='blackmanharris', fs=fs)\n",
    "    filtered = signal.lfilter(b, 1, channel)\n",
    "    delay = 0.5 * (numtaps - 1) / fs\n",
    "    df = pd.DataFrame({\n",
    "        'time': time-delay,\n",
    "        'channel': filtered\n",
    "    })\n",
    "    return df\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, btype, order):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype=btype)\n",
    "    y = signal.lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "def get_phase(channel, time, band, fs, filter_type, start_time_ms, stop_time_ms, blackmann_harris_ntaps):\n",
    "    if filter_type=='butter':\n",
    "        df_filtered = pd.DataFrame({'channel': butter_bandpass_filter(channel, band[0], band[1], fs, btype='bandpass', order=3), 'time': time})\n",
    "    else:\n",
    "        df_filtered = blackman_harris_filter(channel, time, [0.000001, band[0]], fs, numtaps=blackmann_harris_ntaps)\n",
    "        df_filtered = blackman_harris_filter(df_filtered['channel'].values, df_filtered['time'].values, band[1], fs, numtaps=blackmann_harris_ntaps)    \n",
    "    \n",
    "    hilb = signal.hilbert(df_filtered[(df_filtered['time'] > start_time_ms) & (df_filtered['time'] < stop_time_ms)]['channel'])\n",
    "    phase = np.angle(hilb, deg=True)\n",
    "    df_phase = pd.DataFrame(phase, columns=['phase'])\n",
    "    df_phase['time'] = df_filtered[(df_filtered['time'] > start_time_ms) & (df_filtered['time'] < stop_time_ms)]['time'].values\n",
    "    return df_phase\n",
    "\n",
    "def get_power(channel, time, fs, crop_start_millis, crop_end_millis, method, filter_type, resample_fs, line_noise_band, blackmann_harris_ntaps):\n",
    "    # Crop.\n",
    "    channel = channel[(time > crop_start_millis) & (time < crop_end_millis)].values\n",
    "    time = time[(time > crop_start_millis) & (time < crop_end_millis)].values\n",
    "    \n",
    "    # Resample\n",
    "    if resample_fs is None:\n",
    "        resampled = channel\n",
    "        resampled_time = time\n",
    "    else:\n",
    "        ts = time[1] - time[0]\n",
    "        secs = len(channel) * ts\n",
    "        secs = secs/1000\n",
    "        resampled = signal.resample(channel, int(secs*resample_fs))\n",
    "        resampled_time = np.linspace(time[0], time[-1], len(resampled))\n",
    "        fs = resample_fs\n",
    "\n",
    "    # Remove line nosie.\n",
    "    if filter_type == 'butter':\n",
    "        resampled = butter_bandpass_filter(resampled, line_noise_band[0], line_noise_band[1], fs, 'bandstop', order=3)\n",
    "        resampled_time = time\n",
    "    else:\n",
    "        df_filtered = blackman_harris_filter(resampled, resampled_time, line_noise_band, fs, numtaps=blackmann_harris_ntaps)\n",
    "        resampled = df_filtered['channel']\n",
    "        resampled_time = df_filtered['time']\n",
    "    \n",
    "    # PSD.\n",
    "    if method == 'welch':\n",
    "        # Welch method\n",
    "        freq, power = signal.welch(resampled, fs, nperseg=4*fs, nfft=fs)\n",
    "        df_power = pd.DataFrame({'freq': freq, 'power': power})\n",
    "    elif method == 'fft':\n",
    "        # FFT method\n",
    "        T = 1/fs\n",
    "        N = fs//2\n",
    "        yf = scipy.fftpack.fft(resampled, n=N)\n",
    "        yf = 2 / (N/2) * np.abs(yf[:N//2])\n",
    "        xf = np.linspace(0, 1/(2*T), N // 2)\n",
    "        df_power = pd.DataFrame({'freq': xf, 'power': yf})\n",
    "    elif method == 'pburg':\n",
    "        # Burgs method\n",
    "        order = min(len(resampled)-2, int(fs/4))\n",
    "        p = pburg(resampled, order, sampling=fs, NFFT=fs)\n",
    "        power = p.psd\n",
    "        freq = np.linspace(0, fs/2, len(power))\n",
    "        df_power = pd.DataFrame({'freq': freq, 'power': power})\n",
    "\n",
    "    df_power = df_power[df_power['freq'] < fs/2]\n",
    "    df_power['power'] = 10 * np.log10(df_power['power'])\n",
    "    return df_power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diagnose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_ms = -150\n",
    "# end_ms = -1\n",
    "# fs = 4096\n",
    "# numtaps = 401\n",
    "# for filter_type in ['butter', 'blackman']:\n",
    "#     f, axs = plt.subplots(1,4,figsize=(20,3))\n",
    "#     channel = channel[(time > start_ms) & (time < end_ms)]\n",
    "#     time = time[(time > start_ms) & (time < end_ms)]\n",
    "#     axs[0].plot(time, channel)\n",
    "#     axs[0].set_title('Waveform')\n",
    "    \n",
    "#     df_power = get_power(channel, time, fs, start_ms, end_ms, 'fft', None, None, [48, 52], 801)\n",
    "#     df_power = df_power[df_power['freq'] < 100]\n",
    "#     axs[1].plot(df_power['freq'], df_power['power'])\n",
    "#     axs[1].set_title('Spectrum')\n",
    "    \n",
    "#     if filter_type == 'butter':\n",
    "#         df_filter = pd.DataFrame({'time': time, 'channel': butter_bandpass_filter(channel, 48, 52, fs, 'bandstop', 4)})\n",
    "#     else:\n",
    "#         df_filter = blackman_harris_filter(channel, time, [48, 52], fs, numtaps)\n",
    "#     axs[2].plot(df_filter['time'], df_filter['channel'])\n",
    "#     axs[2].set_title('Filtered channel')\n",
    "    \n",
    "#     df_power = get_power(df_filter['channel'], df_filter['time'], fs, start_ms, end_ms, 'fft', None, None, [48, 52], 801)\n",
    "#     df_power = df_power[df_power['freq'] < 100]\n",
    "#     axs[3].plot(df_power['freq'], df_power['power'])\n",
    "#     axs[3].set_title('Spectrum of filtered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order = min(len(df_filter['channel'])-2, int(fs/4))\n",
    "# p = pburg(resampled, order, sampling=fs, NFFT=fs)\n",
    "# power = p.psd\n",
    "# freq = np.linspace(0, fs/2, len(power))\n",
    "# df_power = pd.DataFrame({'freq': freq, 'power': power})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ind = 20\n",
    "# path = df_paths.iloc[ind]['raw']\n",
    "# trials = pickle.load(open(path, \"rb\"))\n",
    "# trial = trials[10]\n",
    "# time = trial['time']\n",
    "# channel = trial['C3']\n",
    "\n",
    "# fs = 4096\n",
    "# band = [8, 12]\n",
    "# blackmann_harris_ntaps = 401\n",
    "# line_noise_band = [48, 52]\n",
    "# crop_start_millis = -150\n",
    "# resample_fs = None\n",
    "\n",
    "# for filter_type in ['butter', 'blackmann']:\n",
    "#     i = 0\n",
    "#     f, axs = plt.subplots(1,5,figsize=(16,2))\n",
    "#     axs[i].plot(time[time < -1], channel[time < -1])\n",
    "#     i = i + 1\n",
    "    \n",
    "#     df_phase = get_phase(channel, time, band=band, fs=fs, filter_type=filter_type, start_time_ms=-750, stop_time_ms=-1, blackmann_harris_ntaps=blackmann_harris_ntaps)\n",
    "#     axs[i].plot(df_phase['time'], df_phase['phase'])\n",
    "#     axs[i].set_title(\"Phase - {}\".format(filter_type))\n",
    "#     i = i + 1\n",
    "    \n",
    "#     for method in ['pburg', 'welch', 'fft']:\n",
    "#         df_power = get_power(channel, time, fs, crop_start_millis=crop_start_millis, crop_end_millis=-1, method=method, filter_type=filter_type, resample_fs=resample_fs, line_noise_band=line_noise_band, blackmann_harris_ntaps=blackmann_harris_ntaps)\n",
    "#         df_power = df_power[df_power['freq'] < 130]\n",
    "#         axs[i].plot(df_power['freq'], df_power['power'])\n",
    "#         axs[i].set_title(\"Power - {} - {}\".format(filter_type, method))\n",
    "#         i = i + 1\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine EEG and others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_block(path_raw, path_hjorth, path_clean_raw, path_clean_hjorth):\n",
    "    powers = []\n",
    "    phases = []\n",
    "    for artifact_removed, eeg_type, path, fs in zip([False, False, True, True, True, False], ['Raw', 'Hjorth', 'Raw', 'Hjorth', 'Averaged', 'Averaged'], [path_raw, path_hjorth, path_clean_raw, path_clean_hjorth, path_clean_raw, path_raw], [4096, 4096, 2048, 2048, 2048, 4096]):\n",
    "        # Read EEG file.\n",
    "        sub = path.split('/')[3]\n",
    "        exp = path.split('/')[4]\n",
    "        run = path.split('/')[6]\n",
    "        if eeg_type == 'Hjorth':\n",
    "            trials = read_trials_from_mat(path)\n",
    "        else:\n",
    "            trials = pickle.load(open(path, \"rb\"))\n",
    "            \n",
    "        # Select channel name.\n",
    "        if sub in ['sub13', 'sub02']:\n",
    "            channel = 'C4'\n",
    "        else:\n",
    "            channel = 'C3'\n",
    "            \n",
    "        # Calculate average of M1 electrodes.\n",
    "        if eeg_type == 'Averaged':\n",
    "            new_trials = []\n",
    "            for trial in trials:\n",
    "                trial['C3'] = trial[['FC5', 'FC3', 'FC1', 'C5', 'C3', 'C1', 'CP5', 'CP3', 'CP1']].mean(axis=1)\n",
    "                trial['C4'] = trial[['FC6', 'FC4', 'FC2', 'C6', 'C4', 'C2', 'CP6', 'CP4', 'CP2']].mean(axis=1)\n",
    "                new_trials.append(trial)\n",
    "            trials = new_trials\n",
    "            \n",
    "        # Read latency duration.\n",
    "        df_ld = read_latency_duration(path)\n",
    "\n",
    "        # Calculate powers and phases. And combine the results in a df list.\n",
    "        for trial_num in df_ld['trial_num'].values:\n",
    "            if len(trials)-1 < trial_num:\n",
    "                continue\n",
    "            trial = trials[trial_num]\n",
    "            \n",
    "            # Calculate MEP parameters.\n",
    "            ld_row = df_ld[df_ld['trial_num'] == trial_num].iloc[0]\n",
    "            latency = ld_row['latency']\n",
    "            duration = ld_row['duration']\n",
    "            mep_frame = open_mep_as_df(get_mep_path(path))[trial_num]\n",
    "            mep_size, _, _ = calculate_mep_size(mep_frame, latency, duration)\n",
    "            mep_area = calculate_mep_area(mep_frame, latency, duration)\n",
    "            \n",
    "            # PSD and phase calculation.\n",
    "            for filter_name, filter_code in zip(['Blackmann-Harris', 'Butterworth'], ['butter', 'blackmann-harris']):\n",
    "\n",
    "                # PSD Calculation.\n",
    "                for resampled, resample_fs, ntaps_option in zip([True, False], [512, None], [[51, 101], [401, 2001]]):\n",
    "                    for time, ntaps in zip([-150, -750], [ntaps_option[0], ntaps_option[1]]):\n",
    "                        for method_name, method_code in zip(['FFT', 'Welch', 'Burg'], ['fft', 'welch', 'pburg']):\n",
    "                            \n",
    "                            try:\n",
    "                                df_power = get_power(trial[channel], trial['time'], fs=fs, crop_start_millis=time, crop_end_millis=-1, method=method_code, filter_type=filter_code, resample_fs=resample_fs, line_noise_band=[48, 52], blackmann_harris_ntaps=ntaps)\n",
    "                            except:\n",
    "                                continue\n",
    "                                \n",
    "                            for band, fc in zip(['Theta', 'Mu', 'Beta', 'Gamma'], [[3.5, 8], [8, 12], [13, 30], [30, 80]]):\n",
    "                                powers.append({\n",
    "                                    'sub': sub,\n",
    "                                    'exp': exp,\n",
    "                                    'run': run,\n",
    "                                    'trial': trial_num,\n",
    "                                    'ArtifactRemoved': artifact_removed,\n",
    "                                    'EEG': eeg_type,\n",
    "                                    'Resampled': resampled,\n",
    "                                    'Filter': filter_name,\n",
    "                                    'Time': time,\n",
    "                                    'Method': method_name,\n",
    "                                    'Band': band,\n",
    "                                    'Power': df_power[(df_power['freq'] >= fc[0]) * (df_power['freq'] < fc[1])]['power'].mean(),\n",
    "                                    'mep_latency': latency,\n",
    "                                    'mep_duration': duration,\n",
    "                                    'mep_area': mep_area,\n",
    "                                    'mep_size': mep_size\n",
    "                                })\n",
    "                                \n",
    "                for band, fc in zip(['Theta', 'Mu', 'Beta', 'Gamma'], [[3.5, 8], [8, 12], [13, 30], [30, 80]]):\n",
    "                    phase = get_phase(trial[channel], trial['time'], band=fc, fs=fs, filter_type=filter_code, start_time_ms=-750, stop_time_ms=-1, blackmann_harris_ntaps=2001)\n",
    "                    phase = phase.iloc[-1]['phase'] + 180\n",
    "                    phases.append({\n",
    "                        'sub': sub,\n",
    "                        'exp': exp,\n",
    "                        'run': run,\n",
    "                        'trial': trial_num,\n",
    "                        'ArtifactRemoved': artifact_removed,\n",
    "                        'EEG': eeg_type,\n",
    "                        'Filter': filter_name,\n",
    "                        'Band': band,\n",
    "                        'Phase': phase,\n",
    "                        'mep_latency': latency,\n",
    "                        'mep_duration': duration,\n",
    "                        'mep_area': mep_area,\n",
    "                    })\n",
    "    return (powers, phases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccfe012277444e609ee9d8b9caa19727",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=54.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run analysis\n",
    "paths = [list(a) for a in zip(df_paths['raw'].values, df_paths['hjorth'].values, df_paths['clean_raw'].values, df_paths['clean_hjorth'].values)]\n",
    "num_cores = multiprocessing.cpu_count() - 2\n",
    "results = Parallel(n_jobs=num_cores)(delayed(process_block)(path_raw, path_hjorth, path_clean_raw, path_clean_hjorth) for path_raw, path_hjorth, path_clean_raw, path_clean_hjorth in tqdm(paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Populate absolute trial numbers and save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa1f51d84b774017ad7d3976b0287d1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=54.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_powers = []\n",
    "df_phases = []\n",
    "for powers, phases in tqdm(results):\n",
    "    for power in powers:\n",
    "        df_powers.append(power)\n",
    "    for phase in phases:\n",
    "        df_phases.append(phase)\n",
    "\n",
    "df_powers = pd.DataFrame(df_powers)\n",
    "df_phases = pd.DataFrame(df_phases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_values_power = {\n",
    "    'ArtifactRemoved': False, \n",
    "    'EEG': 'Raw', \n",
    "    'Resampled': False, \n",
    "    'Filter': 'Blackmann-Harris', \n",
    "    'Time': -750, \n",
    "    'Method': 'Welch'\n",
    "}\n",
    "def_values_phase = {\n",
    "    'ArtifactRemoved': False, \n",
    "    'EEG': 'Raw',\n",
    "    'Filter': 'Butterworth', \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b559a98f6488457fa92f1e14fc054cce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_powers_new = []\n",
    "keys = list(def_values_power.keys())\n",
    "for sub in tqdm(df_powers['sub'].unique()):\n",
    "    df_sub = df_powers[df_powers['sub'] == sub]\n",
    "    for val1 in df_powers[keys[0]].unique():\n",
    "        for val2 in df_powers[keys[1]].unique():\n",
    "            for val3 in df_powers[keys[2]].unique():\n",
    "                for val4 in df_powers[keys[3]].unique():\n",
    "                    for val5 in df_powers[keys[4]].unique():\n",
    "                        for val6 in df_powers[keys[5]].unique():\n",
    "                            for val7 in df_powers['Band'].unique():\n",
    "                                df_powers2 = df_sub[df_sub['Band'] == val7]\n",
    "                                df_powers2 = df_powers2[df_powers2[keys[5]] == val6]\n",
    "                                df_powers2 = df_powers2[df_powers2[keys[4]] == val5]\n",
    "                                df_powers2 = df_powers2[df_powers2[keys[3]] == val4]\n",
    "                                df_powers2 = df_powers2[df_powers2[keys[2]] == val3]\n",
    "                                df_powers2 = df_powers2[df_powers2[keys[1]] == val2]\n",
    "                                df_powers2 = df_powers2[df_powers2[keys[0]] == val1]\n",
    "                                i = 1\n",
    "                                for idx, row in df_powers2.iterrows():\n",
    "                                    row['trial_abs'] = i\n",
    "                                    df_powers_new.append(row)\n",
    "                                    i = i + 1\n",
    "df_powers_new = pd.DataFrame(df_powers_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14eab2f7cbda4c0296e389983a21a6df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_phases_new = []\n",
    "keys = list(def_values_phase.keys())\n",
    "for sub in tqdm(df_phases['sub'].unique()):\n",
    "    df_sub = df_phases[df_phases['sub'] == sub]\n",
    "    for val1 in df_phases[keys[0]].unique():\n",
    "        for val2 in df_phases[keys[1]].unique():\n",
    "            for val3 in df_phases[keys[2]].unique():\n",
    "                for val4 in df_phases['Band'].unique():\n",
    "                    df_phases2 = df_sub[df_sub[keys[0]] == val1]\n",
    "                    df_phases2 = df_phases2[df_phases2[keys[1]] == val2]\n",
    "                    df_phases2 = df_phases2[df_phases2[keys[2]] == val3]\n",
    "                    df_phases2 = df_phases2[df_phases2['Band'] == val4]\n",
    "                    i = 1\n",
    "                    for idx, row in df_phases2.iterrows():\n",
    "                        row['trial_abs'] = i\n",
    "                        df_phases_new.append(row)\n",
    "                        i = i + 1\n",
    "df_phases_new = pd.DataFrame(df_phases_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_powers_new.to_csv('164-d1-powers.csv')\n",
    "df_phases_new.to_csv('164-d1-phases.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_clean_raw = df_paths['raw'].values[53]\n",
    "\n",
    "# powers = []\n",
    "# phases = []\n",
    "# for artifact_removed, eeg_type, path, fs in zip([False], ['Averaged'], [path_clean_raw], [4096]):\n",
    "#     # Read EEG file.\n",
    "#     sub = path.split('/')[3]\n",
    "#     exp = path.split('/')[4]\n",
    "#     run = path.split('/')[6]\n",
    "#     if eeg_type == 'Hjorth':\n",
    "#         trials = read_trials_from_mat(path)\n",
    "#     else:\n",
    "#         trials = pickle.load(open(path, \"rb\"))\n",
    "\n",
    "#     # Select channel name.\n",
    "#     if sub in ['sub13', 'sub02']:\n",
    "#         channel = 'C4'\n",
    "#     else:\n",
    "#         channel = 'C3'\n",
    "\n",
    "#     # Calculate average of M1 electrodes.\n",
    "#     if eeg_type == 'Averaged':\n",
    "#         new_trials = []\n",
    "#         for trial in trials:\n",
    "#             trial['C3'] = trial[['FC5', 'FC3', 'FC1', 'C5', 'C3', 'C1', 'CP5', 'CP3', 'CP1']].mean(axis=1)\n",
    "#             trial['C4'] = trial[['FC6', 'FC4', 'FC2', 'C6', 'C4', 'C2', 'CP6', 'CP4', 'CP2']].mean(axis=1)\n",
    "#             new_trials.append(trial)\n",
    "#         trials = new_trials\n",
    "\n",
    "#     # Read latency duration.\n",
    "#     df_ld = read_latency_duration(path)\n",
    "\n",
    "#     # Calculate powers and phases. And combine the results in a df list.\n",
    "#     for trial_num in tqdm(df_ld['trial_num'].values):\n",
    "# #         if len(trials)-1 < trial_num:\n",
    "# #             continue\n",
    "#         trial = trials[trial_num]\n",
    "\n",
    "#         # Calculate MEP parameters.\n",
    "#         ld_row = df_ld[df_ld['trial_num'] == trial_num].iloc[0]\n",
    "#         latency = ld_row['latency']\n",
    "#         duration = ld_row['duration']\n",
    "#         mep_frame = open_mep_as_df(get_mep_path(path))[trial_num]\n",
    "#         mep_size, _, _ = calculate_mep_size(mep_frame, latency, duration)\n",
    "#         mep_area = calculate_mep_area(mep_frame, latency, duration)\n",
    "\n",
    "#         # PSD and phase calculation.\n",
    "#         for filter_name, filter_code in zip(['Butterworth'], ['butter']):\n",
    "\n",
    "#             # PSD Calculation.\n",
    "#             for resampled, resample_fs, ntaps_option in zip([False], [None], [[401, 2001]]):\n",
    "#                 for time, ntaps in zip([-750], [ntaps_option[1]]):\n",
    "#                     for method_name, method_code in zip(['FFT', 'Welch', 'Burg'], ['fft', 'welch', 'pburg']):\n",
    "\n",
    "# #                         try:\n",
    "#                         df_power = get_power(trial[channel], trial['time'], fs=fs, crop_start_millis=time, crop_end_millis=-1, method=method_code, filter_type=filter_code, resample_fs=resample_fs, line_noise_band=[48, 52], blackmann_harris_ntaps=ntaps)\n",
    "# #                         except:\n",
    "# #                             continue\n",
    "\n",
    "#                         for band, fc in zip(['Theta', 'Mu', 'Beta', 'Gamma'], [[3.5, 8], [8, 12], [13, 30], [30, 80]]):\n",
    "#                             powers.append({\n",
    "#                                 'sub': sub,\n",
    "#                                 'exp': exp,\n",
    "#                                 'run': run,\n",
    "#                                 'trial': trial_num,\n",
    "#                                 'ArtifactRemoved': artifact_removed,\n",
    "#                                 'EEG': eeg_type,\n",
    "#                                 'Resampled': resampled,\n",
    "#                                 'Filter': filter_name,\n",
    "#                                 'Time': time,\n",
    "#                                 'Method': method_name,\n",
    "#                                 'Band': band,\n",
    "#                                 'Power': df_power[(df_power['freq'] >= fc[0]) * (df_power['freq'] < fc[1])]['power'].mean(),\n",
    "#                                 'mep_latency': latency,\n",
    "#                                 'mep_duration': duration,\n",
    "#                                 'mep_area': mep_area\n",
    "#                             })\n",
    "\n",
    "#             for band, fc in zip(['Theta', 'Mu', 'Beta', 'Gamma'], [[3.5, 8], [8, 12], [13, 30], [30, 80]]):\n",
    "#                 phase = get_phase(trial[channel], trial['time'], band=fc, fs=fs, filter_type=filter_code, start_time_ms=-750, stop_time_ms=-1, blackmann_harris_ntaps=2001)\n",
    "#                 phase = phase.iloc[-1]['phase'] + 180\n",
    "#                 phases.append({\n",
    "#                     'sub': sub,\n",
    "#                     'exp': exp,\n",
    "#                     'run': run,\n",
    "#                     'trial': trial_num,\n",
    "#                     'ArtifactRemoved': artifact_removed,\n",
    "#                     'EEG': eeg_type,\n",
    "#                     'Filter': filter_name,\n",
    "#                     'Band': band,\n",
    "#                     'Phase': phase,\n",
    "#                     'mep_latency': latency,\n",
    "#                     'mep_duration': duration,\n",
    "#                     'mep_area': mep_area,\n",
    "#                 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_powers = pd.DataFrame(powers)\n",
    "# df_powers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_paths['clean_raw'].values[53]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
