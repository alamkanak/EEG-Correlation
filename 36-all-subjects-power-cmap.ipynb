{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import glob\n",
    "import pandas as pd\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "from io import StringIO\n",
    "import mne\n",
    "from mne.io import read_raw_eeglab, read_epochs_eeglab\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "import autosklearn.regression\n",
    "import sklearn.model_selection\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "import multiprocessing\n",
    "from tpot import TPOTRegressor\n",
    "from oct2py import octave\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from joblib import wrap_non_picklable_objects\n",
    "import json\n",
    "import pickle\n",
    "import os.path\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from mayavi import mlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeglab_path = '/home/raquib/Documents/MATLAB/eeglab2019_0/functions/'\n",
    "octave.addpath(eeglab_path + 'guifunc');\n",
    "octave.addpath(eeglab_path + 'popfunc');\n",
    "octave.addpath(eeglab_path + 'adminfunc');\n",
    "octave.addpath(eeglab_path + 'sigprocfunc');\n",
    "octave.addpath(eeglab_path + 'miscfunc');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 'data/original/*/*'\n",
    "meps = sorted(glob.glob(experiment + '/mep/*/*.txt'))\n",
    "mep_present = len(meps) > 0\n",
    "eegs = sorted(glob.glob(experiment + '/eeg/*/clean-prestimulus.set'))\n",
    "eeg_present = len(eegs) > 0\n",
    "cmaps = sorted(glob.glob(experiment + '/cmap/*.xlsx'))\n",
    "cmap_present = len(cmaps) > 0\n",
    "all_present = mep_present and eeg_present and cmap_present\n",
    "print(all_present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('EEG count: ' + str(len(eegs)))\n",
    "print('MEP count: ' + str(len(meps)))\n",
    "print('CMAP count: ' + str(len(cmaps)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eegs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eegs = [\n",
    "    'data/original/sub03/exp01/eeg/SP 110RMT r1/clean-prestimulus.set',\n",
    "    'data/original/sub03/exp01/eeg/SP 110RMT r2/clean-prestimulus.set',\n",
    "    'data/original/sub03/exp01/eeg/SP 110RMT r3/clean-prestimulus.set',\n",
    "#     'data/original/sub03/exp02/eeg/SP 110RMT r1/clean-prestimulus.set', NO CMAP\n",
    "#     'data/original/sub03/exp02/eeg/SP 110RMT r2/clean-prestimulus.set', NO CMAP\n",
    "#     'data/original/sub03/exp03/eeg/SP 110RMT r1/clean-prestimulus.set', NO CMAP\n",
    "    'data/original/sub03/exp03/eeg/SP 110RMT r2/clean-prestimulus.set',\n",
    "    'data/original/sub03/exp03/eeg/SP 110RMT r3/clean-prestimulus.set',\n",
    "#     'data/original/sub04/exp01/eeg/SP 110RMT r1/clean-prestimulus.set', NO CMAP\n",
    "#     'data/original/sub04/exp01/eeg/SP 110RMT r2/clean-prestimulus.set', NO CMAP\n",
    "#     'data/original/sub04/exp01/eeg/SP 110RMT r3/clean-prestimulus.set', NO CMAP\n",
    "#     'data/original/sub05/exp01/eeg/SP 110RMT r3/clean-prestimulus.set',\n",
    "    'data/original/sub06/exp01/eeg/SP 110RMT r1/clean-prestimulus.set',\n",
    "    'data/original/sub06/exp01/eeg/SP 110RMT r2/clean-prestimulus.set',\n",
    "    'data/original/sub06/exp01/eeg/SP 110RMT r3/clean-prestimulus.set',\n",
    "    'data/original/sub06/exp02/eeg/SP 110RMT/clean-prestimulus.set',\n",
    "    'data/original/sub07/exp01/eeg/SP 110RMT r1/clean-prestimulus.set',\n",
    "    'data/original/sub07/exp01/eeg/SP 110RMT r2/clean-prestimulus.set',\n",
    "    'data/original/sub07/exp01/eeg/SP 110RMT r3/clean-prestimulus.set',\n",
    "    'data/original/sub08/exp01/eeg/SP 110RMT r1/clean-prestimulus.set',\n",
    "    'data/original/sub08/exp01/eeg/SP 110RMT r2/clean-prestimulus.set',\n",
    "    'data/original/sub08/exp01/eeg/SP 110RMT r3/clean-prestimulus.set',\n",
    "    'data/original/sub08/exp02/eeg/SP 110RMT/clean-prestimulus.set',\n",
    "    'data/original/sub08/exp03/eeg/SP 110RMT r1/clean-prestimulus.set',\n",
    "    'data/original/sub08/exp03/eeg/SP 110RMT r2/clean-prestimulus.set',\n",
    "    'data/original/sub08/exp03/eeg/SP 110RMT r3/clean-prestimulus.set',\n",
    "    'data/original/sub12/exp02/eeg/SP 110RMT/clean-prestimulus.set',\n",
    "    'data/original/sub13/exp01/eeg/SP 110RMT/clean-prestimulus.set',\n",
    "    'data/original/sub14/exp01/eeg/SP 110RMT r1/clean-prestimulus.set',\n",
    "    'data/original/sub15/exp01/eeg/SP 110RMT r1/clean-prestimulus.set',\n",
    "    'data/original/sub15/exp01/eeg/SP 110RMT r2/clean-prestimulus.set',\n",
    "    'data/original/sub15/exp01/eeg/SP 110RMT r3/clean-prestimulus.set',\n",
    "    'data/original/sub16/exp01/eeg/SP 110RMT r1/clean-prestimulus.set',\n",
    "    'data/original/sub16/exp01/eeg/SP 110RMT r2/clean-prestimulus.set',\n",
    "    'data/original/sub16/exp01/eeg/SP 110RMT r3/clean-prestimulus.set'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and process EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def read_eeg(path):\n",
    "    eeg = octave.pop_loadset(path)\n",
    "    new_trial_list = []\n",
    "    for i in range(eeg.data.shape[2]):\n",
    "        trial = eeg.data[:, :, i]\n",
    "        time = np.linspace(-1000, -20, num=trial.shape[1])\n",
    "        trial = pd.DataFrame(np.transpose(trial), columns=eeg.chanlocs.labels[0])\n",
    "        trial['time'] = time\n",
    "        new_trial_list.append(trial)\n",
    "    return new_trial_list\n",
    "\n",
    "def crop_trials(trial_list, duration_millis=500, sampling_rate=2048):\n",
    "    new_trial_list = []\n",
    "    for trial in trial_list:\n",
    "        samples_to_pick = duration_millis * sampling_rate / 1000\n",
    "        new_trial_list.append(trial.tail(int(samples_to_pick)))\n",
    "    return new_trial_list, samples_to_pick\n",
    "\n",
    "# Calculate EEG area.\n",
    "def calculate_eeg_area(epoch_df, sf=2048):\n",
    "    y = epoch_df.drop('time', axis=1).mean(axis=1)\n",
    "    b2, a2 = signal.butter(4, 200/(sf/2), btype='lowpass')\n",
    "    envelope = signal.filtfilt(b2, a2, np.abs(y))\n",
    "    area = np.trapz(envelope, epoch_df['time'].values)\n",
    "    return area\n",
    "\n",
    "# Calculate EEG frequency.\n",
    "def calculate_eeg_frequency(channel):\n",
    "    sf = 2048\n",
    "    win = 4 * sf\n",
    "    freqs, psd = signal.welch(channel, sf, nperseg=win)\n",
    "    return freqs, psd\n",
    "\n",
    "def calculate_eeg_max_amplitude(epoch_df):\n",
    "    avg = epoch_df.mean(axis=1)\n",
    "    return np.max(avg.values)\n",
    "\n",
    "def band_max(freq, psd, start=0, end=4):\n",
    "    indices = np.where((freq >= start) & (freq <= end))\n",
    "    freq = freq[indices]\n",
    "    psd = psd[indices]\n",
    "    i = np.argmax(np.abs(psd))\n",
    "    return freq[i], psd[i]\n",
    "\n",
    "def filter_electrodes(trial, which='all'):\n",
    "    time_column = trial['time']\n",
    "    if which == 'ltm1':\n",
    "        channel_names = ['FC5','FC1','C3','CP5','CP1','FC3','C5','C1','CP3']\n",
    "    elif which == 'rtm1':\n",
    "        channel_names = ['FC6','FC2','C4','CP6','CP2','FC4','C6','C2','CP4']\n",
    "    elif which == 'central':\n",
    "        channel_names = ['Fz','FCz','Cz','F1','FC1','C1','C2','FC2','F2']\n",
    "    else:\n",
    "        channel_names = ['Fp1', 'Fpz', 'Fp2', 'F7', 'F3', 'Fz', 'F4', 'F8', 'FC5', 'FC1', 'FC2', 'FC6', 'M1', 'T7', 'C3', 'Cz', 'C4', 'T8', 'M2', 'CP5', 'CP1', 'CP2', 'CP6', 'P7', 'P3', 'Pz', 'P4', 'P8', 'POz', 'O1', 'O2', 'EOG', 'AF7', 'AF3', 'AF4', 'AF8', 'F5', 'F1', 'F2', 'F6', 'FC3', 'FCz', 'FC4', 'C5', 'C1', 'C2', 'C6', 'CP3', 'CP4', 'P5', 'P1', 'P2', 'P6', 'PO5', 'PO3', 'PO4', 'PO6', 'FT7', 'FT8', 'TP7', 'TP8', 'PO7', 'PO8', 'Oz']\n",
    "    trial = trial[channel_names]\n",
    "    trial['time'] = time_column\n",
    "    return trial\n",
    "\n",
    "def read_wavelets(eeg_path, epoch_num):\n",
    "    segments = eeg_path.split('/')\n",
    "    path = 'wavelets/' + segments[2] + '-' + segments[3] + '-' + segments[5] + '-' + str(epoch_num)\n",
    "    with open(path + '-central.pickle', 'rb') as f:\n",
    "        central = pickle.load(f)\n",
    "    with open(path + '-ltm1.pickle', 'rb') as f:\n",
    "        ltm1 = pickle.load(f)\n",
    "    with open(path + '-rtm1.pickle', 'rb') as f:\n",
    "        rtm1 = pickle.load(f)\n",
    "    with open(path + '-all.pickle', 'rb') as f:\n",
    "        all_channels = pickle.load(f)\n",
    "    return all_channels, ltm1, rtm1, central"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and process MEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mep_path(eeg_path):\n",
    "    segments = eeg_path.split('/')\n",
    "    segments[4] = 'mep'\n",
    "    segments = segments[:-1]\n",
    "    mep_path = '/'.join(segments) + '/*.txt'\n",
    "    mep_path = glob.glob(mep_path)[0]\n",
    "    return mep_path\n",
    "\n",
    "def get_cmap_path(eeg_path):\n",
    "    segments = eeg_path.split('/')\n",
    "    segments[4] = 'cmap'\n",
    "    del segments[5]\n",
    "    segments = segments[:-1]\n",
    "    cmap_path = '/'.join(segments) + '/*.xlsx'\n",
    "    cmap_paths = glob.glob(cmap_path)\n",
    "    if (len(cmap_paths) == 0):\n",
    "        print('No CMAP found for ' + cmap_path)\n",
    "        return ''\n",
    "    return cmap_paths[0]\n",
    "\n",
    "def mep_area(mep):\n",
    "    mep, _ = crop_mep_region(mep)\n",
    "    b2, a2 = signal.butter(4, 250/(3750/2), btype='lowpass')\n",
    "    emg_envelope = signal.filtfilt(b2, a2, np.abs(mep[get_apb_column_name(mep)]))\n",
    "    return np.trapz(np.abs(emg_envelope), np.linspace(1, mep.shape[0], mep.shape[0]))\n",
    "\n",
    "def calculate_mep_categories(mep_frames):\n",
    "    sizes = []\n",
    "    for mep_frame in mep_frames:\n",
    "        sizes.append(calculate_mep_size(mep_frame))\n",
    "    p1 = np.percentile(sizes, 33.33)\n",
    "    p2 = np.percentile(sizes, 66.66)\n",
    "    cat = np.ones(len(mep_frames)) * ((sizes >= p1) & (sizes < p2))\n",
    "    cat = 2 * (sizes >= p2) * np.ones(len(mep_frames)) + cat\n",
    "    return cat\n",
    "\n",
    "# Calculate MEP size.\n",
    "def calculate_mep_size(mep_frame):\n",
    "    mep_cropped, time = crop_mep_region(mep_frame)\n",
    "    apb_name = get_apb_column_name(mep_frame)\n",
    "    max_row = mep_frame.iloc[mep_cropped.idxmax(axis=0)[apb_name]]\n",
    "    min_row = mep_frame.iloc[mep_cropped.idxmin(axis=0)[apb_name]]\n",
    "    mep_size = max_row[apb_name] - min_row[apb_name]\n",
    "    return mep_size\n",
    "\n",
    "# Function to crop MEP region.\n",
    "def crop_mep_region(mep_frame):\n",
    "    crop_start = 0.211\n",
    "    crop_end = 0.4\n",
    "    multiplier = 7499 / 1.4998\n",
    "    start = int(crop_start * multiplier)\n",
    "    end = int(crop_end * multiplier)\n",
    "    mep_cropped = mep_frame.iloc[start:end, :]\n",
    "    time = mep_frame.iloc[start:end, :]\n",
    "    return mep_cropped, time\n",
    "\n",
    "# Function to get APB column name.\n",
    "def get_apb_column_name(mep_frame):\n",
    "    if 'L APB' in mep_frame:\n",
    "        return 'L APB'\n",
    "    else:\n",
    "        return 'APB'\n",
    "\n",
    "# Open MEP file as dataframe.\n",
    "def open_mep_as_df(path):\n",
    "    fileMep = open(path, \"r+\")\n",
    "    mep_frames = fileMep.read().split('\\n\\n')\n",
    "    df_list = []\n",
    "    for mep_frame in mep_frames:\n",
    "        df_list.append(pd.read_csv(StringIO(mep_frame), '\\t'))\n",
    "    return df_list\n",
    "\n",
    "def get_mep_category_absolute(mep_size):\n",
    "    if mep_size <= .2:\n",
    "        return 0\n",
    "    elif mep_size > .2 and mep_size < 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and process CMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CMAP file.\n",
    "def read_cmap(path):\n",
    "    df = pd.read_excel(path, sheet_name='Raw data', header=None)\n",
    "    cmap = df.iloc[44:df.shape[0]-1, 38:59]\n",
    "    time = df.iloc[44:df.shape[0]-1, 0]\n",
    "    df = pd.DataFrame(cmap)\n",
    "    df['time'] = time\n",
    "    return df\n",
    "\n",
    "# Identify CMAP peaks.\n",
    "def find_cmap_peaks(cmap):\n",
    "    time = cmap['time']\n",
    "    mean_clean = cmap.drop('time', axis=1).mean(axis=1)\n",
    "    mean_clean[0:104*10-1] = 0\n",
    "    idxmax = mean_clean.idxmax(axis=0)\n",
    "    idxmax = time[idxmax]\n",
    "    idxmin = mean_clean.idxmin(axis=0)\n",
    "    idxmin = time[idxmin]\n",
    "    max_val = mean_clean.max()\n",
    "    min_val = mean_clean.min()\n",
    "    return max_val, min_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract all features from EEG, CMAP and MEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(eeg_path):\n",
    "    mep_path = get_mep_path(eeg_path)\n",
    "    epochs = read_eeg(eeg_path)\n",
    "    epochs, _ = crop_trials(epochs)\n",
    "    mep_frames = open_mep_as_df(mep_path)\n",
    "    epoch_features = []\n",
    "    if len(epochs) != len(mep_frames):\n",
    "        # print('MEP frame count (' + str(len(mep_frames)) + ') is not equal to EEG epochs count (' + str(len(epochs)) + ') for ' + eeg_path + ' and ' + mep_path)\n",
    "        raise Exception('MEP frame count (' + str(len(mep_frames)) + ') is not equal to EEG epochs count (' + str(len(epochs)) + ') for ' + eeg_path + ' and ' + mep_path)\n",
    "        return\n",
    "    mep_sizes = calculate_mep_categories(mep_frames)\n",
    "    for i in range(len(epochs)):\n",
    "        epoch = epochs[i]\n",
    "        mep = mep_frames[i]\n",
    "        segments = eeg_path.split('/')\n",
    "        d = {'sub': segments[2], 'exp': segments[3], 'run': segments[5], 'epoch': i}\n",
    "\n",
    "        freq, psd = calculate_eeg_frequency(epoch.drop('time', axis=1).values.mean(axis=1))\n",
    "        d['all_all_max_power_freq'], d['all_all_max_power'] = band_max(freq, psd, 4, 40)\n",
    "        d['all_delta_max_power_freq'], d['all_delta_max_power'] = band_max(freq, psd, 0, 4)\n",
    "        d['all_theta_max_power_freq'], d['all_theta_max_power'] = band_max(freq, psd, 4, 8)\n",
    "        d['all_alpha_max_power_freq'], d['all_alpha_max_power'] = band_max(freq, psd, 8, 16)\n",
    "        d['all_beta_max_power_freq'], d['all_beta_max_power'] = band_max(freq, psd, 16, 32)\n",
    "        d['all_gamma_max_power_freq'], d['all_gamma_max_power'] = band_max(freq, psd, 32, 500)\n",
    "\n",
    "        freq, psd = calculate_eeg_frequency(filter_electrodes(epoch, 'ltm1').drop('time', axis=1).values.mean(axis=1))\n",
    "        d['ltm1_all_max_power_freq'], d['ltm1_all_max_power'] = band_max(freq, psd, 4, 40)\n",
    "        d['ltm1_delta_max_power_freq'], d['ltm1_delta_max_power'] = band_max(freq, psd, 0, 4)\n",
    "        d['ltm1_theta_max_power_freq'], d['ltm1_theta_max_power'] = band_max(freq, psd, 4, 8)\n",
    "        d['ltm1_alpha_max_power_freq'], d['ltm1_alpha_max_power'] = band_max(freq, psd, 8, 16)\n",
    "        d['ltm1_beta_max_power_freq'], d['ltm1_beta_max_power'] = band_max(freq, psd, 16, 32)\n",
    "        d['ltm1_gamma_max_power_freq'], d['ltm1_gamma_max_power'] = band_max(freq, psd, 32, 500)\n",
    "\n",
    "        freq, psd = calculate_eeg_frequency(filter_electrodes(epoch, 'rtm1').drop('time', axis=1).values.mean(axis=1))\n",
    "        d['rtm1_all_max_power_freq'], d['rtm1_all_max_power'] = band_max(freq, psd, 4, 40)\n",
    "        d['rtm1_delta_max_power_freq'], d['rtm1_delta_max_power'] = band_max(freq, psd, 0, 4)\n",
    "        d['rtm1_theta_max_power_freq'], d['rtm1_theta_max_power'] = band_max(freq, psd, 4, 8)\n",
    "        d['rtm1_alpha_max_power_freq'], d['rtm1_alpha_max_power'] = band_max(freq, psd, 8, 16)\n",
    "        d['rtm1_beta_max_power_freq'], d['rtm1_beta_max_power'] = band_max(freq, psd, 16, 32)\n",
    "        d['rtm1_gamma_max_power_freq'], d['rtm1_gamma_max_power'] = band_max(freq, psd, 32, 500)\n",
    "\n",
    "        freq, psd = calculate_eeg_frequency(filter_electrodes(epoch, 'central').drop('time', axis=1).values.mean(axis=1))\n",
    "        d['central_all_max_power_freq'], d['central_all_max_power'] = band_max(freq, psd, 4, 40)\n",
    "        d['central_delta_max_power_freq'], d['central_delta_max_power'] = band_max(freq, psd, 0, 4)\n",
    "        d['central_theta_max_power_freq'], d['central_theta_max_power'] = band_max(freq, psd, 4, 8)\n",
    "        d['central_alpha_max_power_freq'], d['central_alpha_max_power'] = band_max(freq, psd, 8, 16)\n",
    "        d['central_beta_max_power_freq'], d['central_beta_max_power'] = band_max(freq, psd, 16, 32)\n",
    "        d['central_gamma_max_power_freq'], d['central_gamma_max_power'] = band_max(freq, psd, 32, 500)\n",
    "        \n",
    "        # Wavelet\n",
    "        wt_all, wt_ltm1, wt_rtm1, wt_central = read_wavelets(eeg_path, i)\n",
    "        d['wavelet_all_max_power_at_freq'] = wt_all.mean(axis=1).argmax() * 1000\n",
    "        d['wavelet_all_max_power_freq'] = wt_all.mean(axis=1).max()\n",
    "        d['wavelet_ltm1_max_power_at_freq'] = wt_ltm1.mean(axis=1).argmax() * 1000\n",
    "        d['wavelet_ltm1_max_power_freq'] = wt_ltm1.mean(axis=1).max()\n",
    "        d['wavelet_rtm1_max_power_at_freq'] = wt_rtm1.mean(axis=1).argmax() * 1000\n",
    "        d['wavelet_rtm1_max_power_freq'] = wt_rtm1.mean(axis=1).max()\n",
    "        d['wavelet_central_max_power_at_freq'] = wt_central.mean(axis=1).argmax() * 1000\n",
    "        d['wavelet_central_max_power_freq'] = wt_central.mean(axis=1).max()\n",
    "        \n",
    "        d['wavelet_all_max_power_at_time'] = wt_all.mean(axis=0).argmax()\n",
    "        d['wavelet_all_max_power_time'] = wt_all.mean(axis=0).max()\n",
    "        d['wavelet_ltm1_max_power_at_time'] = wt_ltm1.mean(axis=0).argmax()\n",
    "        d['wavelet_ltm1_max_power_time'] = wt_ltm1.mean(axis=0).max()\n",
    "        d['wavelet_rtm1_max_power_at_time'] = wt_rtm1.mean(axis=0).argmax()\n",
    "        d['wavelet_rtm1_max_power_time'] = wt_rtm1.mean(axis=0).max()\n",
    "        d['wavelet_central_max_power_at_time'] = wt_central.mean(axis=0).argmax()\n",
    "        d['wavelet_central_max_power_time'] = wt_central.mean(axis=0).max()\n",
    "\n",
    "        d['area_under_eeg'] = calculate_eeg_area(epoch)\n",
    "        d['rtm1_area_under_eeg'] = calculate_eeg_area(filter_electrodes(epoch, 'rtm1'))\n",
    "        d['ltm1_area_under_eeg'] = calculate_eeg_area(filter_electrodes(epoch, 'ltm1'))\n",
    "        d['central_area_under_eeg'] = calculate_eeg_area(filter_electrodes(epoch, 'central'))\n",
    "        \n",
    "        d['all_all_max_amplitude'] = calculate_eeg_max_amplitude(epoch.drop('time', axis=1))\n",
    "        d['rtm1_all_max_amplitude'] = calculate_eeg_max_amplitude(filter_electrodes(epoch, 'rtm1').drop('time', axis=1))\n",
    "        d['ltm1_all_max_amplitude'] = calculate_eeg_max_amplitude(filter_electrodes(epoch, 'ltm1').drop('time', axis=1))\n",
    "        d['central_all_max_amplitude'] = calculate_eeg_max_amplitude(filter_electrodes(epoch, 'central').drop('time', axis=1))\n",
    "\n",
    "        d['all_alpha_max_amplitude'] = calculate_eeg_max_amplitude(epoch.drop('time', axis=1))\n",
    "        d['rtm1_alpha_max_amplitude'] = calculate_eeg_max_amplitude(filter_electrodes(epoch, 'rtm1').drop('time', axis=1))\n",
    "        d['ltm1_alpha_max_amplitude'] = calculate_eeg_max_amplitude(filter_electrodes(epoch, 'ltm1').drop('time', axis=1))\n",
    "        d['central_alpha_max_amplitude'] = calculate_eeg_max_amplitude(filter_electrodes(epoch, 'central').drop('time', axis=1))\n",
    "        \n",
    "        cmap_path = get_cmap_path(eeg_path)\n",
    "        cmap = read_cmap(cmap_path)\n",
    "        d['cmap_max'], d['cmap_min'] = find_cmap_peaks(cmap)\n",
    "        \n",
    "        mep_size = calculate_mep_size(mep)\n",
    "        d['mep_size'] = mep_size\n",
    "        d['mep_category_percentile'] = mep_sizes[i]\n",
    "        d['mep_category_absolute'] = get_mep_category_absolute(mep_size)\n",
    "        d['mep_category_cmap'] = mep_size / (d['cmap_max'] - d['cmap_min'])\n",
    "        d['mep_area'] = mep_area(mep)\n",
    "        \n",
    "        epoch_features.append(d)\n",
    "    return epoch_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_save_features(eeg_path, filename):\n",
    "    features = extract_features(eeg_path)\n",
    "    features = pd.DataFrame(features)\n",
    "    if os.path.isfile(filename):\n",
    "        old_features = pd.read_excel(filename, index_col=0)\n",
    "        features = old_features.append(features)\n",
    "    features.to_excel(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_filename = '36-features.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for eeg_path in tqdm_notebook(eegs):\n",
    "    extract_and_save_features(eeg_path, features_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(features_filename, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Frequency vs MEP Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(df['wavelet_all_max_power_at_freq'], df['mep_size'], '.')\n",
    "plt.xlabel('Scale - All channels')\n",
    "plt.ylabel('MEP Size')\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(df['wavelet_ltm1_max_power_at_freq'], df['mep_size'], '.')\n",
    "plt.xlabel('Scale - Ltm1')\n",
    "plt.ylabel('MEP Size')\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(df['wavelet_rtm1_max_power_at_freq'], df['mep_size'], '.')\n",
    "plt.xlabel('Scale - Rtm1')\n",
    "plt.ylabel('MEP Size')\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(df['wavelet_ltm1_max_power_at_freq'], df['mep_size'], '.')\n",
    "plt.xlabel('Scale - Central')\n",
    "plt.ylabel('MEP Size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(df['ltm1_all_max_power_freq'], df['mep_size'], '.')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('MEP Size')\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(df['ltm1_alpha_max_power_freq'], df['mep_size'], '.')\n",
    "plt.xlabel('Frequency - alpha band (Hz)')\n",
    "plt.ylabel('MEP Size')\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(df['ltm1_beta_max_power_freq'], df['mep_size'], '.')\n",
    "plt.xlabel('Frequency - beta band (Hz)')\n",
    "plt.ylabel('MEP Size')\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(df['ltm1_gamma_max_power_freq'], df['mep_size'], '.')\n",
    "plt.xlabel('Frequency - gamma band (Hz)')\n",
    "plt.ylabel('MEP Size')\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(df['ltm1_delta_max_power_freq'], df['mep_size'], '.')\n",
    "plt.xlabel('Frequency - delta band (Hz)')\n",
    "plt.ylabel('MEP Size')\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(df['ltm1_theta_max_power_freq'], df['mep_size'], '.')\n",
    "plt.xlabel('Frequency - theta band (Hz)')\n",
    "plt.ylabel('MEP Size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.subplot(1, 2, 1)\n",
    "df2 = df[df['mep_category_percentile'] == 0]\n",
    "plt.plot(df2['wavelet_ltm1_max_power_at_freq'], df2['wavelet_ltm1_max_power_freq'], 'o', color='green')\n",
    "df2 = df[df['mep_category_percentile'] == 1]\n",
    "plt.plot(df2['wavelet_ltm1_max_power_at_freq'], df2['wavelet_ltm1_max_power_freq'], 'o', color='red')\n",
    "df2 = df[df['mep_category_percentile'] == 2]\n",
    "plt.plot(df2['wavelet_ltm1_max_power_at_freq'], df2['wavelet_ltm1_max_power_freq'], 'o', color='blue')\n",
    "plt.xlabel('Wavelet Freq - Ltm1')\n",
    "plt.ylabel('Power - Ltm1')\n",
    "plt.title('PERCENTILE CATEGORY')\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "df2 = df[df['mep_category_absolute'] == 0]\n",
    "plt.plot(df2['wavelet_ltm1_max_power_at_freq'], df2['wavelet_ltm1_max_power_freq'], 'o', color='green')\n",
    "df2 = df[df['mep_category_absolute'] == 1]\n",
    "plt.plot(df2['wavelet_ltm1_max_power_at_freq'], df2['wavelet_ltm1_max_power_freq'], 'o', color='red')\n",
    "df2 = df[df['mep_category_absolute'] == 2]\n",
    "plt.plot(df2['wavelet_ltm1_max_power_at_freq'], df2['wavelet_ltm1_max_power_freq'], 'o', color='blue')\n",
    "plt.xlabel('Wavelet Freq - Ltm1')\n",
    "plt.ylabel('Power - Ltm1')\n",
    "plt.title('ABSOLUTE CATEGORY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, Y = np.meshgrid(df['wavelet_ltm1_max_scale'], df['wavelet_ltm1_max_power'])\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter3D(df['wavelet_ltm1_max_power_at_freq'], df['wavelet_ltm1_max_power_freq'], np.abs(np.log(df['mep_category_cmap'])), c=df['mep_category_cmap'])\n",
    "ax.set_xlabel('Freq - Ltm1')\n",
    "ax.set_ylabel('Power - Ltm1')\n",
    "ax.set_zlabel('MEP/CMAP');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, Y = np.meshgrid(df['wavelet_ltm1_max_scale'], df['wavelet_ltm1_max_power'])\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter3D(df['wavelet_ltm1_max_power_at_freq'], df['wavelet_ltm1_max_power_freq'], df['mep_category_absolute'], c=df['mep_category_absolute'])\n",
    "ax.set_xlabel('Scale - Ltm1')\n",
    "ax.set_ylabel('Power - Ltm1')\n",
    "ax.set_zlabel('MEP - absolute');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "df2 = df[df['mep_category_percentile'] == 0]\n",
    "plt.plot(df2['wavelet_rtm1_max_power_at_freq'], df2['wavelet_rtm1_max_power_freq'], 'o', color='green')\n",
    "df2 = df[df['mep_category_percentile'] == 1]\n",
    "plt.plot(df2['wavelet_rtm1_max_power_at_freq'], df2['wavelet_rtm1_max_power_freq'], 'o', color='red')\n",
    "df2 = df[df['mep_category_percentile'] == 2]\n",
    "plt.plot(df2['wavelet_rtm1_max_power_at_freq'], df2['wavelet_rtm1_max_power_freq'], 'o', color='blue')\n",
    "plt.xlabel('Wavelet Scale - Rtm1')\n",
    "plt.ylabel('Power - Rtm1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# X, Y = np.meshgrid(df['wavelet_ltm1_max_scale'], df['wavelet_ltm1_max_power'])\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter3D(df['wavelet_ltm1_max_power_at_time'], df['wavelet_ltm1_max_power_time'], df['mep_category_cmap'], c=df['mep_category_cmap'])\n",
    "ax.set_xlabel('Time - Ltm1')\n",
    "ax.set_ylabel('Power - Ltm1')\n",
    "ax.set_zlabel('MEP/CMAP');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter3D(df['wavelet_all_max_power_at_time'], df['wavelet_all_max_power_time'], df['mep_category_cmap'], c=df['mep_category_cmap'])\n",
    "ax.set_xlabel('Time - All')\n",
    "ax.set_ylabel('Power - All')\n",
    "ax.set_zlabel('MEP/CMAP');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter3D(df['wavelet_all_max_power_at_time'], df['wavelet_all_max_power_at_freq'], df['mep_category_cmap'], c=df['mep_category_cmap'])\n",
    "ax.set_xlabel('Time - All')\n",
    "ax.set_ylabel('Freq - All')\n",
    "ax.set_zlabel('MEP/CMAP');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter3D(df['wavelet_all_max_power_at_time'], df['wavelet_all_max_power_at_freq'], df['mep_category_percentile'], c=df['mep_category_percentile'])\n",
    "ax.set_xlabel('Time - All')\n",
    "ax.set_ylabel('Scale - All')\n",
    "ax.set_zlabel('MEP category (percentile)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter3D(df['wavelet_all_max_power_at_time'], df['wavelet_all_max_power_at_freq'], df['mep_size'], c=df['mep_size'])\n",
    "ax.set_xlabel('Time - All')\n",
    "ax.set_ylabel('Scale - All')\n",
    "ax.set_zlabel('MEP size');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter3D(df['wavelet_ltm1_max_power_at_time'], df['wavelet_ltm1_max_power_at_freq'], df['mep_size'], c=df['mep_size'])\n",
    "ax.set_xlabel('Time - Ltm1')\n",
    "ax.set_ylabel('Scale - Ltm1')\n",
    "ax.set_zlabel('MEP size')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df\n",
    "bins = [0, 4, 8, 12, 20, 30, 46, 70]\n",
    "\n",
    "# ax = plt.axes(projection='3d')\n",
    "# ax.scatter3D(df['wavelet_ltm1_max_power_at_time'], df['mep_category_percentile'], df['mep_size'], c=df['mep_size'])\n",
    "# ax.set_xlabel('Time - Ltm1')\n",
    "# ax.set_ylabel('Scale - Ltm1')\n",
    "# ax.set_zlabel('MEP size');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_by_freq_time(df2, bins = [0, 4, 8, 12, 20, 30, 46, 70], time_bins=np.linspace(-500, 0, 11)):\n",
    "    df2['wavelet_all_max_power_at_freq_bin'] = pd.cut(df2['wavelet_all_max_power_at_freq'], bins)\n",
    "    df2['wavelet_all_max_power_at_time_bin'] = pd.cut(df2['wavelet_all_max_power_at_time'], time_bins/1000)\n",
    "    \n",
    "    df2['wavelet_ltm1_max_power_at_freq_bin'] = pd.cut(df2['wavelet_ltm1_max_power_at_freq'], bins)\n",
    "    df2['wavelet_ltm1_max_power_at_time_bin'] = pd.cut(df2['wavelet_ltm1_max_power_at_time'], time_bins/1000)\n",
    "    \n",
    "    df2['wavelet_rtm1_max_power_at_freq_bin'] = pd.cut(df2['wavelet_rtm1_max_power_at_freq'], bins)\n",
    "    df2['wavelet_rtm1_max_power_at_time_bin'] = pd.cut(df2['wavelet_rtm1_max_power_at_time'], time_bins/1000)\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupby_freq_time(df):\n",
    "    df = pd.DataFrame(df.to_records())\n",
    "    df['wavelet_ltm1_max_power_at_freq_bin_left'] = df['wavelet_ltm1_max_power_at_freq_bin'].apply(lambda x: x.left)\n",
    "    df['wavelet_ltm1_max_power_at_time_bin_left'] = df['wavelet_ltm1_max_power_at_time_bin'].apply(lambda x: x.left)\n",
    "    df = df.fillna(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_percentile_small = categorize_by_freq_time(df2[df2['mep_category_percentile'] == 0]).groupby(['wavelet_ltm1_max_power_at_freq_bin', 'wavelet_ltm1_max_power_at_time_bin']).count()\n",
    "df_percentile_small = groupby_freq_time(df_percentile_small)\n",
    "fig = plt.figure(figsize=(9,6))\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.bar3d(df_percentile_small['wavelet_ltm1_max_power_at_freq_bin_left'], df_percentile_small['wavelet_ltm1_max_power_at_time_bin_left'], np.zeros_like(df_percentile_small['all_all_max_amplitude']), 0.5, 0.005, df_percentile_small['all_all_max_amplitude'], shade=True)\n",
    "ax.set_xlabel('Freq - Ltm1')\n",
    "ax.set_ylabel('Time - Ltm1')\n",
    "ax.set_zlabel('MEP category (percentile)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_percentile_small = categorize_by_freq_time(df2[df2['mep_category_percentile'] == 0]).groupby(['wavelet_ltm1_max_power_at_freq_bin', 'wavelet_ltm1_max_power_at_time_bin']).count()\n",
    "df_percentile_small = groupby_freq_time(df_percentile_small)\n",
    "\n",
    "df_percentile_medium = categorize_by_freq_time(df2[df2['mep_category_percentile'] == 1]).groupby(['wavelet_ltm1_max_power_at_freq_bin', 'wavelet_ltm1_max_power_at_time_bin']).count()\n",
    "df_percentile_medium = groupby_freq_time(df_percentile_medium)\n",
    "\n",
    "df_percentile_large = categorize_by_freq_time(df2[df2['mep_category_percentile'] == 2]).groupby(['wavelet_ltm1_max_power_at_freq_bin', 'wavelet_ltm1_max_power_at_time_bin']).count()\n",
    "df_percentile_large = groupby_freq_time(df_percentile_large)\n",
    "\n",
    "\n",
    "time_width = 0.02\n",
    "freq_width = 0.02\n",
    "mlab.barchart(df_percentile_small['wavelet_ltm1_max_power_at_freq_bin_left'], df_percentile_small['wavelet_ltm1_max_power_at_time_bin_left'], df_percentile_small['all_all_max_amplitude'], line_width=time_width)\n",
    "mlab.barchart(df_percentile_medium['wavelet_ltm1_max_power_at_freq_bin_left'] + freq_width, df_percentile_medium['wavelet_ltm1_max_power_at_time_bin_left'] + time_width, df_percentile_medium['all_all_max_amplitude'], line_width=time_width)\n",
    "mlab.barchart(df_percentile_large['wavelet_ltm1_max_power_at_freq_bin_left'] + freq_width * 2, df_percentile_large['wavelet_ltm1_max_power_at_time_bin_left'] + time_width * 2, df_percentile_large['all_all_max_amplitude'], line_width=time_width)\n",
    "# ax.set_xlabel('Freq - Ltm1')\n",
    "# ax.set_ylabel('Time - Ltm1')\n",
    "# ax.set_zlabel('MEP category (percentile)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_percentile_small = categorize_by_freq_time(df2[df2['mep_category_percentile'] == 0]).groupby(['wavelet_ltm1_max_power_at_freq_bin', 'wavelet_ltm1_max_power_at_time_bin']).count()\n",
    "df_percentile_small = groupby_freq_time(df_percentile_small)\n",
    "\n",
    "df_percentile_medium = categorize_by_freq_time(df2[df2['mep_category_percentile'] == 1]).groupby(['wavelet_ltm1_max_power_at_freq_bin', 'wavelet_ltm1_max_power_at_time_bin']).count()\n",
    "df_percentile_medium = groupby_freq_time(df_percentile_medium)\n",
    "\n",
    "df_percentile_large = categorize_by_freq_time(df2[df2['mep_category_percentile'] == 2]).groupby(['wavelet_ltm1_max_power_at_freq_bin', 'wavelet_ltm1_max_power_at_time_bin']).count()\n",
    "df_percentile_large = groupby_freq_time(df_percentile_large)\n",
    "\n",
    "\n",
    "time_width = 0.02\n",
    "freq_width = 1.2\n",
    "fig = plt.figure(figsize=(9,6))\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.bar3d(df_percentile_small['wavelet_ltm1_max_power_at_freq_bin_left'], df_percentile_small['wavelet_ltm1_max_power_at_time_bin_left'], np.zeros_like(df_percentile_small['all_all_max_amplitude']), freq_width, time_width, df_percentile_small['all_all_max_amplitude'], shade=True)\n",
    "ax.bar3d(df_percentile_medium['wavelet_ltm1_max_power_at_freq_bin_left'] + freq_width, df_percentile_medium['wavelet_ltm1_max_power_at_time_bin_left'] + time_width, np.zeros_like(df_percentile_medium['all_all_max_amplitude']), freq_width, time_width, df_percentile_medium['all_all_max_amplitude'], shade=True)\n",
    "ax.bar3d(df_percentile_large['wavelet_ltm1_max_power_at_freq_bin_left'] + freq_width * 2, df_percentile_large['wavelet_ltm1_max_power_at_time_bin_left'] + time_width * 2, np.zeros_like(df_percentile_large['all_all_max_amplitude']), freq_width, time_width, df_percentile_large['all_all_max_amplitude'], shade=True)\n",
    "ax.set_xlabel('Freq - Ltm1')\n",
    "ax.set_ylabel('Time - Ltm1')\n",
    "ax.set_zlabel('MEP category (percentile)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_percentile_small = categorize_by_freq_time(df2[df2['mep_category_absolute'] == 0]).groupby(['wavelet_ltm1_max_power_at_freq_bin', 'wavelet_ltm1_max_power_at_time_bin']).count()\n",
    "df_percentile_small = groupby_freq_time(df_percentile_small)\n",
    "\n",
    "df_percentile_medium = categorize_by_freq_time(df2[df2['mep_category_absolute'] == 1]).groupby(['wavelet_ltm1_max_power_at_freq_bin', 'wavelet_ltm1_max_power_at_time_bin']).count()\n",
    "df_percentile_medium = groupby_freq_time(df_percentile_medium)\n",
    "\n",
    "df_percentile_large = categorize_by_freq_time(df2[df2['mep_category_absolute'] == 2]).groupby(['wavelet_ltm1_max_power_at_freq_bin', 'wavelet_ltm1_max_power_at_time_bin']).count()\n",
    "df_percentile_large = groupby_freq_time(df_percentile_large)\n",
    "\n",
    "\n",
    "time_width = 0.02\n",
    "freq_width = 1.2\n",
    "fig = plt.figure(figsize=(9,6))\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.bar3d(df_percentile_small['wavelet_ltm1_max_power_at_freq_bin_left'], df_percentile_small['wavelet_ltm1_max_power_at_time_bin_left'], np.zeros_like(df_percentile_small['all_all_max_amplitude']), freq_width, time_width, df_percentile_small['all_all_max_amplitude'], shade=True)\n",
    "ax.bar3d(df_percentile_medium['wavelet_ltm1_max_power_at_freq_bin_left'] + freq_width, df_percentile_medium['wavelet_ltm1_max_power_at_time_bin_left'] + time_width, np.zeros_like(df_percentile_medium['all_all_max_amplitude']), freq_width, time_width, df_percentile_medium['all_all_max_amplitude'], shade=True)\n",
    "ax.bar3d(df_percentile_large['wavelet_ltm1_max_power_at_freq_bin_left'] + freq_width * 2, df_percentile_large['wavelet_ltm1_max_power_at_time_bin_left'] + time_width * 2, np.zeros_like(df_percentile_large['all_all_max_amplitude']), freq_width, time_width, df_percentile_large['all_all_max_amplitude'], shade=True)\n",
    "ax.set_xlabel('Freq - Ltm1')\n",
    "ax.set_ylabel('Time - Ltm1')\n",
    "ax.set_zlabel('MEP category (absolute)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Frequency vs MEP Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,4))\n",
    "plt.plot(df['ltm1_all_max_power_freq'], df['mep_area'], '.')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('MEP Area')\n",
    "\n",
    "plt.figure(figsize=(14,4))\n",
    "plt.plot(df['ltm1_alpha_max_power_freq'], df['mep_area'], '.')\n",
    "plt.xlabel('Frequency - alpha band (Hz)')\n",
    "plt.ylabel('MEP Area')\n",
    "\n",
    "plt.figure(figsize=(14,4))\n",
    "plt.plot(df['ltm1_beta_max_power_freq'], df['mep_area'], '.')\n",
    "plt.xlabel('Frequency - beta band (Hz)')\n",
    "plt.ylabel('MEP Area')\n",
    "\n",
    "plt.figure(figsize=(14,4))\n",
    "plt.plot(df['ltm1_gamma_max_power_freq'], df['mep_area'], '.')\n",
    "plt.xlabel('Frequency - gamma band (Hz)')\n",
    "plt.ylabel('MEP Area')\n",
    "\n",
    "plt.figure(figsize=(14,4))\n",
    "plt.plot(df['ltm1_delta_max_power_freq'], df['mep_area'], '.')\n",
    "plt.xlabel('Frequency - delta band (Hz)')\n",
    "plt.ylabel('MEP Area')\n",
    "\n",
    "plt.figure(figsize=(14,4))\n",
    "plt.plot(df['ltm1_theta_max_power_freq'], df['mep_area'], '.')\n",
    "plt.xlabel('Frequency - theta band (Hz)')\n",
    "plt.ylabel('MEP Area')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.groupby(['sub', 'exp', 'run']).mean()\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,4))\n",
    "plt.plot(df2['ltm1_all_max_power_freq'], df2['mep_size'], 'o')\n",
    "plt.xlabel('LtM1 Frequency (Hz)')\n",
    "plt.ylabel('MEP Size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,4))\n",
    "plt.plot(df2['ltm1_alpha_max_power_freq'], df2['mep_size'], 'o')\n",
    "plt.xlabel('LtM1 Frequency - alpha band (Hz)')\n",
    "plt.ylabel('MEP Size')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 4, 8, 12, 20, 30, 46, 70]\n",
    "df3_mean = df.groupby(pd.cut(df['rtm1_all_max_power_freq'], bins)).mean()\n",
    "df3_max = df.groupby(pd.cut(df['rtm1_all_max_power_freq'], bins)).max()\n",
    "df3_min = df.groupby(pd.cut(df['rtm1_all_max_power_freq'], bins)).min()\n",
    "df3_mean['mep_size_mean'] = df3_mean['mep_size']\n",
    "df3_mean['mep_size_max'] = df3_max['mep_size']\n",
    "df3_mean['mep_size_min'] = df3_min['mep_size']\n",
    "df3_mean['rtm1_all_max_power_freq'] = df3_mean.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_mean[['rtm1_all_max_power_freq', 'mep_size_mean', 'mep_size_max', 'mep_size_min']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df4 = df\n",
    "bins = [0, 4, 8, 12, 20, 30, 46, 70]\n",
    "df4['bin'] = pd.cut(df4['ltm1_all_max_power_freq'], bins)\n",
    "df4.head()\n",
    "\n",
    "fig = plt.figure(figsize=(14, 8))\n",
    "ax = sns.boxplot(x=\"bin\", y=\"mep_size\", data=df4)\n",
    "ax.set_xlabel('Frequency Bin')\n",
    "ax.set_ylabel('MEP Size')\n",
    "ax.set_title('Left M1 Electrode Frequency Bins vs MEP Size')\n",
    "\n",
    "df4 = df\n",
    "df4['bin'] = pd.cut(df4['rtm1_all_max_power_freq'], bins)\n",
    "df4.head()\n",
    "\n",
    "fig = plt.figure(figsize=(14, 8))\n",
    "ax = sns.boxplot(x=\"bin\", y=\"mep_size\", data=df4)\n",
    "ax.set_xlabel('Frequency Bin')\n",
    "ax.set_ylabel('MEP Size')\n",
    "ax.set_title('Right M1 Electrode Frequency Bins vs MEP Size')\n",
    "\n",
    "df4 = df\n",
    "df4['bin'] = pd.cut(df4['all_all_max_power_freq'], bins)\n",
    "df4.head()\n",
    "\n",
    "fig = plt.figure(figsize=(14, 8))\n",
    "ax = sns.boxplot(x=\"bin\", y=\"mep_size\", data=df4)\n",
    "ax.set_xlabel('Frequency Bin')\n",
    "ax.set_ylabel('MEP Size')\n",
    "ax.set_title('All Electrodes Frequency Bins vs MEP Size')\n",
    "\n",
    "df4 = df\n",
    "df4['bin'] = pd.cut(df4['central_all_max_power_freq'], bins)\n",
    "df4.head()\n",
    "\n",
    "fig = plt.figure(figsize=(14, 8))\n",
    "ax = sns.boxplot(x=\"bin\", y=\"mep_size\", data=df4)\n",
    "ax.set_xlabel('Frequency Bin')\n",
    "ax.set_ylabel('MEP Size')\n",
    "ax.set_title('Central Electrodes Frequency Bins vs MEP Size')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = df\n",
    "# df3 = []\n",
    "# for row in df2:\n",
    "#     row['']\n",
    "#     df3.append()\n",
    "\n",
    "df4 = df\n",
    "bins = [0, 4, 8, 12, 20, 30, 46, 70]\n",
    "df4['bin'] = pd.cut(df4['ltm1_all_max_power_freq'], bins)\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MEP size group chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df4.groupby(['bin_str', 'mep_category']).count()\n",
    "df5 = df5[['mep_area']]\n",
    "df5 = df5.unstack()\n",
    "df5.columns = ['small', 'medium', 'large']\n",
    "df5 = df5.sort_index(axis=0)\n",
    "df5['order'] = [0, 3, 4, 5, 1, 2]\n",
    "df5 = df5.sort_values(by=['order'])\n",
    "df5 = df5.drop('order', axis=1)\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ax = df5.plot(kind='bar', figsize=(12,4), colormap='Accent')\n",
    "ax.set_xlabel('Frequency')\n",
    "ax.set_ylabel('Count')\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(df5.index, df5['small'], color='r', label='small')\n",
    "plt.plot(df5.index, df5['medium'], color='k', label='medium')\n",
    "plt.plot(df5.index, df5['large'], color='c', label='large')\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEG area and amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df4['area_under_eeg'], df4['mep_size'], 'o')\n",
    "plt.xlabel('Area under EEG - all electrodes')\n",
    "plt.ylabel('MEP Size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df4['rtm1_area_under_eeg'], df4['mep_size'], 'o')\n",
    "plt.xlabel('Area under EEG - right M1 electrodes')\n",
    "plt.ylabel('MEP Size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df4['ltm1_area_under_eeg'], df4['mep_size'], 'o')\n",
    "plt.xlabel('Area under EEG - left M1 electrodes')\n",
    "plt.ylabel('MEP Size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df4['all_max_amplitude'], df4['mep_size'], 'o')\n",
    "plt.xlabel('Max amplitude - all electrodes')\n",
    "plt.ylabel('MEP Size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df4['ltm1_max_amplitude'], df4['mep_size'], 'o')\n",
    "plt.xlabel('Max amplitude - Left M1 electrodes')\n",
    "plt.ylabel('MEP Size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df4['rtm1_max_amplitude'], df4['mep_size'], 'o')\n",
    "plt.xlabel('Max amplitude - Right M1 electrodes')\n",
    "plt.ylabel('MEP Size')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[['all_all_max_power', \n",
    "        'all_all_max_power_freq', 'all_alpha_max_power',\n",
    "        'all_alpha_max_power_freq', 'all_beta_max_power',\n",
    "        'all_beta_max_power_freq', 'all_delta_max_power',\n",
    "        'all_delta_max_power_freq', 'all_gamma_max_power',\n",
    "        'all_gamma_max_power_freq', 'all_max_amplitude', 'all_theta_max_power',\n",
    "        'all_theta_max_power_freq', 'area_under_eeg',\n",
    "        \n",
    "        'ltm1_all_max_power', \n",
    "        'ltm1_all_max_power_freq', 'ltm1_alpha_max_power',\n",
    "        'ltm1_alpha_max_power_freq', 'ltm1_area_under_eeg',\n",
    "        'ltm1_beta_max_power', 'ltm1_beta_max_power_freq',\n",
    "        'ltm1_delta_max_power', 'ltm1_delta_max_power_freq',\n",
    "        'ltm1_gamma_max_power', 'ltm1_gamma_max_power_freq',\n",
    "        'ltm1_max_amplitude', 'ltm1_theta_max_power',\n",
    "        'ltm1_theta_max_power_freq', \n",
    "        \n",
    "        'rtm1_all_max_power',\n",
    "        'rtm1_all_max_power_freq', 'rtm1_alpha_max_power',\n",
    "        'rtm1_alpha_max_power_freq', 'rtm1_area_under_eeg',\n",
    "        'rtm1_beta_max_power', 'rtm1_beta_max_power_freq',\n",
    "        'rtm1_delta_max_power', 'rtm1_delta_max_power_freq',\n",
    "        'rtm1_gamma_max_power', 'rtm1_gamma_max_power_freq',\n",
    "        'rtm1_max_amplitude', 'rtm1_theta_max_power',\n",
    "        'rtm1_theta_max_power_freq',\n",
    "\n",
    "        'central_all_max_power',\n",
    "        'central_all_max_power_freq', 'central_alpha_max_power',\n",
    "        'central_alpha_max_power_freq', 'central_area_under_eeg',\n",
    "        'central_beta_max_power', 'central_beta_max_power_freq',\n",
    "        'central_delta_max_power', 'central_delta_max_power_freq',\n",
    "        'central_gamma_max_power', 'central_gamma_max_power_freq',\n",
    "        'central_max_amplitude', 'central_theta_max_power',\n",
    "        'central_theta_max_power_freq']]\n",
    "y = df['mep_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = model.predict(x_test)\n",
    "rmse = mean_squared_error(y_test, y_predicted)\n",
    "r2 = r2_score(y_test, y_predicted)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_test, y_predicted, 'o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectPercentile, f_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from tpot.builtins import StackingEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators = 5000, random_state = 42)\n",
    "rf.fit(x_train, y_train)\n",
    "y_pred = rf.predict(x_test)\n",
    "print(\"R2 score:\", sklearn.metrics.r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_test, y_pred, 'o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVR()\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "print(\"R2 score:\", sklearn.metrics.r2_score(y_test, y_pred))\n",
    "plt.plot(y_test, y_pred, 'o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tpot = TPOTRegressor(n_jobs=-1, verbosity=2)\n",
    "tpot.fit(x_train, y_train)\n",
    "print(tpot.score(x_test, y_test))\n",
    "predictions = tpot.predict(x_test)\n",
    "print(\"R2 score:\", sklearn.metrics.r2_score(y_test, predictions))\n",
    "tpot.export('tpot_01_pipeline_accuracy_100.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tpot = TPOTRegressor(n_jobs=-1, verbosity=2, scoring='r2')\n",
    "tpot.fit(x_train, y_train)\n",
    "print(tpot.score(x_test, y_test))\n",
    "predictions = tpot.predict(x_test)\n",
    "print(\"R2 score:\", sklearn.metrics.r2_score(y_test, predictions))\n",
    "tpot.export('tpot_02_pipeline_r2_100.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot = TPOTRegressor(n_jobs=-1, verbosity=2, generations=400, population_size=400, scoring='r2')\n",
    "tpot.fit(x_train, y_train)\n",
    "print(tpot.score(x_test, y_test))\n",
    "predictions = tpot.predict(x_test)\n",
    "print(\"R2 score:\", sklearn.metrics.r2_score(y_test, predictions))\n",
    "tpot.export('tpot_03_pipeline_r2_400.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot = TPOTRegressor(n_jobs=-1, verbosity=2, generations=400, population_size=400)\n",
    "tpot.fit(x_train, y_train)\n",
    "print(tpot.score(x_test, y_test))\n",
    "predictions = tpot.predict(x_test)\n",
    "print(\"R2 score:\", sklearn.metrics.r2_score(y_test, predictions))\n",
    "tpot.export('tpot_03_pipeline_accuracy_400.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectPercentile, f_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from tpot.builtins import StackingEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exported_pipeline = make_pipeline(\n",
    "    SelectPercentile(score_func=f_regression, percentile=7),\n",
    "    StackingEstimator(estimator=KNeighborsRegressor(n_neighbors=29, p=1, weights=\"distance\")),\n",
    "    StackingEstimator(estimator=ExtraTreesRegressor(bootstrap=False, max_features=0.25, min_samples_leaf=20, min_samples_split=15, n_estimators=100)),\n",
    "    SelectPercentile(score_func=f_regression, percentile=48),\n",
    "    RandomForestRegressor(bootstrap=False, max_features=0.6000000000000001, min_samples_leaf=14, min_samples_split=16, n_estimators=100)\n",
    ")\n",
    "\n",
    "exported_pipeline.fit(x_train, y_train)\n",
    "print(\"Train R2 score:\", sklearn.metrics.r2_score(y_train, exported_pipeline.predict(x_train)))\n",
    "print(\"Test R2 score:\", sklearn.metrics.r2_score(y_test, exported_pipeline.predict(x_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
