{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/raquib/anaconda3/envs/tmseeg/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/raquib/anaconda3/envs/tmseeg/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "from io import StringIO\n",
    "import mne\n",
    "from mne.io import read_raw_eeglab, read_epochs_eeglab\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from scipy import fftpack\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "# from tqdm import tqdm, tqdm_notebook\n",
    "from tqdm.notebook import tqdm\n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from livelossplot.tf_keras import PlotLossesCallback\n",
    "\n",
    "import sklearn.model_selection\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "import multiprocessing\n",
    "from tpot import TPOTRegressor\n",
    "from oct2py import octave\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from joblib import wrap_non_picklable_objects\n",
    "import json\n",
    "import pickle\n",
    "import os.path\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import timeit\n",
    "from skimage.transform import resize\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta\n",
    "import json\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.genmod import bayes_mixed_glm as glm\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import RFECV\n",
    "from spectrum import arburg, arma2psd, pburg\n",
    "import pylab\n",
    "from scipy.signal import find_peaks, butter\n",
    "from scipy.integrate import simps\n",
    "from scipy.io import loadmat\n",
    "from numpy import trapz\n",
    "import gzip\n",
    "import scipy.fftpack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power and phase calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blackman_harris_filter(channel, time, cutoffs, fs, numtaps):\n",
    "    b = signal.firwin(numtaps, cutoffs, window='blackmanharris', fs=fs)\n",
    "    filtered = signal.lfilter(b, 1, channel)\n",
    "    delay = 0.5 * (numtaps - 1) / fs\n",
    "    df = pd.DataFrame({\n",
    "        'time': time-delay,\n",
    "        'channel': filtered\n",
    "    })\n",
    "    return df\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, btype, order):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype=btype)\n",
    "    y = signal.lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "def get_phase(channel, time, band, fs, filter_type, start_time_ms, stop_time_ms, blackmann_harris_ntaps):\n",
    "    if filter_type=='butter':\n",
    "        df_filtered = pd.DataFrame({'channel': butter_bandpass_filter(channel, band[0], band[1], fs, btype='bandpass', order=3), 'time': time})\n",
    "    else:\n",
    "        df_filtered = blackman_harris_filter(channel, time, [0.000001, band[0]], fs, numtaps=blackmann_harris_ntaps)\n",
    "        df_filtered = blackman_harris_filter(df_filtered['channel'].values, df_filtered['time'].values, band[1], fs, numtaps=blackmann_harris_ntaps)    \n",
    "    \n",
    "    hilb = signal.hilbert(df_filtered[(df_filtered['time'] > start_time_ms) & (df_filtered['time'] < stop_time_ms)]['channel'])\n",
    "    phase = np.angle(hilb, deg=True)\n",
    "    df_phase = pd.DataFrame(phase, columns=['phase'])\n",
    "    df_phase['time'] = df_filtered[(df_filtered['time'] > start_time_ms) & (df_filtered['time'] < stop_time_ms)]['time'].values\n",
    "    return df_phase\n",
    "\n",
    "def get_power(channel, time, fs, crop_start_millis, crop_end_millis, method, filter_type, resample_fs, line_noise_band, blackmann_harris_ntaps):\n",
    "    # Crop.\n",
    "    channel = channel[(time > crop_start_millis) & (time < crop_end_millis)].values\n",
    "    time = time[(time > crop_start_millis) & (time < crop_end_millis)].values\n",
    "    \n",
    "    # Resample\n",
    "    if resample_fs is None:\n",
    "        resampled = channel\n",
    "        resampled_time = time\n",
    "    else:\n",
    "        ts = time[1] - time[0]\n",
    "        secs = len(channel) * ts\n",
    "        secs = secs/1000\n",
    "        resampled = signal.resample(channel, int(secs*resample_fs))\n",
    "        resampled_time = np.linspace(time[0], time[-1], len(resampled))\n",
    "        fs = resample_fs\n",
    "\n",
    "    # Remove line nosie.\n",
    "    if filter_type == 'butter':\n",
    "        resampled = butter_bandpass_filter(resampled, line_noise_band[0], line_noise_band[1], fs, 'bandstop', order=4)\n",
    "        resampled_time = time\n",
    "    else:\n",
    "        df_filtered = blackman_harris_filter(resampled, resampled_time, line_noise_band, fs, numtaps=blackmann_harris_ntaps)\n",
    "        resampled = df_filtered['channel']\n",
    "        resampled_time = df_filtered['time']\n",
    "    \n",
    "    # PSD.\n",
    "    if method == 'welch':\n",
    "        # Welch method\n",
    "        freq, power = signal.welch(resampled, fs, nperseg=4*fs)\n",
    "        df_power = pd.DataFrame({'freq': freq, 'power': power})\n",
    "    elif method == 'fft':\n",
    "        # FFT method\n",
    "        T = 1/fs\n",
    "        N = len(resampled)\n",
    "        yf = scipy.fftpack.fft(resampled)\n",
    "        yf = 2 / (N/2) * np.abs(yf[:N//2])\n",
    "        xf = np.linspace(0, 1/(2*T), N // 2)\n",
    "        df_power = pd.DataFrame({'freq': xf, 'power': yf})\n",
    "    elif method == 'pburg':\n",
    "        # Burgs method\n",
    "        order = min(len(resampled)-2, int(fs/4))\n",
    "        p = pburg(resampled, order, sampling=fs, NFFT=fs)\n",
    "        power = p.psd\n",
    "        freq = np.linspace(0, fs/2, len(power))\n",
    "        df_power = pd.DataFrame({'freq': freq, 'power': power})\n",
    "\n",
    "    df_power = df_power[df_power['freq'] < fs/2]\n",
    "    return df_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read hjorth file.\n",
    "def get_hjorth_path(path):\n",
    "    return path.replace('.csv', '-hjorth.mat')\n",
    "\n",
    "def get_hjorth_trial(filename):\n",
    "    x = loadmat(filename)\n",
    "    c3 = x['dat'][0][0][3][0][0][0]\n",
    "    trials = []\n",
    "    time = np.linspace(0, 1000, len(c3))\n",
    "    return pd.DataFrame({'C3': c3, 'time': time})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_files = sorted(glob.glob('data/dataset2/alcoholism-02-for-matlab/*/*.csv'))\n",
    "hjorth_files = list(map(get_hjorth_path, raw_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diagnose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ind = 30\n",
    "# print(\"{} - {}\".format(ind, raw_files[ind]))\n",
    "# df_trial = pd.read_csv(raw_files[ind])\n",
    "# df_trial_hjorth = get_hjorth_trial(hjorth_files[ind])\n",
    "# channel = df_trial['C3']\n",
    "# time = df_trial_hjorth['time'] - 1000\n",
    "\n",
    "# fs = 256\n",
    "# band = [30, 80]\n",
    "# blackmann_harris_ntaps = 101\n",
    "# line_noise_band = [48, 52]\n",
    "# time_start = -150\n",
    "\n",
    "# for filter_type in ['butter', 'blackmann']:\n",
    "#     i = 0\n",
    "#     f, axs = plt.subplots(1,5,figsize=(16,2))\n",
    "#     axs[i].plot(time, channel)\n",
    "#     i = i + 1\n",
    "\n",
    "#     df_phase = get_phase(channel, time, band=band, fs=fs, filter_type=filter_type, start_time_ms=time_start, stop_time_ms=-1, blackmann_harris_ntaps=blackmann_harris_ntaps)\n",
    "#     axs[i].plot(df_phase['time'], df_phase['phase'])\n",
    "#     axs[i].set_title(\"Phase - {}\".format(filter_type))\n",
    "#     i = i + 1\n",
    "\n",
    "#     for method in ['pburg', 'welch', 'fft']:\n",
    "#         df_power = get_power(channel, time, fs, crop_start_millis=-750, crop_end_millis=-1, method=method, filter_type=filter_type, resample_fs=None, line_noise_band=line_noise_band, blackmann_harris_ntaps=blackmann_harris_ntaps)\n",
    "#         df_power = df_power[df_power['freq'] < 130]\n",
    "#         axs[i].plot(df_power['freq'], df_power['power'])\n",
    "#         axs[i].set_title(\"Power - {} - {}\".format(filter_type, method))\n",
    "#         i = i + 1\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_trial(raw_path, hjorth_path):\n",
    "    df_powers = []\n",
    "    df_phases = []\n",
    "    blackmann_harris_ntaps = 101\n",
    "    subject = raw_path.split('/')[3]\n",
    "    df_trial_raw = pd.read_csv(raw_path)\n",
    "    df_trial_hjorth = get_hjorth_trial(hjorth_path)\n",
    "    df_trial_hjorth['time'] = df_trial_hjorth['time'] - 1000\n",
    "    df_trial_avg = df_trial_raw.copy()\n",
    "    df_trial_avg['C3'] = df_trial_avg[['C3', 'FC6', 'FC4', 'FC2', 'C6', 'C4', 'C2', 'CP6', 'CP4', 'CP2']].mean(axis=1)\n",
    "    df_trial_raw['time'] = df_trial_hjorth['time']\n",
    "    df_trial_avg['time'] = df_trial_hjorth['time']\n",
    "    \n",
    "    trial_num = int(raw_path.split('/')[4].split('-')[1].split('.')[0])\n",
    "    df_sub = pd.read_csv('data/dataset2/alcoholism-01-parsed/' + subject + '.csv')\n",
    "    power_row = {\n",
    "        'sub': subject,\n",
    "        'trial': trial_num,\n",
    "        'alcholic': df_sub.iloc[0]['alcoholic'],\n",
    "        'condition': df_sub[df_sub['trial'] == trial_num].iloc[0]['condition']\n",
    "    }\n",
    "    \n",
    "    for eeg_type, df_trial in zip(['Raw', 'Hjorth', 'Averaged'], [df_trial_raw, df_trial_hjorth, df_trial_avg]):\n",
    "        for filter_code, filter_name in zip(['butter', 'blackmannharris'], ['Butterworth', 'Blackmann-Harris']):\n",
    "            for time in [-750, -150]:\n",
    "                for method_code, method_name in zip(['pburg', 'welch', 'fft'], ['Burg', 'Welch', 'FFT']):\n",
    "\n",
    "                    try:\n",
    "                        df_power = get_power(df_trial['C3'], df_trial['time'], fs=256, crop_start_millis=time, crop_end_millis=-1, method=method_code, filter_type=filter_code, resample_fs=None, line_noise_band=[48, 52], blackmann_harris_ntaps=blackmann_harris_ntaps)\n",
    "                    except:\n",
    "                        continue\n",
    "\n",
    "                    for band, fc1, fc2 in zip(['Theta', 'Mu', 'Beta', 'Gamma'], [3.5, 8, 13, 30], [8, 12, 30, 80]):\n",
    "                        power = df_power[df_power['freq'] >= fc1]\n",
    "                        power = power[power['freq'] < fc2]\n",
    "                        power = power['power'].mean(axis=0)\n",
    "                        row = power_row.copy()\n",
    "                        row['EEG'] = eeg_type\n",
    "                        row['Filter'] = filter_name\n",
    "                        row['Time'] = time\n",
    "                        row['Method'] = method_name\n",
    "                        row['Band'] = band\n",
    "                        row['Power'] = power\n",
    "                        df_powers.append(row)\n",
    "            for band, fc1, fc2 in zip(['Theta', 'Mu', 'Beta', 'Gamma'], [3.5, 8, 13, 30], [8, 12, 30, 80]):\n",
    "                phase = get_phase(df_trial['C3'], df_trial['time'], [fc1, fc2], filter_type=filter_code, start_time_ms=-750, stop_time_ms=-1, fs=256, blackmann_harris_ntaps=blackmann_harris_ntaps)\n",
    "                row = power_row.copy()\n",
    "                row['EEG'] = eeg_type\n",
    "                row['Filter'] = filter_name\n",
    "                row['Band'] = band\n",
    "                row['Phase'] = phase\n",
    "                df_phases.append(row)\n",
    "    return (df_powers, df_phases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01371427142145edb00fdf6a98294027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10962.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run analysis\n",
    "num_cores = multiprocessing.cpu_count() - 2\n",
    "results = Parallel(n_jobs=num_cores)(delayed(process_trial)(path_raw, path_hjorth) for path_raw, path_hjorth in tqdm(zip(raw_files, hjorth_files), total=len(raw_files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_power = []\n",
    "df_phase = []\n",
    "for power, phase in results:\n",
    "    df_power.append(power)\n",
    "    df_phase.append(phase)\n",
    "df_power = pd.DataFrame(df_power)\n",
    "df_phase = pd.DataFrame(df_phase)\n",
    "df_power.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_power.to_csv('157-d2-power.csv')\n",
    "df_phase.to_csv('157-d2-phase.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
